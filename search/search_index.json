{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"EPN CMS collaboration","text":""},{"location":"#advances-of-the-project","title":"Advances of the Project","text":""},{"location":"#reproducible-analysis","title":"Reproducible Analysis:","text":"<p>Reproducible Analysis of CMS Open Data: Search for Dark Matter in Association with Top Quarks (Based on the CMS publication: \u201cSearch for dark matter produced in association with a single top quark or a top quark pair in proton\u2013proton collisions at (\\(\\sqrt s = 13 \\TeV\\)\u201d).</p>"},{"location":"All_Hadronic/all%20hadronic%20si/","title":"Complete Guide: AH Optimization Analysis for CMS Open Data","text":""},{"location":"All_Hadronic/all%20hadronic%20si/#overview","title":"Overview","text":"<p>This guide provides step-by-step instructions to generate the All-Hadronic (AH) optimization plots using CMS Open Data. The analysis processes TTToSemiLeptonic Monte Carlo events to produce distributions of key kinematic variables for signal region optimization.</p>"},{"location":"All_Hadronic/all%20hadronic%20si/#physics-motivation-and-channel-strategy-all-hadronic-channel","title":"Physics Motivation and Channel Strategy: All-Hadronic Channel","text":"<p>The Large Hadron Collider (LHC) collides protons at center-of-mass energies high enough to probe physics beyond the Standard Model. In the context of simplified dark matter models, partonic interactions can produce top quarks together with a new mediator particle that decays invisibly into dark matter candidates (\u03c7\u03c7\u0304). At the detector level, this results in events with multiple top quarks plus significant missing transverse momentum (p_T^miss).</p> <p>The production mechanisms of interest include: - Gluon fusion: $$gg \u2192 tt\u0304\u03c6 \u2192 tt\u0304 + \u03c7\u03c7\u0304 $$ - Single top associated production: $$gb \u2192 t\u03c6 \u2192 t + \u03c7\u03c7\u0304  $$ - t-channel production: $$qq' \u2192 tb\u03c6 \u2192 tb + \u03c7\u03c7\u0304 $$</p> <p>In all cases, the top quarks decay via \\(t \\to W b\\). In the all-hadronic (AH) channel, both W bosons decay hadronically \\((W \u2192 qq\u0304')\\), resulting in a fully hadronic final state with no isolated leptons.</p>"},{"location":"All_Hadronic/all%20hadronic%20si/#channel-characteristics","title":"Channel Characteristics","text":"<p>The all-hadronic channel is defined by: - No isolated leptons (lepton veto applied) - Multiple jets (\u22653 jets with \u22651 b-tagged jet) - Large missing transverse energy from dark matter particles and detector resolution</p> <p>Advantages: - Highest branching fraction (~46% for tt\u0304 \u2192 all hadronic) - Largest raw event yield - Sensitive to highly boosted topologies</p> <p>Challenges: - Overwhelming QCD multijet background - Instrumental MET from jet mismeasurements - Requires sophisticated background estimation techniques</p> <p>The all-hadronic channel complements lepton channels by providing additional sensitivity in high-MET regions where QCD background can be controlled through kinematic selections.</p>"},{"location":"All_Hadronic/all%20hadronic%20si/#prerequisites","title":"Prerequisites","text":""},{"location":"All_Hadronic/all%20hadronic%20si/#1-system-requirements","title":"1. System Requirements","text":"<ul> <li>Python 3.8 or higher</li> <li>8+ GB RAM recommended</li> <li>Stable internet connection (for XRootD access)</li> <li>5+ GB free disk space</li> </ul>"},{"location":"All_Hadronic/all%20hadronic%20si/#2-python-package-installation","title":"2. Python Package Installation","text":"<pre><code># Create and activate virtual environment (optional but recommended)\npython -m venv cms_analysis\nsource cms_analysis/bin/activate  # On Windows: cms_analysis\\Scripts\\activate\n\n# Install required packages\npip install uproot awkward numpy matplotlib\n</code></pre>"},{"location":"All_Hadronic/all%20hadronic%20si/#selection-criteria","title":"Selection Criteria","text":""},{"location":"All_Hadronic/all%20hadronic%20si/#1-trigger-requirements-hlt","title":"1. Trigger Requirements (HLT)","text":"<p>Events must fire at least one of the following MET-based triggers: \u2022 <code>HLT_PFMETNoMu120</code> \u2022 <code>HLT_PFMETNoMu90_PFMHTNoMu90_IDTight</code> \u2022 <code>HLT_PFMETNoMu110_PFMHTNoMu110_IDTight</code> \u2022 <code>HLT_PFMETNoMu120_PFMHTNoMu120_IDTight</code> \u2022 <code>HLT_PFMETNoMu90_JetIdCleaned_PFMHTNoMu90_IDTight</code> \u2022 <code>HLT_PFMETNoMu120_JetIdCleaned_PFMHTNoMu120_IDTight</code> \u2022 <code>HLT_PFMET120_PFMHT120</code> \u2022 <code>HLT_PFMET110_PFMHT110_IDTight</code> \u2022 <code>HLT_PFMET120_PFMHT120_IDTight</code> \u2022 <code>HLT_PFMET170</code> \u2022 <code>HLT_PFMET170_NoiseCleaned</code> \u2022 <code>HLT_PFMET170_HBHECleaned</code> \u2022 <code>HLT_PFMET170_HBHE_BeamHaloCleaned</code></p> <p>Motivation: These MET-based triggers are efficient for hadronic final states with genuine missing energy.</p>"},{"location":"All_Hadronic/all%20hadronic%20si/#2-event-cleaning-flags","title":"2. Event Cleaning Flags","text":"<p>Applied to both data and MC: - HBHENoiseFilter - HBHENoiseIsoFilter - ECALDeadCellFilter - GlobalTightHalo2016Filter - BadPFMuonFilter - BadChargedHadronFilter</p> <p>Applied to data only: - EEBadScFilter</p>"},{"location":"All_Hadronic/all%20hadronic%20si/#3-lepton-veto","title":"3. Lepton Veto","text":"<p>No veto leptons allowed: - Electrons: No electrons with pT &gt; 10 GeV, |\u03b7| &lt; 2.5 - Muons: No muons with pT &gt; 10 GeV, |\u03b7| &lt; 2.4</p>"},{"location":"All_Hadronic/all%20hadronic%20si/#4-jet-selection","title":"4. Jet Selection","text":"<ul> <li>pT: &gt; 30 GeV</li> <li>|\u03b7|: &lt; 2.4 (central jets)</li> <li>Jet ID: Loose working point</li> <li>Overlap removal: Jets within \u0394R &lt; 0.4 of tight leptons are removed</li> </ul>"},{"location":"All_Hadronic/all%20hadronic%20si/#5-event-level-requirements","title":"5. Event-Level Requirements","text":"<ul> <li>Number of jets: \u2265 3</li> <li>b-tagged jets: \u2265 1 (DeepCSV medium WP: 0.6321)</li> <li>Missing ET: pT^miss \u2265 250 GeV</li> <li>\u0394\u03c6(jet1,2, MET): &gt; 0.4 (baseline), &gt; 1.0 (optimized)</li> </ul>"},{"location":"All_Hadronic/all%20hadronic%20si/#6-additional-kinematic-variables-optimized-selection","title":"6. Additional Kinematic Variables (Optimized Selection)","text":"<ul> <li>Transverse bottom mass: M_bT &gt; 180 GeV</li> <li>Jet fraction: pT(j1)/HT \u2264 0.5 (for n_b \u2265 2 category)</li> </ul>"},{"location":"All_Hadronic/all%20hadronic%20si/#step-by-step-analysis","title":"Step-by-Step Analysis","text":""},{"location":"All_Hadronic/all%20hadronic%20si/#step-1-create-the-analysis-script","title":"Step 1: Create the Analysis Script","text":"<p>Create a file named <code>ah_optimization_analysis.py</code> with the following complete code:</p> <pre><code>import uproot\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport awkward as ak\nfrom matplotlib import rcParams\nimport time\nimport math\n\n# Set plot style for publication quality\nrcParams.update({\n    'font.size': 14,\n    'axes.titlesize': 16,\n    'axes.labelsize': 14,\n    'xtick.labelsize': 12,\n    'ytick.labelsize': 12,\n    'legend.fontsize': 12,\n    'figure.figsize': (15, 10),\n    'figure.autolayout': True\n})\nplt.style.use('seaborn-v0_8-whitegrid')\n\nclass AHOptimizationAnalyzer:\n    \"\"\"Analyzer for All-Hadronic optimization plots\"\"\"\n\n    def __init__(self, file_paths):\n        self.file_paths = file_paths\n        self.events = None\n        self.jet_info = None\n\n        # Selection parameters for AH baseline\n        self.params = {\n            'jet_pt_min': 30,\n            'jet_eta_max': 2.4,\n            'bjet_wp': 0.2783,  # DeepJet medium working point\n            'met_min': 30,\n            'min_dphi': 1.0,\n            'mt_min': 180,\n            'pt_ht_ratio_max': 0.5,\n        }\n\n    def load_events(self, max_events_per_file=None):\n        \"\"\"Load events from multiple remote files\"\"\"\n        print(\"=\"*70)\n        print(\"LOADING EVENTS FROM XROOTD SERVERS\")\n        print(\"=\"*70)\n\n        all_events = []\n        total_files = len(self.file_paths)\n\n        for i, file_path in enumerate(self.file_paths):\n            print(f\"\\n[{i+1}/{total_files}] Processing: {file_path.split('/')[-1]}\")\n\n            try:\n                start_time = time.time()\n\n                # Open remote file\n                file = uproot.open(file_path)\n                tree = file[\"Events\"]\n\n                # Get total entries\n                n_entries = tree.num_entries\n                print(f\"   Total entries: {n_entries:,}\")\n\n                # Determine entries to read\n                if max_events_per_file and max_events_per_file &lt; n_entries:\n                    entries_to_read = max_events_per_file\n                else:\n                    entries_to_read = n_entries\n\n                # Read essential branches\n                print(f\"   Reading {entries_to_read:,} events...\")\n                events = tree.arrays([\n                    \"Jet_pt\", \"Jet_eta\", \"Jet_phi\", \"Jet_btagDeepFlavB\",\n                    \"MET_pt\", \"MET_phi\",\n                    \"Muon_pt\", \"Muon_eta\", \"Muon_tightId\", \"Muon_pfRelIso04_all\",\n                    \"Electron_pt\", \"Electron_eta\", \"Electron_cutBased\", \"Electron_pfRelIso03_all\",\n                    \"nJet\", \"nMuon\", \"nElectron\"\n                ], entry_stop=entries_to_read, library=\"ak\")\n\n                all_events.append(events)\n\n                elapsed = time.time() - start_time\n                print(f\"   \u2713 Loaded {len(events):,} events in {elapsed:.1f}s ({len(events)/elapsed:.0f} events/s)\")\n\n            except Exception as e:\n                print(f\"   \u2717 Error: {e}\")\n                continue\n\n        if all_events:\n            self.events = ak.concatenate(all_events)\n            print(f\"\\n\u2713 SUCCESS: Loaded {len(self.events):,} total events from {len(all_events)} files\")\n        else:\n            raise ValueError(\"Failed to load any events\")\n\n    def apply_ah_baseline_selection(self):\n        \"\"\"Apply AH baseline selection (no isolated leptons, kinematic cuts)\"\"\"\n        print(\"\\n\" + \"=\"*70)\n        print(\"APPLYING AH BASELINE SELECTION\")\n        print(\"=\"*70)\n\n        # 1. Lepton veto\n        print(\"\\n1. Applying lepton veto...\")\n        lepton_veto = self.apply_lepton_veto()\n        print(f\"   Events with 0 isolated leptons: {ak.sum(lepton_veto):,} ({ak.sum(lepton_veto)/len(self.events)*100:.1f}%)\")\n\n        # 2. Jet selection\n        print(\"\\n2. Selecting jets...\")\n        self.jet_info = self.select_jets()\n\n        # 3. Calculate kinematic variables\n        print(\"\\n3. Calculating kinematic variables...\")\n        self.calculate_kinematic_variables()\n\n        # 4. Apply baseline kinematic cuts\n        print(\"\\n4. Applying kinematic cuts...\")\n        baseline_mask = self.apply_baseline_cuts(lepton_veto)\n\n        print(f\"\\n\u2713 AH Baseline selection complete\")\n        print(f\"   Events passing baseline: {ak.sum(baseline_mask):,} ({ak.sum(baseline_mask)/len(self.events)*100:.1f}%)\")\n\n        return baseline_mask\n\n    def apply_lepton_veto(self):\n        \"\"\"Veto events with isolated leptons\"\"\"\n\n        # Initialize counters\n        n_iso_muons = ak.zeros_like(self.events.MET_pt, dtype=int)\n        n_iso_electrons = ak.zeros_like(self.events.MET_pt, dtype=int)\n\n        # Muon selection: pT &gt; 10 GeV, |eta| &lt; 2.4, tight ID, isolation &lt; 0.15\n        if 'Muon_pt' in self.events.fields:\n            muon_pt = ak.fill_none(self.events.Muon_pt, 0)\n            muon_eta = ak.fill_none(self.events.Muon_eta, 100)\n            muon_tightId = ak.fill_none(self.events.Muon_tightId, 0)\n            muon_iso = ak.fill_none(self.events.Muon_pfRelIso04_all, 100)\n\n            muon_mask = (\n                (muon_pt &gt; 10) &amp; \n                (np.abs(muon_eta) &lt; 2.4) &amp;\n                (muon_tightId == 1) &amp;\n                (muon_iso &lt; 0.15)\n            )\n            n_iso_muons = ak.sum(muon_mask, axis=1)\n\n        # Electron selection: pT &gt; 10 GeV, |eta| &lt; 2.5, tight ID, isolation &lt; 0.10\n        if 'Electron_pt' in self.events.fields:\n            electron_pt = ak.fill_none(self.events.Electron_pt, 0)\n            electron_eta = ak.fill_none(self.events.Electron_eta, 100)\n            electron_cutBased = ak.fill_none(self.events.Electron_cutBased, 0)\n            electron_iso = ak.fill_none(self.events.Electron_pfRelIso03_all, 100)\n\n            electron_mask = (\n                (electron_pt &gt; 10) &amp; \n                (np.abs(electron_eta) &lt; 2.5) &amp;\n                (electron_cutBased &gt;= 3) &amp;  # 3 = Tight, 4 = SuperTight\n                (electron_iso &lt; 0.10)\n            )\n            n_iso_electrons = ak.sum(electron_mask, axis=1)\n\n        return (n_iso_muons == 0) &amp; (n_iso_electrons == 0)\n\n    def select_jets(self):\n        \"\"\"Select and count jets\"\"\"\n\n        # Basic jet selection\n        jet_pt = ak.fill_none(self.events.Jet_pt, 0)\n        jet_eta = ak.fill_none(self.events.Jet_eta, 100)\n        jet_phi = ak.fill_none(self.events.Jet_phi, 0)\n\n        # Good jets: pT &gt; 30 GeV, |eta| &lt; 2.4\n        good_jet_mask = (\n            (jet_pt &gt; self.params['jet_pt_min']) &amp;\n            (np.abs(jet_eta) &lt; self.params['jet_eta_max'])\n        )\n\n        # Count jets\n        n_jets = ak.sum(good_jet_mask, axis=1)\n\n        # Count b-jets (DeepJet medium WP)\n        if 'Jet_btagDeepFlavB' in self.events.fields:\n            btag = ak.fill_none(self.events.Jet_btagDeepFlavB, -1)\n            bjet_mask = good_jet_mask &amp; (btag &gt; self.params['bjet_wp'])\n            n_bjets = ak.sum(bjet_mask, axis=1)\n        else:\n            n_bjets = ak.zeros_like(n_jets)\n\n        print(f\"   Events with \u22654 jets: {ak.sum(n_jets &gt;= 4):,} ({ak.sum(n_jets &gt;= 4)/len(self.events)*100:.1f}%)\")\n        print(f\"   Events with \u22651 b-jets: {ak.sum(n_bjets &gt;= 1):,} ({ak.sum(n_bjets &gt;= 1)/len(self.events)*100:.1f}%)\")\n        print(f\"   Events with \u22652 b-jets: {ak.sum(n_bjets &gt;= 2):,} ({ak.sum(n_bjets &gt;= 2)/len(self.events)*100:.1f}%)\")\n\n        return {\n            'n_jets': n_jets,\n            'n_bjets': n_bjets,\n            'good_jet_mask': good_jet_mask,\n            'jet_pt': jet_pt,\n            'jet_eta': jet_eta,\n            'jet_phi': jet_phi\n        }\n\n    def calculate_kinematic_variables(self):\n        \"\"\"Calculate min\u0394\u03c6, MT, HT, and pT/HT ratio\"\"\"\n\n        print(\"   Calculating min\u0394\u03c6(j1,2, MET)...\")\n        print(\"   Calculating MT...\")\n        print(\"   Calculating HT...\")\n        print(\"   Calculating pT/HT ratio...\")\n\n        # Get jet information\n        good_jet_mask = self.jet_info['good_jet_mask']\n        jet_pt = self.jet_info['jet_pt'][good_jet_mask]\n        jet_phi = self.jet_info['jet_phi'][good_jet_mask]\n\n        # Calculate HT (scalar sum of jet pT)\n        self.HT = ak.sum(jet_pt, axis=1)\n\n        # Initialize arrays\n        n_events = len(self.events)\n        self.min_dphi = np.zeros(n_events)\n        self.MT = np.zeros(n_events)\n        self.pt_ht_ratio = np.zeros(n_events)\n\n        # Convert to numpy for faster processing\n        met_pt = ak.to_numpy(self.events.MET_pt)\n        met_phi = ak.to_numpy(self.events.MET_phi)\n        n_jets = ak.to_numpy(self.jet_info['n_jets'])\n\n        # Process each event\n        for i in range(n_events):\n            if n_jets[i] &gt;= 2:\n                # Get jets for this event\n                event_jets_pt = ak.to_numpy(jet_pt[i])\n                event_jets_phi = ak.to_numpy(jet_phi[i])\n\n                if len(event_jets_pt) &gt;= 2:\n                    # Sort by pT (descending)\n                    sorted_idx = np.argsort(event_jets_pt)[::-1]\n\n                    # Get two leading jets\n                    jet1_phi = event_jets_phi[sorted_idx[0]]\n                    jet2_phi = event_jets_phi[sorted_idx[1]]\n                    jet1_pt = event_jets_pt[sorted_idx[0]]\n\n                    # Calculate \u0394\u03c6\n                    delta_phi1 = abs(jet1_phi - met_phi[i])\n                    delta_phi2 = abs(jet2_phi - met_phi[i])\n\n                    # Normalize to [0, \u03c0]\n                    if delta_phi1 &gt; math.pi:\n                        delta_phi1 = 2*math.pi - delta_phi1\n                    if delta_phi2 &gt; math.pi:\n                        delta_phi2 = 2*math.pi - delta_phi2\n\n                    # min\u0394\u03c6\n                    self.min_dphi[i] = min(delta_phi1, delta_phi2)\n\n                    # Calculate MT (transverse mass)\n                    self.MT[i] = math.sqrt(2 * jet1_pt * met_pt[i] * (1 - math.cos(delta_phi1)))\n\n                    # Calculate pT/HT ratio\n                    if self.HT[i] &gt; 0:\n                        self.pt_ht_ratio[i] = jet1_pt / self.HT[i]\n\n        print(f\"   \u2713 Variables calculated for {n_events:,} events\")\n\n    def apply_baseline_cuts(self, lepton_veto):\n        \"\"\"Apply AH baseline cuts\"\"\"\n\n        n_jets = self.jet_info['n_jets']\n\n        # Basic AH baseline selection\n        baseline_mask = (\n            lepton_veto &amp;\n            (n_jets &gt;= 4) &amp;\n            (self.events.MET_pt &gt; self.params['met_min'])\n        )\n\n        return baseline_mask\n\n    def get_category_masks(self, baseline_mask):\n        \"\"\"Get masks for nb = 1 and nb \u2265 2 categories\"\"\"\n\n        n_bjets = self.jet_info['n_bjets']\n\n        # Events in baseline selection\n        in_baseline = baseline_mask\n\n        # Category masks\n        nb_eq_1_mask = in_baseline &amp; (n_bjets == 1)\n        nb_ge_2_mask = in_baseline &amp; (n_bjets &gt;= 2)\n\n        print(f\"\\nCategory statistics after baseline:\")\n        print(f\"   nb = 1 events: {ak.sum(nb_eq_1_mask):,}\")\n        print(f\"   nb \u2265 2 events: {ak.sum(nb_ge_2_mask):,}\")\n\n        return nb_eq_1_mask, nb_ge_2_mask\n\n    def plot_optimization_distributions(self, nb_eq_1_mask, nb_ge_2_mask):\n        \"\"\"\n        Create the 5 optimization plots as shown in the paper\n        \"\"\"\n        print(\"\\n\" + \"=\"*70)\n        print(\"GENERATING AH OPTIMIZATION PLOTS\")\n        print(\"=\"*70)\n\n        # Create figure with 2x3 layout (5 plots + 1 empty)\n        fig = plt.figure(figsize=(16, 12))\n\n        # Define subplot positions\n        ax1 = plt.subplot(2, 3, 1)  # (a) min\u0394\u03c6 for nb = 1\n        ax2 = plt.subplot(2, 3, 2)  # (b) MT for nb = 1\n        ax3 = plt.subplot(2, 3, 4)  # (c) min\u0394\u03c6 for nb \u2265 2\n        ax4 = plt.subplot(2, 3, 5)  # (d) MT for nb \u2265 2\n        ax5 = plt.subplot(2, 3, 6)  # (e) pT/HT for nb \u2265 2\n\n        # Top-right subplot is empty for title\n        ax_empty = plt.subplot(2, 3, 3)\n        ax_empty.axis('off')\n\n        # Get data for each category\n        min_dphi_nb1 = self.min_dphi[ak.to_numpy(nb_eq_1_mask)]\n        mt_nb1 = self.MT[ak.to_numpy(nb_eq_1_mask)]\n\n        min_dphi_nb2 = self.min_dphi[ak.to_numpy(nb_ge_2_mask)]\n        mt_nb2 = self.MT[ak.to_numpy(nb_ge_2_mask)]\n        pt_ht_nb2 = self.pt_ht_ratio[ak.to_numpy(nb_ge_2_mask)]\n\n        # Filter out zeros\n        min_dphi_nb1 = min_dphi_nb1[min_dphi_nb1 &gt; 0]\n        mt_nb1 = mt_nb1[mt_nb1 &gt; 0]\n        min_dphi_nb2 = min_dphi_nb2[min_dphi_nb2 &gt; 0]\n        mt_nb2 = mt_nb2[mt_nb2 &gt; 0]\n        pt_ht_nb2 = pt_ht_nb2[pt_ht_nb2 &gt; 0]\n\n        # Plot (a): min\u0394\u03c6 for nb = 1\n        print(\"Plotting (a) min\u0394\u03c6 for nb = 1...\")\n        if len(min_dphi_nb1) &gt; 0:\n            ax1.hist(min_dphi_nb1, bins=50, range=(0, 3.2),\n                    histtype='step', linewidth=2, color='blue',\n                    density=True)\n            ax1.axvline(self.params['min_dphi'], color='red', linestyle='--',\n                       linewidth=1.5, alpha=0.8, label=f'Cut: &gt;{self.params[\"min_dphi\"]} rad')\n            ax1.legend(loc='upper right')\n\n        ax1.set_xlabel(r'min$\\Delta\\phi(j_{1,2}, p_T^{miss})$ [rad]')\n        ax1.set_ylabel('Normalized Events')\n        ax1.set_title(r'(a) min$\\Delta\\phi(j_{1,2}, p_T^{miss})$ for $n_b = 1$')\n        ax1.grid(True, alpha=0.3)\n        ax1.text(0.05, 0.95, f'Entries: {len(min_dphi_nb1):,}',\n                transform=ax1.transAxes, fontsize=10,\n                verticalalignment='top',\n                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n        # Plot (b): MT for nb = 1\n        print(\"Plotting (b) MT for nb = 1...\")\n        if len(mt_nb1) &gt; 0:\n            ax2.hist(mt_nb1, bins=50, range=(0, 500),\n                    histtype='step', linewidth=2, color='green',\n                    density=True)\n            ax2.axvline(self.params['mt_min'], color='red', linestyle='--',\n                       linewidth=1.5, alpha=0.8, label=f'Cut: &gt;{self.params[\"mt_min\"]} GeV')\n            ax2.legend(loc='upper right')\n\n        ax2.set_xlabel(r'$M_T$ [GeV]')\n        ax2.set_ylabel('Normalized Events')\n        ax2.set_title(r'(b) $M_T$ for $n_b = 1$')\n        ax2.grid(True, alpha=0.3)\n        ax2.text(0.05, 0.95, f'Entries: {len(mt_nb1):,}',\n                transform=ax2.transAxes, fontsize=10,\n                verticalalignment='top',\n                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n        # Plot (c): min\u0394\u03c6 for nb \u2265 2\n        print(\"Plotting (c) min\u0394\u03c6 for nb \u2265 2...\")\n        if len(min_dphi_nb2) &gt; 0:\n            ax3.hist(min_dphi_nb2, bins=50, range=(0, 3.2),\n                    histtype='step', linewidth=2, color='red',\n                    density=True)\n            ax3.axvline(self.params['min_dphi'], color='blue', linestyle='--',\n                       linewidth=1.5, alpha=0.8, label=f'Cut: &gt;{self.params[\"min_dphi\"]} rad')\n            ax3.legend(loc='upper right')\n\n        ax3.set_xlabel(r'min$\\Delta\\phi(j_{1,2}, p_T^{miss})$ [rad]')\n        ax3.set_ylabel('Normalized Events')\n        ax3.set_title(r'(c) min$\\Delta\\phi(j_{1,2}, p_T^{miss})$ for $n_b \\geq 2$')\n        ax3.grid(True, alpha=0.3)\n        ax3.text(0.05, 0.95, f'Entries: {len(min_dphi_nb2):,}',\n                transform=ax3.transAxes, fontsize=10,\n                verticalalignment='top',\n                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n        # Plot (d): MT for nb \u2265 2\n        print(\"Plotting (d) MT for nb \u2265 2...\")\n        if len(mt_nb2) &gt; 0:\n            ax4.hist(mt_nb2, bins=50, range=(0, 500),\n                    histtype='step', linewidth=2, color='purple',\n                    density=True)\n            ax4.axvline(self.params['mt_min'], color='blue', linestyle='--',\n                       linewidth=1.5, alpha=0.8, label=f'Cut: &gt;{self.params[\"mt_min\"]} GeV')\n            ax4.legend(loc='upper right')\n\n        ax4.set_xlabel(r'$M_T$ [GeV]')\n        ax4.set_ylabel('Normalized Events')\n        ax4.set_title(r'(d) $M_T$ for $n_b \\geq 2$')\n        ax4.grid(True, alpha=0.3)\n        ax4.text(0.05, 0.95, f'Entries: {len(mt_nb2):,}',\n                transform=ax4.transAxes, fontsize=10,\n                verticalalignment='top',\n                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n        # Plot (e): pT/HT for nb \u2265 2\n        print(\"Plotting (e) pT/HT for nb \u2265 2...\")\n        if len(pt_ht_nb2) &gt; 0:\n            ax5.hist(pt_ht_nb2, bins=50, range=(0, 1),\n                    histtype='step', linewidth=2, color='orange',\n                    density=True)\n            ax5.axvline(self.params['pt_ht_ratio_max'], color='red', linestyle='--',\n                       linewidth=1.5, alpha=0.8, label=f'Cut: &lt;{self.params[\"pt_ht_ratio_max\"]}')\n            ax5.legend(loc='upper right')\n\n        ax5.set_xlabel(r'$p_T^{jet1} / H_T$')\n        ax5.set_ylabel('Normalized Events')\n        ax5.set_title(r'(e) $p_T^{jet1} / H_T$ for $n_b \\geq 2$')\n        ax5.grid(True, alpha=0.3)\n        ax5.text(0.05, 0.95, f'Entries: {len(pt_ht_nb2):,}',\n                transform=ax5.transAxes, fontsize=10,\n                verticalalignment='top',\n                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n        # Add main title\n        ax_empty.text(0.5, 0.5, 'AH Optimization Distributions\\n(after baseline selection)\\n' +\n                     'TTToSemiLeptonic MC\\n' +\n                     f'Total events: {len(self.events):,}',\n                     horizontalalignment='center',\n                     verticalalignment='center',\n                     transform=ax_empty.transAxes,\n                     fontsize=14, fontweight='bold')\n\n        # Add statistics box\n        stats_text = (\n            f'AH Baseline Selection:\\n'\n            f'\u2022 0 isolated leptons\\n'\n            f'\u2022 \u22654 jets (pT &gt; 30 GeV)\\n'\n            f'\u2022 MET &gt; 30 GeV\\n'\n            f'\u2022 nb = 1: {ak.sum(nb_eq_1_mask):,} events\\n'\n            f'\u2022 nb \u2265 2: {ak.sum(nb_ge_2_mask):,} events'\n        )\n\n        fig.text(0.02, 0.02, stats_text, fontsize=10,\n                verticalalignment='bottom',\n                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n\n        plt.tight_layout()\n\n        # Save figure\n        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n        output_file = f'ah_optimization_plots_{timestamp}.png'\n        plt.savefig(output_file, dpi=150, bbox_inches='tight')\n        print(f\"\\n\u2713 Plots saved to: {output_file}\")\n\n        plt.show()\n\n        # Also create summary statistics plot\n        self.plot_summary_statistics(nb_eq_1_mask, nb_ge_2_mask)\n\n    def plot_summary_statistics(self, nb_eq_1_mask, nb_ge_2_mask):\n        \"\"\"Create additional summary plots\"\"\"\n\n        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n        # 1. Event counts by category\n        categories = ['nb = 1', 'nb \u2265 2', 'Total Baseline']\n        counts = [\n            ak.sum(nb_eq_1_mask),\n            ak.sum(nb_ge_2_mask),\n            ak.sum(nb_eq_1_mask) + ak.sum(nb_ge_2_mask)\n        ]\n\n        bars = axes[0, 0].bar(categories, counts, \n                             color=['skyblue', 'lightgreen', 'salmon'],\n                             edgecolor='black')\n        axes[0, 0].set_ylabel('Number of Events')\n        axes[0, 0].set_title('Event Counts by Category')\n        axes[0, 0].grid(True, alpha=0.3, axis='y')\n\n        for i, (bar, count) in enumerate(zip(bars, counts)):\n            axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(counts)*0.01,\n                          f'{count:,}', ha='center', va='bottom', fontsize=11)\n\n        # 2. MET distribution comparison\n        if ak.sum(nb_eq_1_mask) &gt; 0:\n            met_nb1 = ak.to_numpy(self.events.MET_pt[nb_eq_1_mask])\n            axes[0, 1].hist(met_nb1, bins=40, range=(0, 400), histtype='step',\n                          linewidth=2, color='blue', density=True, label='nb = 1')\n\n        if ak.sum(nb_ge_2_mask) &gt; 0:\n            met_nb2 = ak.to_numpy(self.events.MET_pt[nb_ge_2_mask])\n            axes[0, 1].hist(met_nb2, bins=40, range=(0, 400), histtype='step',\n                          linewidth=2, color='red', density=True, label='nb \u2265 2')\n\n        axes[0, 1].set_xlabel(r'$p_T^{miss}$ [GeV]')\n        axes[0, 1].set_ylabel('Normalized Events')\n        axes[0, 1].set_title(r'$p_T^{miss}$ Distribution by Category')\n        axes[0, 1].legend()\n        axes[0, 1].grid(True, alpha=0.3)\n\n        # 3. HT distribution\n        if ak.sum(nb_eq_1_mask) &gt; 0:\n            ht_nb1 = self.HT[ak.to_numpy(nb_eq_1_mask)]\n            axes[1, 0].hist(ht_nb1, bins=50, range=(0, 1500), histtype='step',\n                          linewidth=2, color='blue', density=True, label='nb = 1')\n\n        if ak.sum(nb_ge_2_mask) &gt; 0:\n            ht_nb2 = self.HT[ak.to_numpy(nb_ge_2_mask)]\n            axes[1, 0].hist(ht_nb2, bins=50, range=(0, 1500), histtype='step',\n                          linewidth=2, color='red', density=True, label='nb \u2265 2')\n\n        axes[1, 0].set_xlabel(r'$H_T$ [GeV]')\n        axes[1, 0].set_ylabel('Normalized Events')\n        axes[1, 0].set_title(r'$H_T$ Distribution by Category')\n        axes[1, 0].legend()\n        axes[1, 0].grid(True, alpha=0.3)\n\n        # 4. Jet multiplicity\n        n_jets_nb1 = ak.to_numpy(self.jet_info['n_jets'][nb_eq_1_mask])\n        n_jets_nb2 = ak.to_numpy(self.jet_info['n_jets'][nb_ge_2_mask])\n\n        axes[1, 1].hist([n_jets_nb1, n_jets_nb2], bins=range(4, 16),\n                       histtype='step', linewidth=2, density=True,\n                       label=['nb = 1', 'nb \u2265 2'], color=['blue', 'red'])\n        axes[1, 1].set_xlabel('Number of Jets')\n        axes[1, 1].set_ylabel('Normalized Events')\n        axes[1, 1].set_title('Jet Multiplicity by Category')\n        axes[1, 1].legend()\n        axes[1, 1].grid(True, alpha=0.3)\n\n        plt.suptitle('AH Analysis Summary - TTToSemiLeptonic MC', fontsize=16, fontweight='bold')\n        plt.tight_layout()\n\n        # Save summary plot\n        summary_file = f'ah_summary_plots_{time.strftime(\"%Y%m%d_%H%M%S\")}.png'\n        plt.savefig(summary_file, dpi=150, bbox_inches='tight')\n        print(f\"\u2713 Summary plots saved to: {summary_file}\")\n\n        plt.show()\n\ndef main():\n    \"\"\"Main execution function\"\"\"\n\n    print(\"=\"*70)\n    print(\"AH OPTIMIZATION ANALYSIS - CMS OPEN DATA\")\n    print(\"=\"*70)\n\n    # All remote file URLs\n    file_paths = [\n        # Original files\n        \"root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v1/120000/08FCB2ED-176B-064B-85AB-37B898773B98.root\",\n        \"root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v1/120000/0BD60695-8388-5141-B157-32AE1A3B4885.root\",\n        \"root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v1/120000/4F3C361D-258C-1D41-AEEA-48CB87D3839A.root\",\n\n        # Additional files\n        \"root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v1/120000/F6C0248E-6AC1-CE45-BEFA-56A735AA214A.root\",\n        \"root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v1/120000/FA5B9B55-06B4-A640-AF3C-7B44552E2393.root\",\n        \"root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v1/120000/FB5A9307-B677-B947-8970-21DA6BD7C9C2.root\",\n        \"root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v1/120000/1D63950A-E444-E049-BFF0-D33296A8A6CA.root\",\n        \"root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v1/120000/FFA621C8-C16B-5740-AB60-84246D9B2FD1.root\",\n        \"root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v1/120000/2D439FBF-CF8D-654F-93B1-2F7D0A74B0CB.root\",\n        \"root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v1/120000/2E85B521-A37E-0044-8662-BFB0C1291422.root\",\n        \"root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v1/120000/301EA765-5A14-1B43-ADED-D3BE6147134B.root\"\n    ]\n\n    print(f\"\\n\ud83d\udcca Total files to process: {len(file_paths)}\")\n\n    try:\n        # Initialize analyzer\n        analyzer = AHOptimizationAnalyzer(file_paths)\n\n        # Load events (limit to 10,000 per file for reasonable runtime)\n        print(\"\\n\u23f3 Loading events (this may take several minutes)...\")\n        analyzer.load_events(max_events_per_file=10000)\n\n        # Apply AH baseline selection\n        baseline_mask = analyzer.apply_ah_baseline_selection()\n\n        # Get category masks\n        nb_eq_1_mask, nb_ge_2_mask = analyzer.get_category_masks(baseline_mask)\n\n        # Generate optimization plots\n        analyzer.plot_optimization_distributions(nb_eq_1_mask, nb_ge_2_mask)\n\n        # Print final summary\n        print(\"\\n\" + \"=\"*70)\n        print(\"ANALYSIS COMPLETE\")\n        print(\"=\"*70)\n        print(f\"\\n\ud83d\udcc8 FINAL STATISTICS:\")\n        print(f\"   Total events processed: {len(analyzer.events):,}\")\n        print(f\"   Events in baseline selection: {ak.sum(baseline_mask):,}\")\n        print(f\"   nb = 1 events: {ak.sum(nb_eq_1_mask):,}\")\n        print(f\"   nb \u2265 2 events: {ak.sum(nb_ge_2_mask):,}\")\n        print(f\"\\n\u2705 Plots have been generated and saved to disk\")\n\n    except Exception as e:\n        print(f\"\\n\u274c Error: {e}\")\n        print(\"\\n\ud83d\udca1 Troubleshooting tips:\")\n        print(\"   1. Check internet connection\")\n        print(\"   2. Try with fewer files first\")\n        print(\"   3. Reduce max_events_per_file parameter\")\n        print(\"   4. Ensure all dependencies are installed:\")\n        print(\"      pip install uproot awkward numpy matplotlib\")\n        import traceback\n        traceback.print_exc()\n\nif __name__ == \"__main__\":\n    # Start timer\n    start_time = time.time()\n\n    # Run analysis\n    main()\n\n    # Print execution time\n    elapsed = time.time() - start_time\n    print(f\"\\n\u23f1\ufe0f  Total execution time: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n</code></pre>"},{"location":"All_Hadronic/all%20hadronic%20si/#step-2-run-the-analysis","title":"Step 2: Run the Analysis","text":"<pre><code># Execute the analysis script\npython ah_optimization_analysis.py\n</code></pre>"},{"location":"All_Hadronic/all%20hadronic%20si/#expected-output","title":"Expected Output","text":"<p>You will get a result output similar to this: </p>"},{"location":"All_Hadronic/all%20hadronic%20si/#console-output","title":"Console Output","text":"<p>The script will display progress messages for each step:</p> <ol> <li>Loading phase: Shows progress for each file with loading speed</li> <li>Selection phase: Displays statistics after each cut</li> <li>Plotting phase: Confirms generation of each plot</li> <li>Final statistics: Summary of events processed</li> </ol>"},{"location":"All_Hadronic/all%20hadronic%20si/#generated-files","title":"Generated Files","text":"<p>Two PNG files will be created with timestamps:</p> <ol> <li>Main optimization plots (<code>ah_optimization_plots_YYYYMMDD_HHMMSS.png</code>):</li> <li>5 plots in 2\u00d73 layout matching the paper</li> <li>Normalized distributions</li> <li>Cut lines shown</li> <li> <p>Event counts displayed</p> </li> <li> <p>Summary plots (<code>ah_summary_plots_YYYYMMDD_HHMMSS.png</code>):</p> </li> <li>Event counts by category</li> <li>MET distribution comparison</li> <li>HT distribution comparison</li> <li>Jet multiplicity</li> </ol>"},{"location":"All_Hadronic/all%20hadronic%20si/#analysis-parameters","title":"Analysis Parameters","text":""},{"location":"All_Hadronic/all%20hadronic%20si/#selection-criteria_1","title":"Selection Criteria","text":"Parameter Value Description Jet pT &gt; 30 GeV Minimum transverse momentum Jet \u03b7 b-tagging WP 0.2783 DeepJet medium working point MET &gt; 30 GeV Missing transverse momentum min\u0394\u03c6 cut &gt; 1.0 rad Minimum angle between jets and MET MT cut &gt; 180 GeV Transverse mass cut pT/HT cut &lt; 0.5 Ratio for nb \u2265 2 category"},{"location":"All_Hadronic/all%20hadronic%20si/#event-categories","title":"Event Categories","text":"<ul> <li>nb = 1: Events with exactly 1 b-tagged jet</li> <li>nb \u2265 2: Events with 2 or more b-tagged jets</li> </ul>"},{"location":"All_Hadronic/all%20hadronic%20si/#troubleshooting","title":"Troubleshooting","text":""},{"location":"All_Hadronic/all%20hadronic%20si/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"All_Hadronic/all%20hadronic%20si/#1-connection-errors","title":"1. Connection Errors","text":"<pre><code># If XRootD connection fails, try:\n# Option A: Reduce number of files\nfile_paths = file_paths[:3]  # Use only first 3 files\n\n# Option B: Reduce events per file\nanalyzer.load_events(max_events_per_file=1000)\n</code></pre>"},{"location":"All_Hadronic/all%20hadronic%20si/#2-memory-issues","title":"2. Memory Issues","text":"<pre><code># Reduce memory usage:\n# 1. Process fewer events\nanalyzer.load_events(max_events_per_file=5000)\n\n# 2. Use fewer files initially\nfile_paths = file_paths[:5]\n</code></pre>"},{"location":"All_Hadronic/all%20hadronic%20si/#3-slow-performance","title":"3. Slow Performance","text":"<ul> <li>The analysis processes ~110,000 events from 11 files</li> <li>Expected runtime: 10-30 minutes depending on connection</li> <li>For faster testing, reduce <code>max_events_per_file</code> to 1000</li> </ul>"},{"location":"All_Hadronic/all%20hadronic%20si/#understanding-the-output-plots","title":"Understanding the Output Plots","text":""},{"location":"All_Hadronic/all%20hadronic%20si/#plot-a-minj12-ptmiss-for-nb-1","title":"Plot (a): min\u0394\u03c6(j\u2081,\u2082, p\u209c\u1d50\u2071\u02e2\u02e2) for nb = 1","text":"<ul> <li>Purpose: Show angular separation between leading jets and MET</li> <li>Interpretation: QCD multijet background tends to have small \u0394\u03c6</li> <li>Cut: Events with min\u0394\u03c6 &gt; 1.0 rad are selected</li> </ul>"},{"location":"All_Hadronic/all%20hadronic%20si/#plot-b-mt-for-nb-1","title":"Plot (b): M\u209c for nb = 1","text":"<ul> <li>Purpose: Transverse mass distribution</li> <li>Interpretation: Signal events have larger MT values</li> <li>Cut: Events with MT &gt; 180 GeV are selected</li> </ul>"},{"location":"All_Hadronic/all%20hadronic%20si/#plot-c-minj12-ptmiss-for-nb-2","title":"Plot (c): min\u0394\u03c6(j\u2081,\u2082, p\u209c\u1d50\u2071\u02e2\u02e2) for nb \u2265 2","text":"<ul> <li>Same as (a) but for events with \u22652 b-jets</li> </ul>"},{"location":"All_Hadronic/all%20hadronic%20si/#plot-d-mt-for-nb-2","title":"Plot (d): M\u209c for nb \u2265 2","text":"<ul> <li>Same as (b) but for events with \u22652 b-jets</li> </ul>"},{"location":"All_Hadronic/all%20hadronic%20si/#plot-e-ptjet1-ht-for-nb-2","title":"Plot (e): p\u209c\u02b2\u1d49\u1d57\u00b9 / H\u209c for nb \u2265 2","text":"<ul> <li>Purpose: Ratio of leading jet pT to total hadronic activity</li> <li>Interpretation: Signal events have more balanced jet energy distribution</li> <li>Cut: Events with ratio &lt; 0.5 are selected</li> </ul>"},{"location":"All_Hadronic/all%20hadronic%20si/#physics-context","title":"Physics Context","text":""},{"location":"All_Hadronic/all%20hadronic%20si/#all-hadronic-channel-characteristics","title":"All-Hadronic Channel Characteristics","text":"<ul> <li>Branching ratio: ~46% (highest for tt\u0304)</li> <li>Background: Dominated by QCD multijet production</li> <li>Challenges: MET can be faked by jet mismeasurement</li> <li>Advantages: Maximum statistical power</li> </ul>"},{"location":"All_Hadronic/all%20hadronic%20si/#optimization-strategy","title":"Optimization Strategy","text":"<p>The cuts shown in the plots are optimized to: 1. Suppress QCD background using angular correlations (min\u0394\u03c6) 2. Enhance signal using transverse mass (MT) 3. Further discriminate signal using jet energy balance (pT/HT)</p>"},{"location":"All_Hadronic/all%20hadronic%20si/#customization-options","title":"Customization Options","text":""},{"location":"All_Hadronic/all%20hadronic%20si/#modify-selection-criteria","title":"Modify Selection Criteria","text":"<pre><code># In the __init__ method, modify parameters:\nself.params = {\n    'jet_pt_min': 40,  # Increase jet pT threshold\n    'met_min': 50,     # Increase MET threshold\n    'min_dphi': 0.8,   # Relax angular cut\n    'mt_min': 200,     # Increase MT cut\n}\n</code></pre>"},{"location":"All_Hadronic/all%20hadronic%20si/#add-additional-plots","title":"Add Additional Plots","text":"<pre><code>def plot_additional_variables(self, nb_eq_1_mask, nb_ge_2_mask):\n    \"\"\"Add custom plots\"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n    # Plot b-jet multiplicity\n    n_bjets_nb1 = ak.to_numpy(self.jet_info['n_bjets'][nb_eq_1_mask])\n    n_bjets_nb2 = ak.to_numpy(self.jet_info['n_bjets'][nb_ge_2_mask])\n\n    # Your custom plotting code here\n</code></pre>"},{"location":"All_Hadronic/all%20hadronic%20si/#performance-notes","title":"Performance Notes","text":""},{"location":"All_Hadronic/all%20hadronic%20si/#expected-resource-usage","title":"Expected Resource Usage","text":"<ul> <li>Memory: ~2-4 GB for 100,000 events</li> <li>Time: 10-30 minutes for full analysis</li> <li>Network: ~500 MB data transfer from CERN servers</li> </ul>"},{"location":"All_Hadronic/all%20hadronic%20si/#optimization-tips","title":"Optimization Tips","text":"<ol> <li>For development, use fewer files: <code>file_paths[:3]</code></li> <li>For quick tests, reduce events: <code>max_events_per_file=1000</code></li> <li>Save intermediate results to avoid re-downloading</li> </ol>"},{"location":"All_Hadronic/all%20hadronic%20si/#citation-and-references","title":"Citation and References","text":""},{"location":"All_Hadronic/all%20hadronic%20si/#data-source","title":"Data Source","text":"<pre><code>@misc{cms_opendata_2024,\n  title = {Simulated dataset TTToSemiLeptonic in NANOAODSIM format},\n  author = {CMS Collaboration},\n  year = {2024},\n  doi = {10.7483/OPENDATA.CMS.4J3Y.1CME},\n  url = {https://opendata.cern.ch/record/67993}\n}\n</code></pre>"},{"location":"All_Hadronic/all%20hadronic%20si/#related-papers","title":"Related Papers","text":"<ul> <li>CMS Collaboration, \"Search for dark matter produced in association with a single top quark or a top quark pair in proton-proton collisions at \u221as = 13 TeV\", JHEP 03 (2019) 141</li> <li>Original analysis methodology from arXiv:1901.01553</li> </ul>"},{"location":"All_Hadronic/all%20hadronic%20si/#support","title":"Support","text":"<p>For issues or questions: 1. Check the console error messages 2. Verify internet connectivity to CERN servers 3. Ensure all Python packages are up to date 4. Consult the CMS Open Data documentation</p> <p>This complete guide provides everything needed to reproduce the AH optimization plots using CMS Open Data. The analysis follows the same methodology as the original CMS paper while being accessible through public data and open-source tools.</p>"},{"location":"Single_Lepton/Analisis_muon_final_version/","title":"Advances of the Project","text":""},{"location":"Single_Lepton/Analisis_muon_final_version/#title-objective","title":"Title / Objective:","text":"<p>Reproducible Analysis of CMS Open Data: Search for Dark Matter in Association with Top Quarks (Based on the CMS publication: \u201cSearch for dark matter produced in association with a single top quark or a top quark pair in proton\u2013proton collisions at (\\(\\sqrt s = 13 \\TeV\\)\u201d).</p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#physics-motivation-and-channel-strategy","title":"Physics Motivation and Channel Strategy","text":"<p>The Large Hadron Collider (LHC) collides protons at center-of-mass energies high enough to probe physics beyond the Standard Model. Although the protons are composite objects, the relevant hard scatterings occur between their constituents \u2014 quarks and gluons. In the context of simplified dark matter models, these partonic interactions can produce top quarks together with a new mediator particle (commonly denoted \u03c6 for scalar or a for pseudoscalar). The mediator then decays invisibly into a pair of dark matter candidates (\\(\\chi \\bar{\\chi}\\)). At the detector level, this results in events with multiple top quarks plus significant missing transverse momentum (\\(p_T^{\\text{miss}}\\)), the latter coming from both neutrinos and the invisible \u03c7 particles.</p> <p>The production mechanisms of interest include:  </p> <ul> <li> <p>Gluon fusion:   $$ gg \\to t \\bar{t}\\,\\phi \\to t \\bar{t} + \\chi \\bar{\\chi} $$  </p> </li> <li> <p>Single top associated production:   $$ gb \\to t \\phi \\to t + \\chi \\bar{\\chi} $$  </p> </li> <li> <p>t\u2013channel production:   $$ qq' \\to tb \\phi \\to tb + \\chi \\bar{\\chi} $$  </p> </li> </ul> <p>In all cases, the top quarks decay via \\(t \\to W b\\). Each W boson subsequently decays either leptonically (\\(W \\to \\ell \\nu\\)) or hadronically (\\(W \\to q \\bar{q}'\\)). Thus, the final states contain a mixture of b-tagged jets, light-flavor jets, charged leptons (electrons or muons), and genuine \\(p_T^{\\text{miss}}\\). The specific experimental signature depends strongly on the decay mode of the W bosons.</p> <p>Because of this, analyses are divided into channels, each defined by the number of isolated charged leptons:</p> <ul> <li>Single-lepton (SL): one isolated electron or muon, several jets (including \u22651 b-tag), and nonzero \\(p_T^{\\text{miss}}\\). This channel is statistically powerful and relatively clean, striking a balance between signal sensitivity and manageable backgrounds.  </li> <li>All-hadronic (AH): no isolated leptons, many jets including b-tagged jets, and \\(p_T^{\\text{miss}}\\). While it has the largest raw yield, it suffers from overwhelming QCD multijet background, which can fake \\(p_T^{\\text{miss}}\\).  </li> <li>Dilepton: two isolated leptons, large \\(p_T^{\\text{miss}}\\), and multiple jets. It provides a very clean signal region but is limited by low branching fraction, hence low statistics.</li> </ul> <p>In this notebook, we concentrate on the single-lepton channel with exactly one muon. There are both theoretical and practical reasons for this choice. From the physics side, the SL channel has the right compromise: it suppresses pure QCD while retaining enough events to make meaningful comparisons. From the experimental side, single-muon triggers are robust, well understood in CMS, and ensure efficient data collection. This focus allows us to demonstrate the full workflow \u2014 from event selection to histograms \u2014 in a setting where the interplay between signal characteristics and background processes can be clearly explained. Splitting into channels is therefore not a stylistic decision but a physics necessity: each final state probes the same underlying processes under different background conditions and detector signatures.</p> <p>After defining the objective of the project (Reproducible Analysis of CMS Open Data), we discussed in which data format to work \u2014 NanoAOD or MiniAOD. We decided to use NanoAOD, because it is lighter and optimized for analysis tasks.</p> <p>In the most precise version, we work within cernbox/swan, but it can work in any Jupyter environment; the important packages are: uproot and awkward</p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#single-lepton","title":"Single Lepton","text":"<p>We import all the libraries that we are going to use.</p> <pre><code>%load_ext autoreload\n%autoreload 2\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport hist\n\n\nimport requests\nimport os\nimport time\nimport json\n\n\nimport awkward as ak\nimport uproot\nimport vector\nvector.register_awkward()\n\n\n</code></pre> <pre><code>Matplotlib is building the font cache; this may take a moment.\n</code></pre> <p>We will use the dpoa_workshop_utilities module to help you access the datasets. The functions it contains are:</p> <p>The <code>nanoaod_filenames</code> is a dictionary with the urls to the file indexes of the root files for every dataset that we will use in the analysis.</p> <p>The <code>pretty_print(fields, fmt='40s', require=None, ignore=None)</code> function allows you to print subsets of keys based on strings that you require or ignore. It will also format that output based on how many characters you want in a column (you are limited to 80 characters per line).</p> <p>The <code>build_lumi_mask(lumifile, tree, verbose=False)</code> function helps you mask (select) the data that's collected from collisions.</p> <pre><code>#-------------------------------\n\nimport dpoa_workshop\nfrom dpoa_workshop import (\n    nanoaod_filenames,\n    get_files_for_dataset,\n    pretty_print,\n    build_lumi_mask\n)\n#-------------------------------------------\n</code></pre> <p>In the drafts related to the papers, the datasets used from 2016 are listed along with their run periods and corresponding luminosities. However, one must be careful with these values, because not all periods are available and the data format differs from the one originally used, as previously noted.\u201d</p> <pre><code>from IPython.display import Image, display\n\ndisplay(Image(filename=\"dataset_2016.png\"))\n\n</code></pre> <p></p> <pre><code>\ndisplay(Image(filename=\"MC_data.png\"))\n\n</code></pre> <p></p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#building-the-ntuple-file-index","title":"Building the Ntuple File Index","text":"<p>CMS Open Data provides file index text files (<code>file_index.txt</code>) for each dataset. These contain the actual XRootD paths to the NanoAOD <code>.root</code> files, along with metadata such as the number of events per file. Example line:</p> <p>root://eospublic.cern.ch//eos/opendata/cms/mc/.../nano_1.root nevts=58293</p> <p>The objective is to collect file paths from multiple URLs, organize them by dataset, and store them in a JSON file, while handling possible download errors so the program keeps running.</p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#to-streamline-the-workflow","title":"To streamline the workflow:","text":"<ul> <li>We define a function <code>download_files(url)</code> that fetches each <code>file_index.txt</code> via HTTP and extracts only the ROOT file paths.  </li> <li>We loop over all entries in <code>nanoaod_filenames</code> (the dictionary we built earlier) and collect the full list of ROOT files per dataset.  </li> <li>The result is stored in a new dictionary <code>ntuples</code>, which maps dataset -- list of ROOT file paths.  </li> <li>Finally, we save this as a JSON file (<code>ntuples.json</code>) for later reuse</li> </ul> <pre><code>def download_files(url):\n    r = requests.get(url)\n    lines = [ln.strip() for ln in r.text.splitlines() if ln.strip()]\n\n    paths = [ln.split()[0] for ln in lines]\n    return paths\n\nntuples = {}\n\nfor dataset, urls in nanoaod_filenames.items():\n    all_paths = []\n    for url in urls:\n        try:\n            all_paths.extend(download_files(url))\n        except Exception as e:\n            print(f\"[warn] {dataset} {url}--{e}\")\n    ntuples[dataset] = all_paths\n\nwith open(\"ntuples.json\", \"w\") as f:\n    json.dump(ntuples, f, indent=2)\n\nprint(\"ntuples.json :\", list(ntuples.keys()))\n\n</code></pre> <pre><code>ntuples.json : ['met', 'SingleMuon', 'SingleElectron', 'ttbar-semileptonic', 'ttbar-hadronic', 't-channel-top', 'ttW', 'WJets-HT400to600', 'DYJets-Zpt200', 'WW', 'ZZ', 'Zvv']\n</code></pre> <p>And we will download important files like the luminosity file.</p> <pre><code>!wget https://opendata.cern.ch/record/14220/files/Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt\n\n</code></pre> <pre><code>--2025-11-05 20:43:37--  https://opendata.cern.ch/record/14220/files/Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt\nResolving opendata.cern.ch (opendata.cern.ch)... 137.138.6.31, 2001:1458:201:8b::100:1c8\nConnecting to opendata.cern.ch (opendata.cern.ch)|137.138.6.31|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 11686 (11K) [text/plain]\nSaving to: \u2018Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt\u2019\n\nCert_271036-284044_ 100%[===================&gt;]  11.41K  --.-KB/s    in 0.001s\n\n2025-11-05 20:43:38 (10.2 MB/s) - \u2018Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt\u2019 saved [11686/11686]\n</code></pre> <p>Complete dictionary, in case it's possible to add all the events but it hasn't been found or verified yet...</p> <pre><code>    # --- Cross sections in pb de todo los dataset del paper ---\n\nXSEC2_PB = {\n    # --- TOP QUARK ---\n    \"ttbar-semileptonic\": 364.35,  \n    \"t-channel-top\": 136.02,       # ST t-channel top\n    \"t-channel-antitop\": 80.95,    # ST t-channel antitop\n    \"tW-top\": 35.85,               # ST tW top \n\n    # --- Rare Top ---\n    \"ttW\": 0.2043,  #  to TTWJetsToLNu\n    \"ttZ\": 0.2529,  # to TTZToLLNuNu\n\n    # --- WJETS (HT Binned) ---\n\n    \"WJets-HT70to100\":    1372.0,\n    \"WJets-HT100to200\":   1345.0, # (Revisa este valor, parece alto para ser binned, quiz\u00e1s es LO)\n    \"WJets-HT200to400\":   359.7,  \n    \"WJets-HT400to600\":   48.91,  \n    \"WJets-HT600to800\":   12.05,\n    \"WJets-HT800to1200\":  5.501,  \n    \"WJets-HT1200to2500\": 1.329,  \n    \"WJets-HT2500toInf\":  0.0322,\n\n    # --- DRELL-YAN (DY) ---\n    \"DYJets-HT100to200\": 147.40,\n    \"DYJets-HT200to400\": 40.99,\n    \"DYJets-HT400to600\": 5.678,\n\n    # --- DIBOSON ---\n    \"WW\": 118.7, #   sumados dan aprox esto\n    \"ZZ\": 16.6,  # \n    \"WZ\": 47.13  \n}\n</code></pre> <p>until while these datasets are being used</p> <pre><code>    XSEC_PB = {\n    # --- Top Quark ---\n    \"ttbar-semileptonic\": 364.35,   \n    \"ttbar-hadronic\":     377.96,  \n    \"t-channel-top\":      136.02,   \n    \"ttW\":                0.2043,   \n\n    # --- WJets ---\n    \"WJets-HT400to600\":   48.91, \n\n    # --- Electroweak / Bosons ---\n    \"DYJets-Zpt200\":      1.27,     \n    \"WW\":                 118.7,    \n    \"ZZ\":                 16.6,     \n    \"Zvv\":                77.3,     \n}\n\n</code></pre> <p>This function builds the fileset used by the analysis. It reads the JSON inventory of ntuples, identifies which samples are data or MC, applies an optional file limit for fast debugging, and attaches minimal metadata such as the cross section and number of files. The output is a clean, ready-to-use dictionary that tells the processor exactly which datasets to run over and how they should be treated.</p> <pre><code>def construct_fileset(ntuples_json=\"ntuples.json\", limit=None, verbose=True):\n    \"\"\"\n    Parses the input JSON inventory and assigns metadata (xsec, is_data).\n\n    Args:\n        ntuples_json (str): Path to the JSON file containing the file lists.\n        limit (int or None): Max number of files to load per process. \n                             Useful for quick debugging (e.g., limit=1).\n                             If None, loads all files (production mode).\n        verbose (bool): If True, prints a summary table of loaded samples.\n\n    Returns:\n        dict: A dictionary structured for the processor (Coffea/UpRoot).\n    \"\"\"\n\n    # Load the file manifest\n    with open(ntuples_json) as f:\n        info = json.load(f)\n\n    fileset = {}\n\n    if verbose:\n        print(f\"\\n{'Process Name':30} {'Type':&gt;6} {'N Files':&gt;10} {'XSEC [pb]':&gt;12}\")\n        print(\"-\" * 65)\n\n    # Iterate over each process found in the JSON\n    for process_name, file_list in info.items():\n\n        # --- A. APPLY LIMIT (DEBUG MODE) ---\n        # Slicing handles None gracefully, but explicit check is clearer for readers\n        if limit is not None:\n            files_to_use = file_list[:limit]\n        else:\n            files_to_use = file_list\n\n        # --- B. IDENTIFY TYPE (DATA vs MC) ---\n        # Logic: If process exists in the Cross-Section table, treat as Simulation (MC).\n        # Otherwise, treat as Real Data.\n        if process_name in XSEC_PB:\n            is_data = False\n            xsec_value = XSEC_PB[process_name]\n            proc_type = \"MC\"\n        else:\n            is_data = True\n            xsec_value = None  # Real data has no theoretical xsec here\n            proc_type = \"DATA\"\n\n        # --- C. BUILD DICTIONARY ---\n        # Minimal metadata structure to keep it lightweight\n        fileset[process_name] = {\n            \"files\": files_to_use,\n            \"metadata\": {\n                \"is_data\": is_data,\n                \"xsec\": xsec_value,\n                \"n_files_loaded\": len(files_to_use)\n            }\n        }\n\n        # --- D. LOGGING ---\n        if verbose:\n            xsec_str = f\"{xsec_value:.2f}\" if xsec_value else \"-\"\n            print(f\"{process_name:30} {proc_type:&gt;6} {len(files_to_use):&gt;10} {xsec_str:&gt;12}\")\n\n    if verbose: \n        print(\"-\" * 65)\n        print(f\" Fileset construction complete. Loaded {len(fileset)} processes.\")\n\n    return fileset\n</code></pre> <p>This line initializes the full list of datasets for the analysis. It loads all ntuples defined in ntuples.json (since <code>limit=None</code>) and prints a summary of the samples. The resulting <code>fileset</code> becomes the central input that tells the processor which data and MC files to process.</p> <pre><code>fileset = construct_fileset(\n    ntuples_json=\"ntuples.json\",\n    limit=None,      \n    verbose=True\n)\n</code></pre> <pre><code>Process Name                     Type    N Files    XSEC [pb]\n-----------------------------------------------------------------\nmet                              DATA         32            -\nSingleMuon                       DATA         82            -\nSingleElectron                   DATA         80            -\nttbar-semileptonic                 MC        138       364.35\nttbar-hadronic                     MC        146       377.96\nt-channel-top                      MC         25       136.02\nttW                                MC         12         0.20\nWJets-HT400to600                   MC         11        48.91\nDYJets-Zpt200                      MC         10         1.27\nWW                                 MC         41       118.70\nZZ                                 MC         17        16.60\nZvv                                MC         14        77.30\n-----------------------------------------------------------------\n Fileset construction complete. Loaded 12 processes.\n</code></pre> <p>Before running a massive analysis loop (which might take hours), a physicist always opens one single file first. We call this Exploratory Data Analysis (EDA). You need to verify:</p> <p>1.Are the files actually there?</p> <p>2.What are the variable names? (Is it Muon_pt or Muon_pT? Case matters!)</p> <p>3.What Triggers (HLT) are available?</p> <p>Here is the code organized as a clear \"Exploratory Phase\" for students.</p> <p>Why do we do this? We are about to treat the data as a \"black box\" in the processing loop. But we need to verify the inputs first. We use uproot, which is a Python library that allows us to read CERN ROOT files directly, without needing C++.</p> <pre><code>dataset = \"SingleMuon\"\n\nfor i, fpath in enumerate(fileset[dataset][\"files\"][:10]):\n    print(f\"{i+1:2d}. {fpath}\")\n\n</code></pre> <pre><code> 1. root://eospublic.cern.ch//eos/opendata/cms/Run2016H/SingleMuon/NANOAOD/UL2016_MiniAODv2_NanoAODv9-v1/120000/61FC1E38-F75C-6B44-AD19-A9894155874E.root\n 2. root://eospublic.cern.ch//eos/opendata/cms/Run2016H/SingleMuon/NANOAOD/UL2016_MiniAODv2_NanoAODv9-v1/1210000/576759DA-4A35-534B-B926-2A9E4A5A7268.root\n 3. root://eospublic.cern.ch//eos/opendata/cms/Run2016H/SingleMuon/NANOAOD/UL2016_MiniAODv2_NanoAODv9-v1/130000/0107961B-4308-F845-8F96-E14622BBA484.root\n 4. root://eospublic.cern.ch//eos/opendata/cms/Run2016H/SingleMuon/NANOAOD/UL2016_MiniAODv2_NanoAODv9-v1/130000/0DEE1709-0416-F24B-ACB2-C68997CB6465.root\n 5. root://eospublic.cern.ch//eos/opendata/cms/Run2016H/SingleMuon/NANOAOD/UL2016_MiniAODv2_NanoAODv9-v1/130000/1C08614E-0C0E-6044-966A-CAF630CAEF8F.root\n 6. root://eospublic.cern.ch//eos/opendata/cms/Run2016H/SingleMuon/NANOAOD/UL2016_MiniAODv2_NanoAODv9-v1/130000/1D87B4FB-E31C-9F43-AC21-C32469DE9FC6.root\n 7. root://eospublic.cern.ch//eos/opendata/cms/Run2016H/SingleMuon/NANOAOD/UL2016_MiniAODv2_NanoAODv9-v1/130000/1EB443F2-1230-8042-B8AE-FD50329CA59B.root\n 8. root://eospublic.cern.ch//eos/opendata/cms/Run2016H/SingleMuon/NANOAOD/UL2016_MiniAODv2_NanoAODv9-v1/130000/2045F967-9F0A-7C46-9946-787B27D56E88.root\n 9. root://eospublic.cern.ch//eos/opendata/cms/Run2016H/SingleMuon/NANOAOD/UL2016_MiniAODv2_NanoAODv9-v1/130000/236A04EE-C105-D947-8A2E-F8CC6731644F.root\n10. root://eospublic.cern.ch//eos/opendata/cms/Run2016H/SingleMuon/NANOAOD/UL2016_MiniAODv2_NanoAODv9-v1/130000/370BE877-DA24-DB41-A875-07A86EAB6852.root\n</code></pre> <pre><code>#import uproot\n\nf = uproot.open(fileset[\"SingleMuon\"][\"files\"][0])\nevents = f[\"Events\"]\nfor name in events.keys():\n    if \"Muon\" in name or \"Electron\" in name or \"Jet\" in name or \"MET\" in name:\n        print(name)\n\n</code></pre> <pre><code>CaloMET_phi\nCaloMET_pt\nCaloMET_sumEt\nChsMET_phi\nChsMET_pt\nChsMET_sumEt\nnCorrT1METJet\nCorrT1METJet_area\nCorrT1METJet_eta\nCorrT1METJet_muonSubtrFactor\nCorrT1METJet_phi\nCorrT1METJet_rawPt\nDeepMETResolutionTune_phi\nDeepMETResolutionTune_pt\nDeepMETResponseTune_phi\nDeepMETResponseTune_pt\nnElectron\nElectron_dEscaleDown\nElectron_dEscaleUp\nElectron_dEsigmaDown\nElectron_dEsigmaUp\nElectron_deltaEtaSC\nElectron_dr03EcalRecHitSumEt\nElectron_dr03HcalDepth1TowerSumEt\nElectron_dr03TkSumPt\nElectron_dr03TkSumPtHEEP\nElectron_dxy\nElectron_dxyErr\nElectron_dz\nElectron_dzErr\nElectron_eCorr\nElectron_eInvMinusPInv\nElectron_energyErr\nElectron_eta\nElectron_hoe\nElectron_ip3d\nElectron_jetPtRelv2\nElectron_jetRelIso\nElectron_mass\nElectron_miniPFRelIso_all\nElectron_miniPFRelIso_chg\nElectron_mvaFall17V2Iso\nElectron_mvaFall17V2noIso\nElectron_pfRelIso03_all\nElectron_pfRelIso03_chg\nElectron_phi\nElectron_pt\nElectron_r9\nElectron_scEtOverPt\nElectron_sieie\nElectron_sip3d\nElectron_mvaTTH\nElectron_charge\nElectron_cutBased\nElectron_jetIdx\nElectron_pdgId\nElectron_photonIdx\nElectron_tightCharge\nElectron_vidNestedWPBitmap\nElectron_vidNestedWPBitmapHEEP\nElectron_convVeto\nElectron_cutBased_HEEP\nElectron_isPFcand\nElectron_jetNDauCharged\nElectron_lostHits\nElectron_mvaFall17V2Iso_WP80\nElectron_mvaFall17V2Iso_WP90\nElectron_mvaFall17V2Iso_WPL\nElectron_mvaFall17V2noIso_WP80\nElectron_mvaFall17V2noIso_WP90\nElectron_mvaFall17V2noIso_WPL\nElectron_seedGain\nnFatJet\nFatJet_area\nFatJet_btagCSVV2\nFatJet_btagDDBvLV2\nFatJet_btagDDCvBV2\nFatJet_btagDDCvLV2\nFatJet_btagDeepB\nFatJet_btagHbb\nFatJet_deepTagMD_H4qvsQCD\nFatJet_deepTagMD_HbbvsQCD\nFatJet_deepTagMD_TvsQCD\nFatJet_deepTagMD_WvsQCD\nFatJet_deepTagMD_ZHbbvsQCD\nFatJet_deepTagMD_ZHccvsQCD\nFatJet_deepTagMD_ZbbvsQCD\nFatJet_deepTagMD_ZvsQCD\nFatJet_deepTagMD_bbvsLight\nFatJet_deepTagMD_ccvsLight\nFatJet_deepTag_H\nFatJet_deepTag_QCD\nFatJet_deepTag_QCDothers\nFatJet_deepTag_TvsQCD\nFatJet_deepTag_WvsQCD\nFatJet_deepTag_ZvsQCD\nFatJet_eta\nFatJet_mass\nFatJet_msoftdrop\nFatJet_n2b1\nFatJet_n3b1\nFatJet_particleNetMD_QCD\nFatJet_particleNetMD_Xbb\nFatJet_particleNetMD_Xcc\nFatJet_particleNetMD_Xqq\nFatJet_particleNet_H4qvsQCD\nFatJet_particleNet_HbbvsQCD\nFatJet_particleNet_HccvsQCD\nFatJet_particleNet_QCD\nFatJet_particleNet_TvsQCD\nFatJet_particleNet_WvsQCD\nFatJet_particleNet_ZvsQCD\nFatJet_particleNet_mass\nFatJet_phi\nFatJet_pt\nFatJet_rawFactor\nFatJet_tau1\nFatJet_tau2\nFatJet_tau3\nFatJet_tau4\nFatJet_lsf3\nFatJet_jetId\nFatJet_subJetIdx1\nFatJet_subJetIdx2\nFatJet_electronIdx3SJ\nFatJet_muonIdx3SJ\nFatJet_nConstituents\nnJet\nJet_area\nJet_btagCSVV2\nJet_btagDeepB\nJet_btagDeepCvB\nJet_btagDeepCvL\nJet_btagDeepFlavB\nJet_btagDeepFlavCvB\nJet_btagDeepFlavCvL\nJet_btagDeepFlavQG\nJet_chEmEF\nJet_chFPV0EF\nJet_chHEF\nJet_eta\nJet_hfsigmaEtaEta\nJet_hfsigmaPhiPhi\nJet_mass\nJet_muEF\nJet_muonSubtrFactor\nJet_neEmEF\nJet_neHEF\nJet_phi\nJet_pt\nJet_puIdDisc\nJet_qgl\nJet_rawFactor\nJet_bRegCorr\nJet_bRegRes\nJet_cRegCorr\nJet_cRegRes\nJet_electronIdx1\nJet_electronIdx2\nJet_hfadjacentEtaStripsSize\nJet_hfcentralEtaStripSize\nJet_jetId\nJet_muonIdx1\nJet_muonIdx2\nJet_nElectrons\nJet_nMuons\nJet_puId\nJet_nConstituents\nL1PreFiringWeight_Muon_Nom\nL1PreFiringWeight_Muon_StatDn\nL1PreFiringWeight_Muon_StatUp\nL1PreFiringWeight_Muon_SystDn\nL1PreFiringWeight_Muon_SystUp\nnLowPtElectron\nLowPtElectron_ID\nLowPtElectron_convVtxRadius\nLowPtElectron_deltaEtaSC\nLowPtElectron_dxy\nLowPtElectron_dxyErr\nLowPtElectron_dz\nLowPtElectron_dzErr\nLowPtElectron_eInvMinusPInv\nLowPtElectron_embeddedID\nLowPtElectron_energyErr\nLowPtElectron_eta\nLowPtElectron_hoe\nLowPtElectron_mass\nLowPtElectron_miniPFRelIso_all\nLowPtElectron_miniPFRelIso_chg\nLowPtElectron_phi\nLowPtElectron_pt\nLowPtElectron_ptbiased\nLowPtElectron_r9\nLowPtElectron_scEtOverPt\nLowPtElectron_sieie\nLowPtElectron_unbiased\nLowPtElectron_charge\nLowPtElectron_convWP\nLowPtElectron_pdgId\nLowPtElectron_convVeto\nLowPtElectron_lostHits\nMET_MetUnclustEnUpDeltaX\nMET_MetUnclustEnUpDeltaY\nMET_covXX\nMET_covXY\nMET_covYY\nMET_phi\nMET_pt\nMET_significance\nMET_sumEt\nMET_sumPtUnclustered\nnMuon\nMuon_dxy\nMuon_dxyErr\nMuon_dxybs\nMuon_dz\nMuon_dzErr\nMuon_eta\nMuon_ip3d\nMuon_jetPtRelv2\nMuon_jetRelIso\nMuon_mass\nMuon_miniPFRelIso_all\nMuon_miniPFRelIso_chg\nMuon_pfRelIso03_all\nMuon_pfRelIso03_chg\nMuon_pfRelIso04_all\nMuon_phi\nMuon_pt\nMuon_ptErr\nMuon_segmentComp\nMuon_sip3d\nMuon_softMva\nMuon_tkRelIso\nMuon_tunepRelPt\nMuon_mvaLowPt\nMuon_mvaTTH\nMuon_charge\nMuon_jetIdx\nMuon_nStations\nMuon_nTrackerLayers\nMuon_pdgId\nMuon_tightCharge\nMuon_fsrPhotonIdx\nMuon_highPtId\nMuon_highPurity\nMuon_inTimeMuon\nMuon_isGlobal\nMuon_isPFcand\nMuon_isStandalone\nMuon_isTracker\nMuon_jetNDauCharged\nMuon_looseId\nMuon_mediumId\nMuon_mediumPromptId\nMuon_miniIsoId\nMuon_multiIsoId\nMuon_mvaId\nMuon_mvaLowPtId\nMuon_pfIsoId\nMuon_puppiIsoId\nMuon_softId\nMuon_softMvaId\nMuon_tightId\nMuon_tkIsoId\nMuon_triggerIdLoose\nPuppiMET_phi\nPuppiMET_phiJERDown\nPuppiMET_phiJERUp\nPuppiMET_phiJESDown\nPuppiMET_phiJESUp\nPuppiMET_phiUnclusteredDown\nPuppiMET_phiUnclusteredUp\nPuppiMET_pt\nPuppiMET_ptJERDown\nPuppiMET_ptJERUp\nPuppiMET_ptJESDown\nPuppiMET_ptJESUp\nPuppiMET_ptUnclusteredDown\nPuppiMET_ptUnclusteredUp\nPuppiMET_sumEt\nRawMET_phi\nRawMET_pt\nRawMET_sumEt\nRawPuppiMET_phi\nRawPuppiMET_pt\nRawPuppiMET_sumEt\nnSoftActivityJet\nSoftActivityJet_eta\nSoftActivityJet_phi\nSoftActivityJet_pt\nSoftActivityJetHT\nSoftActivityJetHT10\nSoftActivityJetHT2\nSoftActivityJetHT5\nSoftActivityJetNjets10\nSoftActivityJetNjets2\nSoftActivityJetNjets5\nnSubJet\nSubJet_btagCSVV2\nSubJet_btagDeepB\nSubJet_eta\nSubJet_mass\nSubJet_n2b1\nSubJet_n3b1\nSubJet_phi\nSubJet_pt\nSubJet_rawFactor\nSubJet_tau1\nSubJet_tau2\nSubJet_tau3\nSubJet_tau4\nTkMET_phi\nTkMET_pt\nTkMET_sumEt\nElectron_cleanmask\nJet_cleanmask\nMuon_cleanmask\nL1_CastorHaloMuon\nL1_CastorHaloMuon_BptxAND\nL1_CastorHighJet_BptxAND\nL1_CastorMediumJet_BptxAND\nL1_DoubleJet12_ForwardBackward\nL1_DoubleJet16_ForwardBackward\nL1_DoubleJet30_Mj30j30_400_Mu10\nL1_DoubleJet30_Mj30j30_400_Mu6\nL1_DoubleJet8_ForwardBackward\nL1_DoubleJetC100\nL1_DoubleJetC112\nL1_DoubleJetC120\nL1_DoubleJetC40\nL1_DoubleJetC50\nL1_DoubleJetC60\nL1_DoubleJetC60_ETM60\nL1_DoubleJetC80\nL1_DoubleJet_100_30_Mj30j30_620\nL1_DoubleJet_90_30_Mj30j30_620\nL1_ETM75_Jet60_dPhi_Min0p4\nL1_Jet32_DoubleMu_10_0_dPhi_Jet_Mu0_Max0p4_dPhi_Mu_Mu_Min1p0\nL1_Jet32_Mu0_EG10_dPhi_Jet_Mu_Max0p4_dPhi_Mu_EG_Min1p0\nL1_Mu3_JetC120\nL1_Mu3_JetC120_dEta_Max0p4_dPhi_Max0p4\nL1_Mu3_JetC16\nL1_Mu3_JetC16_dEta_Max0p4_dPhi_Max0p4\nL1_Mu3_JetC60\nL1_Mu3_JetC60_dEta_Max0p4_dPhi_Max0p4\nL1_QuadJetC36_Tau52\nL1_QuadJetC40\nL1_QuadJetC50\nL1_QuadJetC60\nL1_SingleJet12\nL1_SingleJet120\nL1_SingleJet12_BptxAND\nL1_SingleJet140\nL1_SingleJet150\nL1_SingleJet16\nL1_SingleJet160\nL1_SingleJet170\nL1_SingleJet180\nL1_SingleJet20\nL1_SingleJet200\nL1_SingleJet35\nL1_SingleJet4\nL1_SingleJet60\nL1_SingleJet8\nL1_SingleJet8_BptxAND\nL1_SingleJet90\nL1_SingleJetC20_NotBptxOR\nL1_SingleJetC20_NotBptxOR_3BX\nL1_SingleJetC40_NotBptxOR_3BX\nL1_SingleJetC40_NotBptxOR_5BX\nL1_TripleJet_84_68_48_VBF\nL1_TripleJet_88_72_56_VBF\nL1_TripleJet_92_76_64_VBF\nFlag_BadPFMuonFilter\nFlag_BadPFMuonDzFilter\nFlag_BadPFMuonSummer16Filter\nFlag_METFilters\nFlag_BadPFMuonFilter_pRECO\nFlag_BadPFMuonSummer16Filter_pRECO\nFlag_METFilters_pRECO\nHLT_AK8PFJet360_TrimMass30\nHLT_AK8PFJet400_TrimMass30\nHLT_AK8DiPFJet300_200_TrimMass30_BTagCSV_p20\nHLT_AK8DiPFJet280_200_TrimMass30_BTagCSV_p087\nHLT_AK8DiPFJet300_200_TrimMass30_BTagCSV_p087\nHLT_AK8DiPFJet300_200_TrimMass30\nHLT_AK8DiPFJet280_200_TrimMass30\nHLT_AK8DiPFJet250_200_TrimMass30\nHLT_AK8DiPFJet280_200_TrimMass30_BTagCSV_p20\nHLT_AK8DiPFJet250_200_TrimMass30_BTagCSV_p20\nHLT_CaloJet500_NoJetID\nHLT_Ele27_WPTight_Gsf_L1JetTauSeeded\nHLT_Ele45_CaloIdVT_GsfTrkIdT_PFJet200_PFJet50\nHLT_IsoMu16_eta2p1_MET30\nHLT_IsoMu16_eta2p1_MET30_LooseIsoPFTau50_Trk30_eta2p1\nHLT_JetE30_NoBPTX3BX\nHLT_JetE30_NoBPTX\nHLT_JetE50_NoBPTX3BX\nHLT_JetE70_NoBPTX3BX\nHLT_LooseIsoPFTau50_Trk30_eta2p1_MET90\nHLT_LooseIsoPFTau50_Trk30_eta2p1_MET110\nHLT_LooseIsoPFTau50_Trk30_eta2p1_MET120\nHLT_Mu30_eta2p1_PFJet150_PFJet50\nHLT_Mu40_eta2p1_PFJet200_PFJet50\nHLT_Mu28NoFiltersNoVtx_DisplacedJet40_Loose\nHLT_Mu38NoFiltersNoVtxDisplaced_DisplacedJet60_Tight\nHLT_Mu38NoFiltersNoVtxDisplaced_DisplacedJet60_Loose\nHLT_Mu38NoFiltersNoVtx_DisplacedJet60_Loose\nHLT_Mu28NoFiltersNoVtx_CentralCaloJet40\nHLT_PFHT300_PFMET110\nHLT_PFHT550_4JetPt50\nHLT_PFHT650_4JetPt50\nHLT_PFHT750_4JetPt70\nHLT_PFHT750_4JetPt80\nHLT_PFHT800_4JetPt50\nHLT_PFHT850_4JetPt50\nHLT_PFJet15_NoCaloMatched\nHLT_PFJet25_NoCaloMatched\nHLT_DiPFJet15_NoCaloMatched\nHLT_DiPFJet25_NoCaloMatched\nHLT_DiPFJet15_FBEta3_NoCaloMatched\nHLT_DiPFJet25_FBEta3_NoCaloMatched\nHLT_DiPFJetAve15_HFJEC\nHLT_DiPFJetAve25_HFJEC\nHLT_DiPFJetAve35_HFJEC\nHLT_AK8PFJet40\nHLT_AK8PFJet60\nHLT_AK8PFJet80\nHLT_AK8PFJet140\nHLT_AK8PFJet200\nHLT_AK8PFJet260\nHLT_AK8PFJet320\nHLT_AK8PFJet400\nHLT_AK8PFJet450\nHLT_AK8PFJet500\nHLT_PFJet40\nHLT_PFJet60\nHLT_PFJet80\nHLT_PFJet140\nHLT_PFJet200\nHLT_PFJet260\nHLT_PFJet320\nHLT_PFJet400\nHLT_PFJet450\nHLT_PFJet500\nHLT_DiPFJetAve40\nHLT_DiPFJetAve60\nHLT_DiPFJetAve80\nHLT_DiPFJetAve140\nHLT_DiPFJetAve200\nHLT_DiPFJetAve260\nHLT_DiPFJetAve320\nHLT_DiPFJetAve400\nHLT_DiPFJetAve500\nHLT_DiPFJetAve60_HFJEC\nHLT_DiPFJetAve80_HFJEC\nHLT_DiPFJetAve100_HFJEC\nHLT_DiPFJetAve160_HFJEC\nHLT_DiPFJetAve220_HFJEC\nHLT_DiPFJetAve300_HFJEC\nHLT_DiPFJet40_DEta3p5_MJJ600_PFMETNoMu140\nHLT_DiPFJet40_DEta3p5_MJJ600_PFMETNoMu80\nHLT_DiCentralPFJet170\nHLT_SingleCentralPFJet170_CFMax0p1\nHLT_DiCentralPFJet170_CFMax0p1\nHLT_DiCentralPFJet330_CFMax0p5\nHLT_DiCentralPFJet430\nHLT_DiJetVBF_PassThrough\nHLT_DiJetVBFMu_PassThrough\nHLT_PFHT200_DiPFJetAve90_PFAlphaT0p63\nHLT_PFHT250_DiPFJetAve90_PFAlphaT0p58\nHLT_PFHT300_DiPFJetAve90_PFAlphaT0p54\nHLT_PFHT350_DiPFJetAve90_PFAlphaT0p53\nHLT_PFHT400_DiPFJetAve90_PFAlphaT0p52\nHLT_MET60_IsoTrk35_Loose\nHLT_MET75_IsoTrk50\nHLT_MET90_IsoTrk50\nHLT_PFMET170_NotCleaned\nHLT_PFMET170_HBHECleaned\nHLT_PFMET170_BeamHaloCleaned\nHLT_PFMET170_HBHE_BeamHaloCleaned\nHLT_PFMETTypeOne190_HBHE_BeamHaloCleaned\nHLT_PFMET110_PFMHT110_IDTight\nHLT_PFMET120_PFMHT120_IDTight\nHLT_CaloMHTNoPU90_PFMET90_PFMHT90_IDTight_BTagCSV_p067\nHLT_CaloMHTNoPU90_PFMET90_PFMHT90_IDTight\nHLT_QuadPFJet_BTagCSV_p016_p11_VBF_Mqq200\nHLT_QuadPFJet_BTagCSV_p016_VBF_Mqq460\nHLT_QuadPFJet_BTagCSV_p016_p11_VBF_Mqq240\nHLT_QuadPFJet_BTagCSV_p016_VBF_Mqq500\nHLT_QuadPFJet_VBF\nHLT_L1_TripleJet_VBF\nHLT_QuadJet45_TripleBTagCSV_p087\nHLT_QuadJet45_DoubleBTagCSV_p087\nHLT_DoubleJet90_Double30_TripleBTagCSV_p087\nHLT_DoubleJet90_Double30_DoubleBTagCSV_p087\nHLT_DoubleJetsC100_DoubleBTagCSV_p026_DoublePFJetsC160\nHLT_DoubleJetsC100_DoubleBTagCSV_p014_DoublePFJetsC100MaxDeta1p6\nHLT_DoubleJetsC112_DoubleBTagCSV_p026_DoublePFJetsC172\nHLT_DoubleJetsC112_DoubleBTagCSV_p014_DoublePFJetsC112MaxDeta1p6\nHLT_DoubleJetsC100_SingleBTagCSV_p026\nHLT_DoubleJetsC100_SingleBTagCSV_p014\nHLT_DoubleJetsC100_SingleBTagCSV_p026_SinglePFJetC350\nHLT_DoubleJetsC100_SingleBTagCSV_p014_SinglePFJetC350\nHLT_Photon135_PFMET100\nHLT_Photon22_R9Id90_HE10_Iso40_EBOnly_PFMET40\nHLT_Photon36_R9Id90_HE10_Iso40_EBOnly_PFMET40\nHLT_Photon50_R9Id90_HE10_Iso40_EBOnly_PFMET40\nHLT_Photon75_R9Id90_HE10_Iso40_EBOnly_PFMET40\nHLT_Photon90_R9Id90_HE10_Iso40_EBOnly_PFMET40\nHLT_Photon120_R9Id90_HE10_Iso40_EBOnly_PFMET40\nHLT_Ele8_CaloIdL_TrackIdL_IsoVL_PFJet30\nHLT_Ele12_CaloIdL_TrackIdL_IsoVL_PFJet30\nHLT_Ele17_CaloIdL_TrackIdL_IsoVL_PFJet30\nHLT_Ele23_CaloIdL_TrackIdL_IsoVL_PFJet30\nHLT_BTagMu_DiJet20_Mu5\nHLT_BTagMu_DiJet40_Mu5\nHLT_BTagMu_DiJet70_Mu5\nHLT_BTagMu_DiJet110_Mu5\nHLT_BTagMu_DiJet170_Mu5\nHLT_BTagMu_Jet300_Mu5\nHLT_BTagMu_AK8Jet300_Mu5\nHLT_Ele23_Ele12_CaloIdL_TrackIdL_IsoVL_DZ_L1JetTauSeeded\nHLT_Mu6_PFHT200_PFMET100\nHLT_PFHT650_WideJetMJJ900DEtaJJ1p5\nHLT_PFHT650_WideJetMJJ950DEtaJJ1p5\nHLT_Dimuon0_Jpsi_Muon\nHLT_Dimuon0_Upsilon_Muon\nHLT_QuadMuon0_Dimuon0_Jpsi\nHLT_QuadMuon0_Dimuon0_Upsilon\nHLT_Rsq0p02_MR400_TriPFJet80_60_40_DoubleBTagCSV_p063_Mbb60_200\nHLT_Rsq0p02_MR450_TriPFJet80_60_40_DoubleBTagCSV_p063_Mbb60_200\nHLT_Rsq0p02_MR500_TriPFJet80_60_40_DoubleBTagCSV_p063_Mbb60_200\nHLT_Rsq0p02_MR550_TriPFJet80_60_40_DoubleBTagCSV_p063_Mbb60_200\nHLT_VBF_DisplacedJet40_DisplacedTrack\nHLT_VBF_DisplacedJet40_DisplacedTrack_2TrackIP2DSig5\nHLT_VBF_DisplacedJet40_TightID_DisplacedTrack\nHLT_VBF_DisplacedJet40_TightID_Hadronic\nHLT_VBF_DisplacedJet40_VTightID_Hadronic\nHLT_VBF_DisplacedJet40_VVTightID_Hadronic\nHLT_VBF_DisplacedJet40_VTightID_DisplacedTrack\nHLT_VBF_DisplacedJet40_VVTightID_DisplacedTrack\nHLT_PFMETNoMu110_PFMHTNoMu110_IDTight\nHLT_PFMETNoMu120_PFMHTNoMu120_IDTight\nHLT_MonoCentralPFJet80_PFMETNoMu110_PFMHTNoMu110_IDTight\nHLT_MonoCentralPFJet80_PFMETNoMu120_PFMHTNoMu120_IDTight\nHLT_Mu10_CentralPFJet30_BTagCSV_p13\nHLT_DoubleMu3_PFMET50\nHLT_Ele10_CaloIdM_TrackIdM_CentralPFJet30_BTagCSV_p13\nHLT_Ele15_IsoVVVL_PFHT400_PFMET50\nHLT_Mu8_TrkIsoVVL_DiPFJet40_DEta3p5_MJJ750_HTT300_PFMETNoMu60\nHLT_Mu10_TrkIsoVVL_DiPFJet40_DEta3p5_MJJ750_HTT350_PFMETNoMu60\nHLT_Mu15_IsoVVVL_PFHT400_PFMET50\nHLT_Mu3_PFJet40\nHLT_Ele8_CaloIdM_TrackIdM_PFJet30\nHLT_Ele12_CaloIdM_TrackIdM_PFJet30\nHLT_Ele17_CaloIdM_TrackIdM_PFJet30\nHLT_Ele23_CaloIdM_TrackIdM_PFJet30\nHLT_Ele50_CaloIdVT_GsfTrkIdT_PFJet165\nHLT_PFHT400_SixJet30_DoubleBTagCSV_p056\nHLT_PFHT450_SixJet40_BTagCSV_p056\nHLT_PFHT400_SixJet30\nHLT_PFHT450_SixJet40\nHLT_MET200\nHLT_AK4CaloJet30\nHLT_AK4CaloJet40\nHLT_AK4CaloJet50\nHLT_AK4CaloJet80\nHLT_AK4CaloJet100\nHLT_AK4PFJet30\nHLT_AK4PFJet50\nHLT_AK4PFJet80\nHLT_AK4PFJet100\nHLT_MET250\nHLT_MET300\nHLT_MET600\nHLT_MET700\nHLT_PFMET300\nHLT_PFMET400\nHLT_PFMET500\nHLT_PFMET600\n</code></pre> <pre><code>for b in events.keys():\n    if b.startswith(\"HLT_\"):\n        print(b)\n\n</code></pre> <pre><code>HLT_AK8PFJet360_TrimMass30\nHLT_AK8PFJet400_TrimMass30\nHLT_AK8PFHT750_TrimMass50\nHLT_AK8PFHT800_TrimMass50\nHLT_AK8DiPFJet300_200_TrimMass30_BTagCSV_p20\nHLT_AK8DiPFJet280_200_TrimMass30_BTagCSV_p087\nHLT_AK8DiPFJet300_200_TrimMass30_BTagCSV_p087\nHLT_AK8DiPFJet300_200_TrimMass30\nHLT_AK8PFHT700_TrimR0p1PT0p03Mass50\nHLT_AK8PFHT650_TrimR0p1PT0p03Mass50\nHLT_AK8PFHT600_TrimR0p1PT0p03Mass50_BTagCSV_p20\nHLT_AK8DiPFJet280_200_TrimMass30\nHLT_AK8DiPFJet250_200_TrimMass30\nHLT_AK8DiPFJet280_200_TrimMass30_BTagCSV_p20\nHLT_AK8DiPFJet250_200_TrimMass30_BTagCSV_p20\nHLT_CaloJet500_NoJetID\nHLT_Dimuon13_PsiPrime\nHLT_Dimuon13_Upsilon\nHLT_Dimuon20_Jpsi\nHLT_DoubleEle24_22_eta2p1_WPLoose_Gsf\nHLT_DoubleEle33_CaloIdL\nHLT_DoubleEle33_CaloIdL_MW\nHLT_DoubleEle33_CaloIdL_GsfTrkIdVL_MW\nHLT_DoubleMediumCombinedIsoPFTau35_Trk1_eta2p1_Reg\nHLT_DoubleTightCombinedIsoPFTau35_Trk1_eta2p1_Reg\nHLT_DoubleMediumCombinedIsoPFTau40_Trk1_eta2p1_Reg\nHLT_DoubleTightCombinedIsoPFTau40_Trk1_eta2p1_Reg\nHLT_DoubleMediumCombinedIsoPFTau40_Trk1_eta2p1\nHLT_DoubleTightCombinedIsoPFTau40_Trk1_eta2p1\nHLT_DoubleEle37_Ele27_CaloIdL_GsfTrkIdVL\nHLT_DoubleMu33NoFiltersNoVtx\nHLT_DoubleMu38NoFiltersNoVtx\nHLT_DoubleMu23NoFiltersNoVtxDisplaced\nHLT_DoubleMu28NoFiltersNoVtxDisplaced\nHLT_DoubleMu0\nHLT_DoubleMu4_3_Bs\nHLT_DoubleMu4_3_Jpsi_Displaced\nHLT_DoubleMu4_JpsiTrk_Displaced\nHLT_DoubleMu4_LowMassNonResonantTrk_Displaced\nHLT_DoubleMu3_Trk_Tau3mu\nHLT_DoubleMu4_PsiPrimeTrk_Displaced\nHLT_Mu7p5_L2Mu2_Jpsi\nHLT_Mu7p5_L2Mu2_Upsilon\nHLT_Mu7p5_Track2_Jpsi\nHLT_Mu7p5_Track3p5_Jpsi\nHLT_Mu7p5_Track7_Jpsi\nHLT_Mu7p5_Track2_Upsilon\nHLT_Mu7p5_Track3p5_Upsilon\nHLT_Mu7p5_Track7_Upsilon\nHLT_Dimuon0er16_Jpsi_NoOS_NoVertexing\nHLT_Dimuon6_Jpsi_NoVertexing\nHLT_DoublePhoton60\nHLT_DoublePhoton85\nHLT_Ele20_eta2p1_WPLoose_Gsf_LooseIsoPFTau28\nHLT_Ele22_eta2p1_WPLoose_Gsf_LooseIsoPFTau29\nHLT_Ele22_eta2p1_WPLoose_Gsf\nHLT_Ele24_eta2p1_WPLoose_Gsf_LooseIsoPFTau30\nHLT_Ele25_WPTight_Gsf\nHLT_Ele25_eta2p1_WPTight_Gsf\nHLT_Ele27_WPLoose_Gsf_WHbbBoost\nHLT_Ele27_WPTight_Gsf\nHLT_Ele27_WPTight_Gsf_L1JetTauSeeded\nHLT_Ele27_eta2p1_WPLoose_Gsf\nHLT_Ele27_eta2p1_WPTight_Gsf\nHLT_Ele30_WPTight_Gsf\nHLT_Ele30_eta2p1_WPTight_Gsf\nHLT_Ele32_WPTight_Gsf\nHLT_Ele32_eta2p1_WPTight_Gsf\nHLT_Ele36_eta2p1_WPLoose_Gsf_LooseIsoPFTau20_SingleL1\nHLT_Ele45_CaloIdVT_GsfTrkIdT_PFJet200_PFJet50\nHLT_Ele105_CaloIdVT_GsfTrkIdT\nHLT_HT200\nHLT_HT275\nHLT_HT325\nHLT_HT425\nHLT_HT575\nHLT_HT430to450\nHLT_HT450to470\nHLT_HT470to500\nHLT_HT500to550\nHLT_HT550to650\nHLT_HT650\nHLT_IsoMu16_eta2p1_MET30\nHLT_IsoMu16_eta2p1_MET30_LooseIsoPFTau50_Trk30_eta2p1\nHLT_DoubleIsoMu17_eta2p1_noDzCut\nHLT_IsoMu19_eta2p1_LooseIsoPFTau20\nHLT_IsoMu19_eta2p1_LooseIsoPFTau20_SingleL1\nHLT_IsoMu19_eta2p1_MediumIsoPFTau32_Trk1_eta2p1_Reg\nHLT_IsoMu19_eta2p1_LooseCombinedIsoPFTau20\nHLT_IsoMu19_eta2p1_MediumCombinedIsoPFTau32_Trk1_eta2p1_Reg\nHLT_IsoMu19_eta2p1_TightCombinedIsoPFTau32_Trk1_eta2p1_Reg\nHLT_IsoMu21_eta2p1_MediumCombinedIsoPFTau32_Trk1_eta2p1_Reg\nHLT_IsoMu21_eta2p1_TightCombinedIsoPFTau32_Trk1_eta2p1_Reg\nHLT_IsoMu20\nHLT_IsoMu21_eta2p1_LooseIsoPFTau20_SingleL1\nHLT_IsoMu21_eta2p1_LooseIsoPFTau50_Trk30_eta2p1_SingleL1\nHLT_IsoMu21_eta2p1_MediumIsoPFTau32_Trk1_eta2p1_Reg\nHLT_IsoMu22\nHLT_IsoMu22_eta2p1\nHLT_IsoMu24\nHLT_IsoMu24_eta2p1\nHLT_IsoMu27\nHLT_IsoTkMu20\nHLT_IsoTkMu22\nHLT_IsoTkMu22_eta2p1\nHLT_IsoTkMu24\nHLT_IsoTkMu24_eta2p1\nHLT_IsoTkMu27\nHLT_JetE30_NoBPTX3BX\nHLT_JetE30_NoBPTX\nHLT_JetE50_NoBPTX3BX\nHLT_JetE70_NoBPTX3BX\nHLT_L1SingleMu18\nHLT_L2Mu10\nHLT_L2DoubleMu23_NoVertex\nHLT_L2DoubleMu28_NoVertex_2Cha_Angle2p5_Mass10\nHLT_L2DoubleMu38_NoVertex_2Cha_Angle2p5_Mass10\nHLT_L2Mu10_NoVertex_NoBPTX3BX\nHLT_L2Mu10_NoVertex_NoBPTX\nHLT_L2Mu45_NoVertex_3Sta_NoBPTX3BX\nHLT_L2Mu40_NoVertex_3Sta_NoBPTX3BX\nHLT_LooseIsoPFTau50_Trk30_eta2p1\nHLT_LooseIsoPFTau50_Trk30_eta2p1_MET90\nHLT_LooseIsoPFTau50_Trk30_eta2p1_MET110\nHLT_LooseIsoPFTau50_Trk30_eta2p1_MET120\nHLT_PFTau120_eta2p1\nHLT_PFTau140_eta2p1\nHLT_VLooseIsoPFTau120_Trk50_eta2p1\nHLT_VLooseIsoPFTau140_Trk50_eta2p1\nHLT_Mu17_Mu8\nHLT_Mu17_Mu8_DZ\nHLT_Mu17_Mu8_SameSign\nHLT_Mu17_Mu8_SameSign_DZ\nHLT_Mu20_Mu10\nHLT_Mu20_Mu10_DZ\nHLT_Mu20_Mu10_SameSign\nHLT_Mu20_Mu10_SameSign_DZ\nHLT_Mu17_TkMu8_DZ\nHLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL\nHLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL_DZ\nHLT_Mu17_TrkIsoVVL_TkMu8_TrkIsoVVL\nHLT_Mu17_TrkIsoVVL_TkMu8_TrkIsoVVL_DZ\nHLT_Mu25_TkMu0_dEta18_Onia\nHLT_Mu27_TkMu8\nHLT_Mu30_TkMu11\nHLT_Mu30_eta2p1_PFJet150_PFJet50\nHLT_Mu40_TkMu11\nHLT_Mu40_eta2p1_PFJet200_PFJet50\nHLT_Mu20\nHLT_TkMu17\nHLT_TkMu17_TrkIsoVVL_TkMu8_TrkIsoVVL\nHLT_TkMu17_TrkIsoVVL_TkMu8_TrkIsoVVL_DZ\nHLT_TkMu20\nHLT_Mu24_eta2p1\nHLT_TkMu24_eta2p1\nHLT_Mu27\nHLT_TkMu27\nHLT_Mu45_eta2p1\nHLT_Mu50\nHLT_TkMu50\nHLT_Mu38NoFiltersNoVtx_Photon38_CaloIdL\nHLT_Mu42NoFiltersNoVtx_Photon42_CaloIdL\nHLT_Mu28NoFiltersNoVtxDisplaced_Photon28_CaloIdL\nHLT_Mu33NoFiltersNoVtxDisplaced_Photon33_CaloIdL\nHLT_Mu23NoFiltersNoVtx_Photon23_CaloIdL\nHLT_DoubleMu18NoFiltersNoVtx\nHLT_Mu28NoFiltersNoVtx_DisplacedJet40_Loose\nHLT_Mu38NoFiltersNoVtxDisplaced_DisplacedJet60_Tight\nHLT_Mu38NoFiltersNoVtxDisplaced_DisplacedJet60_Loose\nHLT_Mu38NoFiltersNoVtx_DisplacedJet60_Loose\nHLT_Mu28NoFiltersNoVtx_CentralCaloJet40\nHLT_PFHT300_PFMET110\nHLT_PFHT550_4JetPt50\nHLT_PFHT650_4JetPt50\nHLT_PFHT750_4JetPt70\nHLT_PFHT750_4JetPt80\nHLT_PFHT800_4JetPt50\nHLT_PFHT850_4JetPt50\nHLT_PFJet15_NoCaloMatched\nHLT_PFJet25_NoCaloMatched\nHLT_DiPFJet15_NoCaloMatched\nHLT_DiPFJet25_NoCaloMatched\nHLT_DiPFJet15_FBEta3_NoCaloMatched\nHLT_DiPFJet25_FBEta3_NoCaloMatched\nHLT_DiPFJetAve15_HFJEC\nHLT_DiPFJetAve25_HFJEC\nHLT_DiPFJetAve35_HFJEC\nHLT_AK8PFJet40\nHLT_AK8PFJet60\nHLT_AK8PFJet80\nHLT_AK8PFJet140\nHLT_AK8PFJet200\nHLT_AK8PFJet260\nHLT_AK8PFJet320\nHLT_AK8PFJet400\nHLT_AK8PFJet450\nHLT_AK8PFJet500\nHLT_PFJet40\nHLT_PFJet60\nHLT_PFJet80\nHLT_PFJet140\nHLT_PFJet200\nHLT_PFJet260\nHLT_PFJet320\nHLT_PFJet400\nHLT_PFJet450\nHLT_PFJet500\nHLT_DiPFJetAve40\nHLT_DiPFJetAve60\nHLT_DiPFJetAve80\nHLT_DiPFJetAve140\nHLT_DiPFJetAve200\nHLT_DiPFJetAve260\nHLT_DiPFJetAve320\nHLT_DiPFJetAve400\nHLT_DiPFJetAve500\nHLT_DiPFJetAve60_HFJEC\nHLT_DiPFJetAve80_HFJEC\nHLT_DiPFJetAve100_HFJEC\nHLT_DiPFJetAve160_HFJEC\nHLT_DiPFJetAve220_HFJEC\nHLT_DiPFJetAve300_HFJEC\nHLT_DiPFJet40_DEta3p5_MJJ600_PFMETNoMu140\nHLT_DiPFJet40_DEta3p5_MJJ600_PFMETNoMu80\nHLT_DiCentralPFJet170\nHLT_SingleCentralPFJet170_CFMax0p1\nHLT_DiCentralPFJet170_CFMax0p1\nHLT_DiCentralPFJet330_CFMax0p5\nHLT_DiCentralPFJet430\nHLT_DiJetVBF_PassThrough\nHLT_DiJetVBFMu_PassThrough\nHLT_PFHT125\nHLT_PFHT200\nHLT_PFHT250\nHLT_PFHT300\nHLT_PFHT350\nHLT_PFHT400\nHLT_PFHT475\nHLT_PFHT600\nHLT_PFHT650\nHLT_PFHT900\nHLT_PFHT200_PFAlphaT0p51\nHLT_PFHT200_DiPFJetAve90_PFAlphaT0p63\nHLT_PFHT250_DiPFJetAve90_PFAlphaT0p58\nHLT_PFHT300_DiPFJetAve90_PFAlphaT0p54\nHLT_PFHT350_DiPFJetAve90_PFAlphaT0p53\nHLT_PFHT400_DiPFJetAve90_PFAlphaT0p52\nHLT_MET60_IsoTrk35_Loose\nHLT_MET75_IsoTrk50\nHLT_MET90_IsoTrk50\nHLT_PFMET170_NotCleaned\nHLT_PFMET170_HBHECleaned\nHLT_PFMET170_BeamHaloCleaned\nHLT_PFMET170_HBHE_BeamHaloCleaned\nHLT_PFMETTypeOne190_HBHE_BeamHaloCleaned\nHLT_PFMET110_PFMHT110_IDTight\nHLT_PFMET120_PFMHT120_IDTight\nHLT_CaloMHTNoPU90_PFMET90_PFMHT90_IDTight_BTagCSV_p067\nHLT_CaloMHTNoPU90_PFMET90_PFMHT90_IDTight\nHLT_QuadPFJet_BTagCSV_p016_p11_VBF_Mqq200\nHLT_QuadPFJet_BTagCSV_p016_VBF_Mqq460\nHLT_QuadPFJet_BTagCSV_p016_p11_VBF_Mqq240\nHLT_QuadPFJet_BTagCSV_p016_VBF_Mqq500\nHLT_QuadPFJet_VBF\nHLT_L1_TripleJet_VBF\nHLT_QuadJet45_TripleBTagCSV_p087\nHLT_QuadJet45_DoubleBTagCSV_p087\nHLT_DoubleJet90_Double30_TripleBTagCSV_p087\nHLT_DoubleJet90_Double30_DoubleBTagCSV_p087\nHLT_DoubleJetsC100_DoubleBTagCSV_p026_DoublePFJetsC160\nHLT_DoubleJetsC100_DoubleBTagCSV_p014_DoublePFJetsC100MaxDeta1p6\nHLT_DoubleJetsC112_DoubleBTagCSV_p026_DoublePFJetsC172\nHLT_DoubleJetsC112_DoubleBTagCSV_p014_DoublePFJetsC112MaxDeta1p6\nHLT_DoubleJetsC100_SingleBTagCSV_p026\nHLT_DoubleJetsC100_SingleBTagCSV_p014\nHLT_DoubleJetsC100_SingleBTagCSV_p026_SinglePFJetC350\nHLT_DoubleJetsC100_SingleBTagCSV_p014_SinglePFJetC350\nHLT_Photon135_PFMET100\nHLT_Photon22_R9Id90_HE10_Iso40_EBOnly_PFMET40\nHLT_Photon22_R9Id90_HE10_Iso40_EBOnly_VBF\nHLT_Photon250_NoHE\nHLT_Photon300_NoHE\nHLT_Photon26_R9Id85_OR_CaloId24b40e_Iso50T80L_Photon16_AND_HE10_R9Id65_Eta2_Mass60\nHLT_Photon36_R9Id85_OR_CaloId24b40e_Iso50T80L_Photon22_AND_HE10_R9Id65_Eta2_Mass15\nHLT_Photon36_R9Id90_HE10_Iso40_EBOnly_PFMET40\nHLT_Photon36_R9Id90_HE10_Iso40_EBOnly_VBF\nHLT_Photon50_R9Id90_HE10_Iso40_EBOnly_PFMET40\nHLT_Photon50_R9Id90_HE10_Iso40_EBOnly_VBF\nHLT_Photon75_R9Id90_HE10_Iso40_EBOnly_PFMET40\nHLT_Photon75_R9Id90_HE10_Iso40_EBOnly_VBF\nHLT_Photon90_R9Id90_HE10_Iso40_EBOnly_PFMET40\nHLT_Photon90_R9Id90_HE10_Iso40_EBOnly_VBF\nHLT_Photon120_R9Id90_HE10_Iso40_EBOnly_PFMET40\nHLT_Photon120_R9Id90_HE10_Iso40_EBOnly_VBF\nHLT_Mu8_TrkIsoVVL\nHLT_Mu17_TrkIsoVVL\nHLT_Ele8_CaloIdL_TrackIdL_IsoVL_PFJet30\nHLT_Ele12_CaloIdL_TrackIdL_IsoVL_PFJet30\nHLT_Ele17_CaloIdL_TrackIdL_IsoVL_PFJet30\nHLT_Ele23_CaloIdL_TrackIdL_IsoVL_PFJet30\nHLT_BTagMu_DiJet20_Mu5\nHLT_BTagMu_DiJet40_Mu5\nHLT_BTagMu_DiJet70_Mu5\nHLT_BTagMu_DiJet110_Mu5\nHLT_BTagMu_DiJet170_Mu5\nHLT_BTagMu_Jet300_Mu5\nHLT_BTagMu_AK8Jet300_Mu5\nHLT_Ele23_Ele12_CaloIdL_TrackIdL_IsoVL_DZ\nHLT_Ele23_Ele12_CaloIdL_TrackIdL_IsoVL_DZ_L1JetTauSeeded\nHLT_Ele17_Ele12_CaloIdL_TrackIdL_IsoVL_DZ\nHLT_Ele16_Ele12_Ele8_CaloIdL_TrackIdL\nHLT_Mu8_TrkIsoVVL_Ele17_CaloIdL_TrackIdL_IsoVL\nHLT_Mu8_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL_DZ\nHLT_Mu12_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL\nHLT_Mu12_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL_DZ\nHLT_Mu17_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL\nHLT_Mu23_TrkIsoVVL_Ele8_CaloIdL_TrackIdL_IsoVL_DZ\nHLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL\nHLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL_DZ\nHLT_Mu33_Ele33_CaloIdL_GsfTrkIdVL\nHLT_Mu37_Ele27_CaloIdL_GsfTrkIdVL\nHLT_Mu27_Ele37_CaloIdL_GsfTrkIdVL\nHLT_Mu8_DiEle12_CaloIdL_TrackIdL\nHLT_Mu12_Photon25_CaloIdL\nHLT_Mu12_Photon25_CaloIdL_L1ISO\nHLT_Mu12_Photon25_CaloIdL_L1OR\nHLT_Mu17_Photon30_CaloIdL_L1ISO\nHLT_Mu17_Photon35_CaloIdL_L1ISO\nHLT_DiMu9_Ele9_CaloIdL_TrackIdL\nHLT_TripleMu_5_3_3_DZ_Mass3p8\nHLT_TripleMu_12_10_5\nHLT_Mu6_PFHT200_PFMET100\nHLT_Ele17_Ele12_CaloIdL_TrackIdL_IsoVL\nHLT_Ele23_Ele12_CaloIdL_TrackIdL_IsoVL\nHLT_Ele12_CaloIdL_TrackIdL_IsoVL\nHLT_Ele17_CaloIdL_GsfTrkIdVL\nHLT_Ele17_CaloIdL_TrackIdL_IsoVL\nHLT_Ele23_CaloIdL_TrackIdL_IsoVL\nHLT_PFHT650_WideJetMJJ900DEtaJJ1p5\nHLT_PFHT650_WideJetMJJ950DEtaJJ1p5\nHLT_Photon22\nHLT_Photon30\nHLT_Photon36\nHLT_Photon50\nHLT_Photon75\nHLT_Photon90\nHLT_Photon120\nHLT_Photon175\nHLT_Photon165_HE10\nHLT_Photon22_R9Id90_HE10_IsoM\nHLT_Photon30_R9Id90_HE10_IsoM\nHLT_Photon36_R9Id90_HE10_IsoM\nHLT_Photon50_R9Id90_HE10_IsoM\nHLT_Photon75_R9Id90_HE10_IsoM\nHLT_Photon90_R9Id90_HE10_IsoM\nHLT_Photon120_R9Id90_HE10_IsoM\nHLT_Photon165_R9Id90_HE10_IsoM\nHLT_Diphoton30_18_R9Id_OR_IsoCaloId_AND_HE_R9Id_Mass90\nHLT_Diphoton30_18_R9Id_OR_IsoCaloId_AND_HE_R9Id_DoublePixelSeedMatch_Mass70\nHLT_Diphoton30PV_18PV_R9Id_AND_IsoCaloId_AND_HE_R9Id_DoublePixelVeto_Mass55\nHLT_Diphoton30_18_Solid_R9Id_AND_IsoCaloId_AND_HE_R9Id_Mass55\nHLT_Diphoton30EB_18EB_R9Id_OR_IsoCaloId_AND_HE_R9Id_DoublePixelVeto_Mass55\nHLT_Dimuon0_Jpsi_Muon\nHLT_Dimuon0_Upsilon_Muon\nHLT_QuadMuon0_Dimuon0_Jpsi\nHLT_QuadMuon0_Dimuon0_Upsilon\nHLT_Rsq0p25\nHLT_Rsq0p30\nHLT_RsqMR270_Rsq0p09_MR200\nHLT_RsqMR270_Rsq0p09_MR200_4jet\nHLT_Rsq0p02_MR400_TriPFJet80_60_40_DoubleBTagCSV_p063_Mbb60_200\nHLT_Rsq0p02_MR450_TriPFJet80_60_40_DoubleBTagCSV_p063_Mbb60_200\nHLT_Rsq0p02_MR500_TriPFJet80_60_40_DoubleBTagCSV_p063_Mbb60_200\nHLT_Rsq0p02_MR550_TriPFJet80_60_40_DoubleBTagCSV_p063_Mbb60_200\nHLT_HT250_DisplacedDijet40_DisplacedTrack\nHLT_HT350_DisplacedDijet40_DisplacedTrack\nHLT_HT350_DisplacedDijet80_DisplacedTrack\nHLT_HT350_DisplacedDijet80_Tight_DisplacedTrack\nHLT_HT350_DisplacedDijet40_Inclusive\nHLT_HT550_DisplacedDijet80_Inclusive\nHLT_HT650_DisplacedDijet80_Inclusive\nHLT_HT750_DisplacedDijet80_Inclusive\nHLT_VBF_DisplacedJet40_DisplacedTrack\nHLT_VBF_DisplacedJet40_DisplacedTrack_2TrackIP2DSig5\nHLT_VBF_DisplacedJet40_TightID_DisplacedTrack\nHLT_VBF_DisplacedJet40_TightID_Hadronic\nHLT_VBF_DisplacedJet40_VTightID_Hadronic\nHLT_VBF_DisplacedJet40_VVTightID_Hadronic\nHLT_VBF_DisplacedJet40_VTightID_DisplacedTrack\nHLT_VBF_DisplacedJet40_VVTightID_DisplacedTrack\nHLT_PFMETNoMu110_PFMHTNoMu110_IDTight\nHLT_PFMETNoMu120_PFMHTNoMu120_IDTight\nHLT_MonoCentralPFJet80_PFMETNoMu110_PFMHTNoMu110_IDTight\nHLT_MonoCentralPFJet80_PFMETNoMu120_PFMHTNoMu120_IDTight\nHLT_Ele27_eta2p1_WPLoose_Gsf_HT200\nHLT_DoubleMu8_Mass8_PFHT300\nHLT_Mu8_Ele8_CaloIdM_TrackIdM_Mass8_PFHT300\nHLT_DoubleEle8_CaloIdM_TrackIdM_Mass8_PFHT300\nHLT_Mu10_CentralPFJet30_BTagCSV_p13\nHLT_DoubleMu3_PFMET50\nHLT_Ele10_CaloIdM_TrackIdM_CentralPFJet30_BTagCSV_p13\nHLT_Ele15_IsoVVVL_BTagCSV_p067_PFHT400\nHLT_Ele15_IsoVVVL_PFHT600\nHLT_Ele15_IsoVVVL_PFHT400_PFMET50\nHLT_Ele15_IsoVVVL_PFHT400\nHLT_Ele50_IsoVVVL_PFHT400\nHLT_Mu8_TrkIsoVVL_DiPFJet40_DEta3p5_MJJ750_HTT300_PFMETNoMu60\nHLT_Mu10_TrkIsoVVL_DiPFJet40_DEta3p5_MJJ750_HTT350_PFMETNoMu60\nHLT_Mu15_IsoVVVL_BTagCSV_p067_PFHT400\nHLT_Mu15_IsoVVVL_PFHT600\nHLT_Mu15_IsoVVVL_PFHT400_PFMET50\nHLT_Mu15_IsoVVVL_PFHT400\nHLT_Mu50_IsoVVVL_PFHT400\nHLT_Dimuon16_Jpsi\nHLT_Dimuon8_PsiPrime_Barrel\nHLT_Dimuon8_Upsilon_Barrel\nHLT_Dimuon0_Phi_Barrel\nHLT_TrkMu15_DoubleTrkMu5NoFiltersNoVtx\nHLT_TrkMu17_DoubleTrkMu8NoFiltersNoVtx\nHLT_Mu8\nHLT_Mu17\nHLT_Mu3_PFJet40\nHLT_Ele8_CaloIdM_TrackIdM_PFJet30\nHLT_Ele12_CaloIdM_TrackIdM_PFJet30\nHLT_Ele17_CaloIdM_TrackIdM_PFJet30\nHLT_Ele23_CaloIdM_TrackIdM_PFJet30\nHLT_Ele50_CaloIdVT_GsfTrkIdT_PFJet165\nHLT_PFHT400_SixJet30_DoubleBTagCSV_p056\nHLT_PFHT450_SixJet40_BTagCSV_p056\nHLT_PFHT400_SixJet30\nHLT_PFHT450_SixJet40\nHLT_Ele115_CaloIdVT_GsfTrkIdT\nHLT_Ele145_CaloIdVT_GsfTrkIdT\nHLT_Ele200_CaloIdVT_GsfTrkIdT\nHLT_Mu55\nHLT_Photon42_R9Id85_OR_CaloId24b40e_Iso50T80L_Photon25_AND_HE10_R9Id65_Eta2_Mass15\nHLT_Photon90_CaloIdL_PFHT600\nHLT_FullTracks_Multiplicity80\nHLT_FullTracks_Multiplicity100\nHLT_FullTracks_Multiplicity130\nHLT_FullTracks_Multiplicity150\nHLT_ECALHT800\nHLT_DiSC30_18_EIso_AND_HE_Mass70\nHLT_MET200\nHLT_Ele27_HighEta_Ele20_Mass55\nHLT_L1FatEvents\nHLT_Physics\nHLT_L1FatEvents_part0\nHLT_L1FatEvents_part1\nHLT_L1FatEvents_part2\nHLT_L1FatEvents_part3\nHLT_Random\nHLT_ZeroBias\nHLT_ZeroBias_part0\nHLT_ZeroBias_part1\nHLT_ZeroBias_part2\nHLT_ZeroBias_part3\nHLT_ZeroBias_part4\nHLT_ZeroBias_part5\nHLT_ZeroBias_part6\nHLT_ZeroBias_part7\nHLT_AK4CaloJet30\nHLT_AK4CaloJet40\nHLT_AK4CaloJet50\nHLT_AK4CaloJet80\nHLT_AK4CaloJet100\nHLT_AK4PFJet30\nHLT_AK4PFJet50\nHLT_AK4PFJet80\nHLT_AK4PFJet100\nHLT_HISinglePhoton10\nHLT_HISinglePhoton15\nHLT_HISinglePhoton20\nHLT_HISinglePhoton40\nHLT_HISinglePhoton60\nHLT_EcalCalibration\nHLT_HcalCalibration\nHLT_GlobalRunHPDNoise\nHLT_L1BptxMinus\nHLT_L1BptxPlus\nHLT_L1NotBptxOR\nHLT_L1MinimumBiasHF_OR_part0\nHLT_L1MinimumBiasHF_OR_part1\nHLT_L1MinimumBiasHF_OR_part2\nHLT_L1MinimumBiasHF_OR_part3\nHLT_L1MinimumBiasHF_OR_part4\nHLT_L1MinimumBiasHF_OR_part5\nHLT_L1MinimumBiasHF_OR_part6\nHLT_L1MinimumBiasHF_OR_part7\nHLT_L1MinimumBiasHF_OR_part8\nHLT_L1MinimumBiasHF_OR_part9\nHLT_L1MinimumBiasHF_AND\nHLT_HcalNZS\nHLT_HcalPhiSym\nHLT_HcalIsolatedbunch\nHLT_ZeroBias_FirstCollisionAfterAbortGap\nHLT_ZeroBias_FirstCollisionAfterAbortGap_copy\nHLT_ZeroBias_IsolatedBunches\nHLT_ZeroBias_FirstCollisionInTrain\nHLT_ZeroBias_FirstBXAfterTrain\nHLT_Photon500\nHLT_Photon600\nHLT_Mu300\nHLT_Mu350\nHLT_MET250\nHLT_MET300\nHLT_MET600\nHLT_MET700\nHLT_PFMET300\nHLT_PFMET400\nHLT_PFMET500\nHLT_PFMET600\nHLT_Ele250_CaloIdVT_GsfTrkIdT\nHLT_Ele300_CaloIdVT_GsfTrkIdT\nHLT_HT2000\nHLT_HT2500\nHLT_IsoTrackHE\nHLT_IsoTrackHB\n</code></pre> <pre><code>#import uproot\n\nsample = \"ttbar-semileptonic\"\n\nroot_path = fileset[sample][\"files\"][0]\nprint(\"Open:\", root_path)\n\nf = uproot.open(root_path)\nevents = f[\"Events\"]\n\nprint(\"# events:\", events.num_entries)\n\nall_keys = events.keys()\nprint(f\"Total braches : {len(all_keys)}\")\n\n</code></pre> <pre><code>Open: root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v1/120000/08FCB2ED-176B-064B-85AB-37B898773B98.root\n# events: 1233000\nTotal braches : 1504\n</code></pre> <pre><code>#from dpoa_workshop import pretty_print\n\npretty_print(all_keys, fmt='35s', require='Muon')\npretty_print(all_keys, fmt='35s', require='Electron')\npretty_print(all_keys, fmt='35s', require='Jet')\npretty_print(all_keys, fmt='35s', require='MET')\n\n</code></pre> <pre><code>Jet_nMuons                          L1PreFiringWeight_Muon_Nom          \nL1PreFiringWeight_Muon_StatDn       L1PreFiringWeight_Muon_StatUp       \nL1PreFiringWeight_Muon_SystDn       L1PreFiringWeight_Muon_SystUp       nMuon                               \nMuon_dxy                            Muon_dxyErr                         \nMuon_dxybs                          Muon_dz                             \nMuon_dzErr                          Muon_eta                            \nMuon_ip3d                           Muon_jetPtRelv2                     \nMuon_jetRelIso                      Muon_mass                           \nMuon_miniPFRelIso_all               Muon_miniPFRelIso_chg               \nMuon_pfRelIso03_all                 Muon_pfRelIso03_chg                 \nMuon_pfRelIso04_all                 Muon_phi                            Muon_pt                             \nMuon_ptErr                          Muon_segmentComp                    \nMuon_sip3d                          Muon_softMva                        \nMuon_tkRelIso                       Muon_tunepRelPt                     \nMuon_mvaLowPt                       Muon_mvaTTH                         \nMuon_charge                         Muon_jetIdx                         \nMuon_nStations                      Muon_nTrackerLayers                 \nMuon_pdgId                          Muon_tightCharge                    \nMuon_fsrPhotonIdx                   Muon_highPtId                       \nMuon_highPurity                     Muon_inTimeMuon                     \nMuon_isGlobal                       Muon_isPFcand                       \nMuon_isStandalone                   Muon_isTracker                      \nMuon_jetNDauCharged                 Muon_looseId                        \nMuon_mediumId                       Muon_mediumPromptId                 \nMuon_miniIsoId                      Muon_multiIsoId                     \nMuon_mvaId                          Muon_mvaLowPtId                     \nMuon_pfIsoId                        Muon_puppiIsoId                     \nMuon_softId                         Muon_softMvaId                      \nMuon_tightId                        Muon_tkIsoId                        \nMuon_triggerIdLoose                 Muon_genPartIdx                     \nMuon_genPartFlav                    Muon_cleanmask                      \nFlag_BadPFMuonFilter                Flag_BadPFMuonDzFilter              \nFlag_BadPFMuonSummer16Filter        HLT_Dimuon0_Jpsi_Muon               \nHLT_Dimuon0_Upsilon_Muon            HLT_QuadMuon0_Dimuon0_Jpsi          \nHLT_QuadMuon0_Dimuon0_Upsilon       \nnElectron                           Electron_dEscaleDown                \nElectron_dEscaleUp                  Electron_dEsigmaDown                \nElectron_dEsigmaUp                  Electron_deltaEtaSC                 \nElectron_dr03EcalRecHitSumEt        Electron_dr03HcalDepth1TowerSumEt   \nElectron_dr03TkSumPt                Electron_dr03TkSumPtHEEP            \nElectron_dxy                        Electron_dxyErr                     \nElectron_dz                         Electron_dzErr                      \nElectron_eCorr                      Electron_eInvMinusPInv              \nElectron_energyErr                  Electron_eta                        \nElectron_hoe                        Electron_ip3d                       \nElectron_jetPtRelv2                 Electron_jetRelIso                  \nElectron_mass                       Electron_miniPFRelIso_all           \nElectron_miniPFRelIso_chg           Electron_mvaFall17V2Iso             \nElectron_mvaFall17V2noIso           Electron_pfRelIso03_all             \nElectron_pfRelIso03_chg             Electron_phi                        \nElectron_pt                         Electron_r9                         \nElectron_scEtOverPt                 Electron_sieie                      \nElectron_sip3d                      Electron_mvaTTH                     \nElectron_charge                     Electron_cutBased                   \nElectron_jetIdx                     Electron_pdgId                      \nElectron_photonIdx                  Electron_tightCharge                \nElectron_vidNestedWPBitmap          Electron_vidNestedWPBitmapHEEP      \nElectron_convVeto                   Electron_cutBased_HEEP              \nElectron_isPFcand                   Electron_jetNDauCharged             \nElectron_lostHits                   Electron_mvaFall17V2Iso_WP80        \nElectron_mvaFall17V2Iso_WP90        Electron_mvaFall17V2Iso_WPL         \nElectron_mvaFall17V2noIso_WP80      Electron_mvaFall17V2noIso_WP90      \nElectron_mvaFall17V2noIso_WPL       Electron_seedGain                   \nJet_nElectrons                      nLowPtElectron                      \nLowPtElectron_ID                    LowPtElectron_convVtxRadius         \nLowPtElectron_deltaEtaSC            LowPtElectron_dxy                   \nLowPtElectron_dxyErr                LowPtElectron_dz                    \nLowPtElectron_dzErr                 LowPtElectron_eInvMinusPInv         \nLowPtElectron_embeddedID            LowPtElectron_energyErr             \nLowPtElectron_eta                   LowPtElectron_hoe                   \nLowPtElectron_mass                  LowPtElectron_miniPFRelIso_all      \nLowPtElectron_miniPFRelIso_chg      LowPtElectron_phi                   \nLowPtElectron_pt                    LowPtElectron_ptbiased              \nLowPtElectron_r9                    LowPtElectron_scEtOverPt            \nLowPtElectron_sieie                 LowPtElectron_unbiased              \nLowPtElectron_charge                LowPtElectron_convWP                \nLowPtElectron_pdgId                 LowPtElectron_convVeto              \nLowPtElectron_lostHits              Electron_genPartIdx                 \nElectron_genPartFlav                LowPtElectron_genPartIdx            \nLowPtElectron_genPartFlav           Electron_cleanmask                  \nnCorrT1METJet                       CorrT1METJet_area                   \nCorrT1METJet_eta                    CorrT1METJet_muonSubtrFactor        \nCorrT1METJet_phi                    CorrT1METJet_rawPt                  nFatJet                             \nFatJet_area                         FatJet_btagCSVV2                    \nFatJet_btagDDBvLV2                  FatJet_btagDDCvBV2                  \nFatJet_btagDDCvLV2                  FatJet_btagDeepB                    \nFatJet_btagHbb                      FatJet_deepTagMD_H4qvsQCD           \nFatJet_deepTagMD_HbbvsQCD           FatJet_deepTagMD_TvsQCD             \nFatJet_deepTagMD_WvsQCD             FatJet_deepTagMD_ZHbbvsQCD          \nFatJet_deepTagMD_ZHccvsQCD          FatJet_deepTagMD_ZbbvsQCD           \nFatJet_deepTagMD_ZvsQCD             FatJet_deepTagMD_bbvsLight          \nFatJet_deepTagMD_ccvsLight          FatJet_deepTag_H                    \nFatJet_deepTag_QCD                  FatJet_deepTag_QCDothers            \nFatJet_deepTag_TvsQCD               FatJet_deepTag_WvsQCD               \nFatJet_deepTag_ZvsQCD               FatJet_eta                          \nFatJet_mass                         FatJet_msoftdrop                    \nFatJet_n2b1                         FatJet_n3b1                         \nFatJet_particleNetMD_QCD            FatJet_particleNetMD_Xbb            \nFatJet_particleNetMD_Xcc            FatJet_particleNetMD_Xqq            \nFatJet_particleNet_H4qvsQCD         FatJet_particleNet_HbbvsQCD         \nFatJet_particleNet_HccvsQCD         FatJet_particleNet_QCD              \nFatJet_particleNet_TvsQCD           FatJet_particleNet_WvsQCD           \nFatJet_particleNet_ZvsQCD           FatJet_particleNet_mass             \nFatJet_phi                          FatJet_pt                           \nFatJet_rawFactor                    FatJet_tau1                         \nFatJet_tau2                         FatJet_tau3                         \nFatJet_tau4                         FatJet_lsf3                         \nFatJet_jetId                        FatJet_subJetIdx1                   \nFatJet_subJetIdx2                   FatJet_electronIdx3SJ               \nFatJet_muonIdx3SJ                   FatJet_nConstituents                \nnGenJetAK8                          GenJetAK8_eta                       \nGenJetAK8_mass                      GenJetAK8_phi                       \nGenJetAK8_pt                        nGenJet                             \nGenJet_eta                          GenJet_mass                         \nGenJet_phi                          GenJet_pt                           \nnSubGenJetAK8                       SubGenJetAK8_eta                    \nSubGenJetAK8_mass                   SubGenJetAK8_phi                    \nSubGenJetAK8_pt                     nJet                                Jet_area                            \nJet_btagCSVV2                       Jet_btagDeepB                       \nJet_btagDeepCvB                     Jet_btagDeepCvL                     \nJet_btagDeepFlavB                   Jet_btagDeepFlavCvB                 \nJet_btagDeepFlavCvL                 Jet_btagDeepFlavQG                  \nJet_chEmEF                          Jet_chFPV0EF                        \nJet_chHEF                           Jet_eta                             \nJet_hfsigmaEtaEta                   Jet_hfsigmaPhiPhi                   Jet_mass                            \nJet_muEF                            Jet_muonSubtrFactor                 \nJet_neEmEF                          Jet_neHEF                           Jet_phi                             \nJet_pt                              Jet_puIdDisc                        Jet_qgl                             \nJet_rawFactor                       Jet_bRegCorr                        \nJet_bRegRes                         Jet_cRegCorr                        \nJet_cRegRes                         Jet_electronIdx1                    \nJet_electronIdx2                    Jet_hfadjacentEtaStripsSize         \nJet_hfcentralEtaStripSize           Jet_jetId                           \nJet_muonIdx1                        Jet_muonIdx2                        \nJet_nElectrons                      Jet_nMuons                          Jet_puId                            \nJet_nConstituents                   nSoftActivityJet                    \nSoftActivityJet_eta                 SoftActivityJet_phi                 \nSoftActivityJet_pt                  SoftActivityJetHT                   \nSoftActivityJetHT10                 SoftActivityJetHT2                  \nSoftActivityJetHT5                  SoftActivityJetNjets10              \nSoftActivityJetNjets2               SoftActivityJetNjets5               nSubJet                             \nSubJet_btagCSVV2                    SubJet_btagDeepB                    \nSubJet_eta                          SubJet_mass                         \nSubJet_n2b1                         SubJet_n3b1                         \nSubJet_phi                          SubJet_pt                           \nSubJet_rawFactor                    SubJet_tau1                         \nSubJet_tau2                         SubJet_tau3                         \nSubJet_tau4                         FatJet_genJetAK8Idx                 \nFatJet_hadronFlavour                FatJet_nBHadrons                    \nFatJet_nCHadrons                    GenJetAK8_partonFlavour             \nGenJetAK8_hadronFlavour             GenJet_partonFlavour                \nGenJet_hadronFlavour                Jet_genJetIdx                       \nJet_hadronFlavour                   Jet_partonFlavour                   \nJet_cleanmask                       SubJet_hadronFlavour                \nSubJet_nBHadrons                    SubJet_nCHadrons                    \nL1_DoubleJet12_ForwardBackward      L1_DoubleJet16_ForwardBackward      \nL1_DoubleJet8_ForwardBackward       L1_DoubleJetC100                    \nL1_DoubleJetC112                    L1_DoubleJetC120                    \nL1_DoubleJetC40                     L1_DoubleJetC50                     \nL1_DoubleJetC60                     L1_DoubleJetC60_ETM60               \nL1_DoubleJetC80                     L1_ETM75_Jet60_dPhi_Min0p4          \nL1_Jet32_DoubleMu_10_0_dPhi_Jet_Mu0_Max0p4_dPhi_Mu_Mu_Min1p0 \nL1_Jet32_Mu0_EG10_dPhi_Jet_Mu_Max0p4_dPhi_Mu_EG_Min1p0 L1_Mu3_JetC120                      \nL1_Mu3_JetC120_dEta_Max0p4_dPhi_Max0p4 L1_Mu3_JetC16                       \nL1_Mu3_JetC16_dEta_Max0p4_dPhi_Max0p4 L1_Mu3_JetC60                       \nL1_Mu3_JetC60_dEta_Max0p4_dPhi_Max0p4 L1_QuadJetC36_Tau52                 \nL1_QuadJetC40                       L1_QuadJetC50                       \nL1_QuadJetC60                       L1_SingleJet120                     \nL1_SingleJet12_BptxAND              L1_SingleJet140                     \nL1_SingleJet150                     L1_SingleJet16                      \nL1_SingleJet160                     L1_SingleJet170                     \nL1_SingleJet180                     L1_SingleJet20                      \nL1_SingleJet200                     L1_SingleJet35                      \nL1_SingleJet60                      L1_SingleJet8_BptxAND               \nL1_SingleJet90                      L1_SingleJetC20_NotBptxOR           \nL1_SingleJetC20_NotBptxOR_3BX       L1_SingleJetC32_NotBptxOR           \nL1_SingleJetC32_NotBptxOR_3BX       L1_SingleJetC36_NotBptxOR_3BX       \nL1_TripleJet_84_68_48_VBF           L1_TripleJet_88_72_56_VBF           \nL1_TripleJet_92_76_64_VBF           HLT_AK8PFJet360_TrimMass30          \nHLT_AK8PFJet400_TrimMass30          HLT_AK8DiPFJet300_200_TrimMass30_BTagCSV_p20 \nHLT_AK8DiPFJet280_200_TrimMass30_BTagCSV_p087 \nHLT_AK8DiPFJet300_200_TrimMass30_BTagCSV_p087 HLT_AK8DiPFJet300_200_TrimMass30    \nHLT_AK8DiPFJet280_200_TrimMass30    HLT_AK8DiPFJet250_200_TrimMass30    \nHLT_AK8DiPFJet280_200_TrimMass30_BTagCSV_p20 \nHLT_AK8DiPFJet250_200_TrimMass30_BTagCSV_p20 HLT_CaloJet260                      \nHLT_CaloJet500_NoJetID              HLT_Ele27_WPTight_Gsf_L1JetTauSeeded \nHLT_Ele35_CaloIdVT_GsfTrkIdT_PFJet150_PFJet50 \nHLT_Ele45_WPLoose_Gsf_L1JetTauSeeded \nHLT_Ele45_CaloIdVT_GsfTrkIdT_PFJet200_PFJet50 HLT_JetE30_NoBPTX3BX                \nHLT_JetE30_NoBPTX                   HLT_JetE50_NoBPTX3BX                \nHLT_JetE70_NoBPTX3BX                HLT_Mu30_eta2p1_PFJet150_PFJet50    \nHLT_Mu40_eta2p1_PFJet200_PFJet50    \nHLT_Mu33NoFiltersNoVtxDisplaced_DisplacedJet50_Tight \nHLT_Mu33NoFiltersNoVtxDisplaced_DisplacedJet50_Loose \nHLT_Mu28NoFiltersNoVtx_DisplacedJet40_Loose \nHLT_Mu38NoFiltersNoVtxDisplaced_DisplacedJet60_Tight \nHLT_Mu38NoFiltersNoVtxDisplaced_DisplacedJet60_Loose \nHLT_Mu38NoFiltersNoVtx_DisplacedJet60_Loose \nHLT_Mu28NoFiltersNoVtx_CentralCaloJet40 HLT_PFHT550_4JetPt50                \nHLT_PFHT650_4JetPt50                HLT_PFHT750_4JetPt50                \nHLT_PFHT750_4JetPt70                HLT_PFHT750_4JetPt80                \nHLT_PFHT800_4JetPt50                HLT_PFHT850_4JetPt50                \nHLT_PFJet15_NoCaloMatched           HLT_PFJet25_NoCaloMatched           \nHLT_DiPFJet15_NoCaloMatched         HLT_DiPFJet25_NoCaloMatched         \nHLT_DiPFJet15_FBEta3_NoCaloMatched  HLT_DiPFJet25_FBEta3_NoCaloMatched  \nHLT_DiPFJetAve15_HFJEC              HLT_DiPFJetAve25_HFJEC              \nHLT_DiPFJetAve35_HFJEC              HLT_AK8PFJet40                      \nHLT_AK8PFJet60                      HLT_AK8PFJet80                      \nHLT_AK8PFJet140                     HLT_AK8PFJet200                     \nHLT_AK8PFJet260                     HLT_AK8PFJet320                     \nHLT_AK8PFJet400                     HLT_AK8PFJet450                     \nHLT_AK8PFJet500                     HLT_PFJet40                         \nHLT_PFJet60                         HLT_PFJet80                         \nHLT_PFJet140                        HLT_PFJet200                        \nHLT_PFJet260                        HLT_PFJet320                        \nHLT_PFJet400                        HLT_PFJet450                        \nHLT_PFJet500                        HLT_DiPFJetAve40                    \nHLT_DiPFJetAve60                    HLT_DiPFJetAve80                    \nHLT_DiPFJetAve140                   HLT_DiPFJetAve200                   \nHLT_DiPFJetAve260                   HLT_DiPFJetAve320                   \nHLT_DiPFJetAve400                   HLT_DiPFJetAve500                   \nHLT_DiPFJetAve60_HFJEC              HLT_DiPFJetAve80_HFJEC              \nHLT_DiPFJetAve100_HFJEC             HLT_DiPFJetAve160_HFJEC             \nHLT_DiPFJetAve220_HFJEC             HLT_DiPFJetAve300_HFJEC             \nHLT_DiPFJet40_DEta3p5_MJJ600_PFMETNoMu140 \nHLT_DiPFJet40_DEta3p5_MJJ600_PFMETNoMu80 HLT_DiCentralPFJet170               \nHLT_SingleCentralPFJet170_CFMax0p1  HLT_DiCentralPFJet170_CFMax0p1      \nHLT_DiCentralPFJet220_CFMax0p3      HLT_DiCentralPFJet330_CFMax0p5      \nHLT_DiCentralPFJet430               HLT_PFHT200_DiPFJetAve90_PFAlphaT0p57 \nHLT_PFHT200_DiPFJetAve90_PFAlphaT0p63 HLT_PFHT250_DiPFJetAve90_PFAlphaT0p55 \nHLT_PFHT250_DiPFJetAve90_PFAlphaT0p58 HLT_PFHT300_DiPFJetAve90_PFAlphaT0p53 \nHLT_PFHT300_DiPFJetAve90_PFAlphaT0p54 HLT_PFHT350_DiPFJetAve90_PFAlphaT0p52 \nHLT_PFHT350_DiPFJetAve90_PFAlphaT0p53 HLT_PFHT400_DiPFJetAve90_PFAlphaT0p51 \nHLT_PFHT400_DiPFJetAve90_PFAlphaT0p52 HLT_PFMET170_JetIdCleaned           \nHLT_QuadPFJet_BTagCSV_p016_p11_VBF_Mqq200 HLT_QuadPFJet_BTagCSV_p016_VBF_Mqq460 \nHLT_QuadPFJet_BTagCSV_p016_p11_VBF_Mqq240 HLT_QuadPFJet_BTagCSV_p016_VBF_Mqq500 \nHLT_QuadPFJet_VBF                   HLT_L1_TripleJet_VBF                \nHLT_QuadJet45_TripleBTagCSV_p087    HLT_QuadJet45_DoubleBTagCSV_p087    \nHLT_DoubleJet90_Double30_TripleBTagCSV_p087 \nHLT_DoubleJet90_Double30_DoubleBTagCSV_p087 \nHLT_DoubleJetsC100_DoubleBTagCSV_p026_DoublePFJetsC160 \nHLT_DoubleJetsC100_DoubleBTagCSV_p014_DoublePFJetsC100MaxDeta1p6 \nHLT_DoubleJetsC112_DoubleBTagCSV_p026_DoublePFJetsC172 \nHLT_DoubleJetsC112_DoubleBTagCSV_p014_DoublePFJetsC112MaxDeta1p6 \nHLT_DoubleJetsC100_SingleBTagCSV_p026 HLT_DoubleJetsC100_SingleBTagCSV_p014 \nHLT_DoubleJetsC100_SingleBTagCSV_p026_SinglePFJetC350 \nHLT_DoubleJetsC100_SingleBTagCSV_p014_SinglePFJetC350 \nHLT_Ele8_CaloIdL_TrackIdL_IsoVL_PFJet30 HLT_Ele12_CaloIdL_TrackIdL_IsoVL_PFJet30 \nHLT_Ele17_CaloIdL_TrackIdL_IsoVL_PFJet30 \nHLT_Ele23_CaloIdL_TrackIdL_IsoVL_PFJet30 HLT_BTagMu_DiJet20_Mu5              \nHLT_BTagMu_DiJet40_Mu5              HLT_BTagMu_DiJet70_Mu5              \nHLT_BTagMu_DiJet110_Mu5             HLT_BTagMu_DiJet170_Mu5             \nHLT_BTagMu_Jet300_Mu5               HLT_BTagMu_AK8Jet300_Mu5            \nHLT_Ele23_Ele12_CaloIdL_TrackIdL_IsoVL_DZ_L1JetTauSeeded \nHLT_PFHT650_WideJetMJJ900DEtaJJ1p5  HLT_PFHT650_WideJetMJJ950DEtaJJ1p5  \nHLT_Rsq0p02_MR300_TriPFJet80_60_40_BTagCSV_p063_p20_Mbb60_200 \nHLT_Rsq0p02_MR400_TriPFJet80_60_40_DoubleBTagCSV_p063_Mbb60_200 \nHLT_Rsq0p02_MR450_TriPFJet80_60_40_DoubleBTagCSV_p063_Mbb60_200 \nHLT_Rsq0p02_MR500_TriPFJet80_60_40_DoubleBTagCSV_p063_Mbb60_200 \nHLT_Rsq0p02_MR550_TriPFJet80_60_40_DoubleBTagCSV_p063_Mbb60_200 \nHLT_VBF_DisplacedJet40_DisplacedTrack \nHLT_VBF_DisplacedJet40_DisplacedTrack_2TrackIP2DSig5 \nHLT_VBF_DisplacedJet40_TightID_DisplacedTrack HLT_VBF_DisplacedJet40_Hadronic     \nHLT_VBF_DisplacedJet40_Hadronic_2PromptTrack \nHLT_VBF_DisplacedJet40_TightID_Hadronic HLT_VBF_DisplacedJet40_VTightID_Hadronic \nHLT_VBF_DisplacedJet40_VVTightID_Hadronic \nHLT_VBF_DisplacedJet40_VTightID_DisplacedTrack \nHLT_VBF_DisplacedJet40_VVTightID_DisplacedTrack \nHLT_MonoCentralPFJet80_PFMETNoMu90_PFMHTNoMu90_IDTight \nHLT_MonoCentralPFJet80_PFMETNoMu100_PFMHTNoMu100_IDTight \nHLT_MonoCentralPFJet80_PFMETNoMu110_PFMHTNoMu110_IDTight \nHLT_MonoCentralPFJet80_PFMETNoMu120_PFMHTNoMu120_IDTight \nHLT_Mu10_CentralPFJet30_BTagCSV_p13 \nHLT_Ele10_CaloIdM_TrackIdM_CentralPFJet30_BTagCSV_p13 \nHLT_Mu8_TrkIsoVVL_DiPFJet40_DEta3p5_MJJ750_HTT300_PFMETNoMu60 \nHLT_Mu10_TrkIsoVVL_DiPFJet40_DEta3p5_MJJ750_HTT350_PFMETNoMu60 HLT_Mu3_PFJet40                     \nHLT_Ele8_CaloIdM_TrackIdM_PFJet30   HLT_Ele12_CaloIdM_TrackIdM_PFJet30  \nHLT_Ele17_CaloIdM_TrackIdM_PFJet30  HLT_Ele23_CaloIdM_TrackIdM_PFJet30  \nHLT_Ele50_CaloIdVT_GsfTrkIdT_PFJet140 HLT_Ele50_CaloIdVT_GsfTrkIdT_PFJet165 \nHLT_PFHT400_SixJet30_DoubleBTagCSV_p056 HLT_PFHT450_SixJet40_BTagCSV_p056   \nHLT_PFHT400_SixJet30                HLT_PFHT450_SixJet40                \nHLT_AK4CaloJet30                    HLT_AK4CaloJet40                    \nHLT_AK4CaloJet50                    HLT_AK4CaloJet80                    \nHLT_AK4CaloJet100                   HLT_AK4PFJet30                      \nHLT_AK4PFJet50                      HLT_AK4PFJet80                      \nHLT_AK4PFJet100                     \nCaloMET_phi                         CaloMET_pt                          \nCaloMET_sumEt                       ChsMET_phi                          \nChsMET_pt                           ChsMET_sumEt                        \nnCorrT1METJet                       CorrT1METJet_area                   \nCorrT1METJet_eta                    CorrT1METJet_muonSubtrFactor        \nCorrT1METJet_phi                    CorrT1METJet_rawPt                  \nDeepMETResolutionTune_phi           DeepMETResolutionTune_pt            \nDeepMETResponseTune_phi             DeepMETResponseTune_pt              \nGenMET_phi                          GenMET_pt                           \nMET_MetUnclustEnUpDeltaX            MET_MetUnclustEnUpDeltaY            \nMET_covXX                           MET_covXY                           \nMET_covYY                           MET_phi                             MET_pt                              \nMET_significance                    MET_sumEt                           \nMET_sumPtUnclustered                PuppiMET_phi                        \nPuppiMET_phiJERDown                 PuppiMET_phiJERUp                   \nPuppiMET_phiJESDown                 PuppiMET_phiJESUp                   \nPuppiMET_phiUnclusteredDown         PuppiMET_phiUnclusteredUp           \nPuppiMET_pt                         PuppiMET_ptJERDown                  \nPuppiMET_ptJERUp                    PuppiMET_ptJESDown                  \nPuppiMET_ptJESUp                    PuppiMET_ptUnclusteredDown          \nPuppiMET_ptUnclusteredUp            PuppiMET_sumEt                      \nRawMET_phi                          RawMET_pt                           \nRawMET_sumEt                        RawPuppiMET_phi                     \nRawPuppiMET_pt                      RawPuppiMET_sumEt                   \nTkMET_phi                           TkMET_pt                            \nTkMET_sumEt                         MET_fiducialGenPhi                  \nMET_fiducialGenPt                   Flag_METFilters                     \nHLT_HT250_CaloMET70                 HLT_Mu16_eta2p1_MET30               \nHLT_IsoMu16_eta2p1_MET30            \nHLT_IsoMu16_eta2p1_MET30_LooseIsoPFTau50_Trk30_eta2p1 \nHLT_LooseIsoPFTau50_Trk30_eta2p1_MET80 HLT_LooseIsoPFTau50_Trk30_eta2p1_MET90 \nHLT_LooseIsoPFTau50_Trk30_eta2p1_MET110 HLT_LooseIsoPFTau50_Trk30_eta2p1_MET120 \nHLT_PFHT300_PFMET100                HLT_PFHT300_PFMET110                \nHLT_DiPFJet40_DEta3p5_MJJ600_PFMETNoMu140 \nHLT_DiPFJet40_DEta3p5_MJJ600_PFMETNoMu80 HLT_MET60_IsoTrk35_Loose            \nHLT_MET75_IsoTrk50                  HLT_MET90_IsoTrk50                  \nHLT_PFMET120_BTagCSV_p067           HLT_PFMET120_Mu5                    \nHLT_PFMET170_NotCleaned             HLT_PFMET170_NoiseCleaned           \nHLT_PFMET170_HBHECleaned            HLT_PFMET170_JetIdCleaned           \nHLT_PFMET170_BeamHaloCleaned        HLT_PFMET170_HBHE_BeamHaloCleaned   \nHLT_PFMETTypeOne190_HBHE_BeamHaloCleaned HLT_PFMET90_PFMHT90_IDTight         \nHLT_PFMET100_PFMHT100_IDTight       \nHLT_PFMET100_PFMHT100_IDTight_BeamHaloCleaned HLT_PFMET110_PFMHT110_IDTight       \nHLT_PFMET120_PFMHT120_IDTight       \nHLT_CaloMHTNoPU90_PFMET90_PFMHT90_IDTight_BTagCSV_p067 \nHLT_CaloMHTNoPU90_PFMET90_PFMHT90_IDTight HLT_Photon135_PFMET100              \nHLT_Photon22_R9Id90_HE10_Iso40_EBOnly_PFMET40 \nHLT_Photon36_R9Id90_HE10_Iso40_EBOnly_PFMET40 \nHLT_Photon50_R9Id90_HE10_Iso40_EBOnly_PFMET40 \nHLT_Photon75_R9Id90_HE10_Iso40_EBOnly_PFMET40 \nHLT_Photon90_R9Id90_HE10_Iso40_EBOnly_PFMET40 \nHLT_Photon120_R9Id90_HE10_Iso40_EBOnly_PFMET40 HLT_Mu3er_PFHT140_PFMET125          \nHLT_Mu6_PFHT200_PFMET80_BTagCSV_p067 HLT_Mu6_PFHT200_PFMET100            \nHLT_Mu14er_PFMET100                 HLT_PFMETNoMu90_PFMHTNoMu90_IDTight \nHLT_PFMETNoMu100_PFMHTNoMu100_IDTight HLT_PFMETNoMu110_PFMHTNoMu110_IDTight \nHLT_PFMETNoMu120_PFMHTNoMu120_IDTight \nHLT_MonoCentralPFJet80_PFMETNoMu90_PFMHTNoMu90_IDTight \nHLT_MonoCentralPFJet80_PFMETNoMu100_PFMHTNoMu100_IDTight \nHLT_MonoCentralPFJet80_PFMETNoMu110_PFMHTNoMu110_IDTight \nHLT_MonoCentralPFJet80_PFMETNoMu120_PFMHTNoMu120_IDTight HLT_DoubleMu3_PFMET50               \nHLT_Ele15_IsoVVVL_PFHT350_PFMET50   HLT_Ele15_IsoVVVL_PFHT400_PFMET50   \nHLT_Mu8_TrkIsoVVL_DiPFJet40_DEta3p5_MJJ750_HTT300_PFMETNoMu60 \nHLT_Mu10_TrkIsoVVL_DiPFJet40_DEta3p5_MJJ750_HTT350_PFMETNoMu60 \nHLT_Mu15_IsoVVVL_PFHT350_PFMET50    HLT_Mu15_IsoVVVL_PFHT400_PFMET50    \nHLT_MET100                          HLT_MET150                          \nHLT_MET200                          HLT_MET250                          \nHLT_MET300                          HLT_MET600                          \nHLT_MET700                          HLT_PFMET300                        \nHLT_PFMET400                        HLT_PFMET500                        \nHLT_PFMET600\n</code></pre> <pre><code>if \"genWeight\" in events.keys():\n    gw = events[\"genWeight\"].array(entry_stop=100_000, library=\"np\")\n    print(f\"genWeight: mean={gw.mean():.3f}, std={gw.std():.3f}, negativos={(gw&lt;0).mean():.2%}\")\nelse:\n    print(\"There is no genWeight\")\n\n</code></pre> <pre><code>genWeight: mean=300.828, std=39.097, negativos=0.42%\n</code></pre> <p>Because std &gt; 0 and negativos &gt; 0, you have learned a golden rule for this dataset:</p> <p>NEVER count events.</p> <p>Wrong: N = len(events)</p> <p>Right: N = sum(events.genWeight)</p> <p>If you just count them (len), you will be wrong by 0.84% (counting the negatives as positives instead of subtracting them).</p> <p>\u201cNow the goal is to explore the characteristic variables of these events and visualize them. We are not applying any cuts yet; this step is simply to inspect the raw distributions. For this, we will use the following:\u201d</p> <p>Note:</p> <p>Notice that we could reuse the dictionary built earlier (<code>fileset</code>) to automatically loop over all available datasets. However, for debugging and flexibility, a manual list of datasets was defined. At the beginning, only a few datasets were used for quick tests, and later this list was expanded to match the same datasets contained in the <code>fileset</code>. This approach allows easier control during development while keeping compatibility with the full processing workflow.</p> <pre><code>#import uproot\n#import awkward as ak\n#import numpy as np\n#import matplotlib.pyplot as plt\n\n\nselected_datasets = [\n    'SingleMuon', 'SingleElectron', \n    'ttbar-semileptonic', 't-channel-top', 'ttW', \n    'WJets-HT400to600', 'DYJets-Zpt200', \n    'WW', 'ZZ', 'Zvv'\n]\n\nvariables = [\n    \"Muon_pt\", \"Muon_eta\",\n    \"Jet_pt\", \"Jet_btagDeepFlavB\", \n    \"MET_pt\",\n    \"nJet\", \"nMuon\", \"nElectron\"\n]\n\n\nmax_files = 1\n\n\ndata = {} \n\n\nfor ds_name in selected_datasets:\n\n    #################################3\n\n    if ds_name not in fileset:\n        print(f\"Skipping {ds_name}: Not found in fileset\")\n        continue\n     ####################################   \n\n\n    file_list = fileset[ds_name][\"files\"][:max_files]\n\n    print(f\"Reading {ds_name}: {len(file_list)} files...\")\n\n    # We need a temporary place to hold data chunks from multiple files\n    # Structure: temp_storage[\"Muon_pt\"] = [ [array_file1], [array_file2] ]\n    temp_storage = {var: [] for var in variables}\n\n    # Loop over the selected files\n    for file_path in file_list:\n        try:\n            with uproot.open(f\"{file_path}:Events\") as f:\n\n                # Read raw data\n                raw_data = f.arrays(variables, library=\"ak\")\n\n                for var in variables:\n                    # Flatten the data for this specific file\n                    flat_array = ak.to_numpy(ak.flatten(raw_data[var], axis=None))\n\n                    # Add to our temporary list\n                    temp_storage[var].append(flat_array)\n\n        except Exception as e:\n            print(f\"  Error reading file in {ds_name}: {e}\")\n\n\n    data[ds_name] = {}\n\n    for var in variables:\n        if len(temp_storage[var]) &gt; 0:\n            # np.concatenate joins the list of arrays into one big array\n            data[ds_name][var] = np.concatenate(temp_storage[var])\n        else:\n            data[ds_name][var] = np.array([]) # Empty if something went wrong\n\n\n</code></pre> <pre><code>Reading SingleMuon: 1 files...\nReading SingleElectron: 1 files...\nReading ttbar-semileptonic: 1 files...\nReading t-channel-top: 1 files...\nReading ttW: 1 files...\nReading WJets-HT400to600: 1 files...\nReading DYJets-Zpt200: 1 files...\nReading WW: 1 files...\nReading ZZ: 1 files...\nReading Zvv: 1 files...\n</code></pre> <pre><code>plt.rcParams.update({'font.size': 12})\n\nfor var in variables:\n\n    plt.figure(figsize=(8, 6))\n\n    # Loop through the data we just loaded\n    for ds_name in selected_datasets:\n\n        # Check if we have data for this combination\n        if ds_name in data and var in data[ds_name]:\n\n            values = data[ds_name][var]\n\n            # Check if empty\n            if len(values) == 0: continue\n\n\n\n       ########################################################     \n\n\n            plt.hist(\n                values, \n                bins=50, \n                # Automatic range: cut off the top 1% outliers so plot looks good\n                range=(0, np.percentile(values, 99)), \n                histtype='bar',   \n                linewidth=2,      \n                label=ds_name      # Name in legend\n            )\n\n    plt.xlabel(var)\n    plt.ylabel(\"Events\")\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>\u201cBecause data and MC have very different event counts, we cannot compare their raw histograms directly. For now, we normalize each distribution so that its integral equals 1. This lets us compare the shape of the variables without worrying about absolute yields:\u201d</p> <pre><code># --- NORMALIZATION ---\n# We create weights so the sum of the histogram equals 1.\n# This allows us to compare SHAPES, not counts.\nweights = np.ones_like(vals) / len(vals)\n</code></pre> <p>Then copy the previous block and add this line, and in plt.his add weights</p> <pre><code>\n\nplt.rcParams.update({'font.size': 12})\n\nfor var in variables:\n\n    plt.figure(figsize=(8, 6))\n\n    for ds_name in selected_datasets:\n\n        # Check for data\n        if ds_name in data and var in data[ds_name]:\n\n            vals = data[ds_name][var]\n            if len(vals) == 0: continue\n\n            # --- NORMALIZATION STEP ---\n            # Create an array of weights where every entry is (1 / total_events)\n            # When summed up by the histogram, the total area will be 1.0\n            weights = np.ones_like(vals) / len(vals)\n\n            # --- PLOT ---\n            plt.hist(\n                vals, \n                bins=50, \n                range=(0, np.percentile(vals, 99)), \n                weights=weights,   # APPLY WEIGHTS HERE\n                histtype='bar',   \n                linewidth=2,       \n                label=ds_name      \n            )\n\n    # Labels\n    plt.xlabel(var)\n    plt.ylabel(\"Fraction of Events (Normalized)\") # Changed label\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>The workflow proceeds in three main steps:</p> <ol> <li> <p>Apply the baseline selection    We first select events that match the single-lepton topology (electron or muon).    This removes events that clearly do not belong to the channel and defines the core event structure we will work with.</p> </li> <li> <p>Filter the events    After the baseline, we keep only the events that satisfy these basic criteria.    This produces a clean and well-defined sample for further analysis.</p> </li> <li> <p>Apply additional cuts to build CR and SR    With the filtered sample, we introduce extra requirements to define:</p> </li> <li> <p>Control Regions (CR): used to study and validate the dominant backgrounds.</p> </li> <li>Signal Region (SR): where the dark-matter search is performed.</li> </ol> <p>This step-by-step structure mirrors the logic used in the CMS paper and ensures a transparent and reproducible analysis flow.</p> <p>So all of this is reflected in the tables, which are directly the cuts we should use,  and we don't have to explore it ourselves in this case for this guide.</p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#base-line","title":"Base line","text":"<p>If you read the drafts</p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#table-10-baseline-selection-sl-and-ah","title":"Table 10 \u2014 Baseline Selection (SL and AH)","text":""},{"location":"Single_Lepton/Analisis_muon_final_version/#what-does-it-contain","title":"What does it contain?","text":"<p>The minimum or baseline selection that every event must satisfy before being assigned to any region (Signal or Control).</p> <p>It includes:</p> <ul> <li>Lepton quality and type (muons, electrons)</li> <li>Minimum cuts on pT and \u03b7</li> <li>Requirements on jets and b-jets</li> <li>Event-cleaning criteria</li> <li>Additional-lepton veto</li> </ul>"},{"location":"Single_Lepton/Analisis_muon_final_version/#what-is-it-for","title":"What is it for?","text":"<p>It acts as the universal first filter of the analysis. No event enters the SR or CR without passing this baseline.</p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#tables-11-and-12-expected-events-after-optimized-cuts-sl-and-ah","title":"Tables 11 and 12 \u2014 Expected Events After Optimized Cuts (SL and AH)","text":""},{"location":"Single_Lepton/Analisis_muon_final_version/#what-do-they-contain","title":"What do they contain?","text":"<p>Tables showing:</p> <ul> <li>Expected event yields for each background</li> <li>Predictions for different signal models</li> <li>Results after the baseline plus optimized cuts</li> </ul>"},{"location":"Single_Lepton/Analisis_muon_final_version/#what-is-it-for_1","title":"What is it for?","text":"<p>These tables serve only for internal validation in the paper:</p> <ul> <li>Checking consistency between simulated backgrounds and signals</li> <li>Showing how many events remain under different signal hypotheses</li> </ul> <pre><code>from IPython.display import Image, display\n\ndisplay(Image(filename=\"Table_10.png\"))\n\n</code></pre> <p></p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#single-muon","title":"Single Muon","text":"<p>1.\u201cLoad all physics objects (muons, electrons, jets, MET) from the ROOT file and package them as 4-vectors. This prepares the event for the physics selections that follow.\u201d</p> <p>2.\u201cApply the baseline selection: require exactly one tight muon, veto additional leptons, and apply the minimal MET requirement. This defines the core single-lepton topology before any SR or CR classification.\u201d</p> <p>3.\u201cClean all jets (quality, pT, \u0394R from the muon) and classify them as central or forward. Retain only events with at least two central jets, as required by the topology used in the analysis.\u201d</p> <p>4.Compute the physics variables used throughout the analysis: W transverse mass, jet multiplicities, b-tag multiplicity, min\u0394\u03c6(jets,MET), forward-jet count, and mT(b). These variables are the basis for the SR/CR definitions and the later shape studies.</p> <p>5.Package all selected events and computed variables into NumPy arrays. This standardized structure makes it easy to plot distributions, apply further event selection, or feed the results into statistical tools.</p> <pre><code>#import awkward as ak\n#import uproot\n#import numpy as np\n#colorsimport vector\nvector.register_awkward()\n\n#  1.  ###################################\n\ndef process_file_muon(filename, dataset=\"Unknown\", IS_DATA=False):\n\n    try:\n        with uproot.open(f\"{filename}:Events\") as tree:\n            muons = ak.zip({\n                \"pt\": tree[\"Muon_pt\"].array(),\n                \"eta\": tree[\"Muon_eta\"].array(),\n                \"phi\": tree[\"Muon_phi\"].array(),\n                \"mass\": tree[\"Muon_mass\"].array(),\n                \"iso\": tree[\"Muon_pfRelIso04_all\"].array(),\n                \"tightId\": tree[\"Muon_tightId\"].array(),\n                \"looseId\": tree[\"Muon_looseId\"].array(),\n            }, with_name=\"Momentum4D\")\n\n            electrons = ak.zip({\n                \"pt\": tree[\"Electron_pt\"].array(),\n                \"eta\": tree[\"Electron_eta\"].array(),\n                \"phi\": tree[\"Electron_phi\"].array(),\n                \"mass\": tree[\"Electron_mass\"].array(),\n                \"cutBased\": tree[\"Electron_cutBased\"].array(), \n            }, with_name=\"Momentum4D\")\n\n            jets = ak.zip({\n                \"pt\": tree[\"Jet_pt\"].array(),\n                \"eta\": tree[\"Jet_eta\"].array(),\n                \"phi\": tree[\"Jet_phi\"].array(),\n                \"mass\": tree[\"Jet_mass\"].array(),\n                \"jetId\": tree[\"Jet_jetId\"].array(),\n                \"btag\": tree[\"Jet_btagDeepFlavB\"].array(),\n            }, with_name=\"Momentum4D\")\n\n            met_pt = tree[\"MET_pt\"].array()\n            met_phi = tree[\"MET_phi\"].array()\n\n            if not IS_DATA:\n                gen_weight = tree[\"genWeight\"].array()\n            else:\n                gen_weight = ak.ones_like(met_pt)\n\n##############################################################################\n\n        # --- 2. SELECCI\u00d3N BASELINE ---\n\n\n        mu_tight_mask = (muons.pt &gt; 30) &amp; (abs(muons.eta) &lt; 2.4) &amp; (muons.tightId) &amp; (muons.iso &lt; 0.15)\n        mu_loose_mask = (muons.pt &gt; 10) &amp; (abs(muons.eta) &lt; 2.4) &amp; (muons.looseId) &amp; (muons.iso &lt; 0.25)\n        ele_veto_mask = (electrons.pt &gt; 10) &amp; (abs(electrons.eta) &lt; 2.5) &amp; (electrons.cutBased &gt;= 1)\n\n        good_muons = muons[mu_tight_mask]\n        veto_muons = muons[mu_loose_mask]\n        veto_electrons = electrons[ele_veto_mask]\n\n        has_1_tight_mu = (ak.num(good_muons) == 1)\n        veto_extra_lep = (ak.num(veto_muons) == 1) &amp; (ak.num(veto_electrons) == 0)\n        pass_met = met_pt &gt; 150 \n\n        event_mask = has_1_tight_mu &amp; veto_extra_lep &amp; pass_met\n\n        # Filtrado inicial\n        good_muons = good_muons[event_mask]\n        jets = jets[event_mask]\n        met_pt = met_pt[event_mask]\n        met_phi = met_phi[event_mask]\n        gen_weight = gen_weight[event_mask]\n\n        leading_mu = good_muons[:, 0]\n\n\n        # 3. ###########################################################3\n        jet_clean_mask = (\n            (jets.pt &gt; 30) &amp; \n            (jets.jetId &gt;= 1) &amp; \n            (jets.deltaR(leading_mu) &gt; 0.4)\n        )\n        all_clean_jets = jets[jet_clean_mask]\n\n        # B. Separar Central vs Forward (NUEVO)\n        central_jets = all_clean_jets[abs(all_clean_jets.eta) &lt; 2.4]\n        forward_jets = all_clean_jets[(abs(all_clean_jets.eta) &gt;= 2.4) &amp; (abs(all_clean_jets.eta) &lt; 5.0)]\n\n        has_2_jets = ak.num(central_jets) &gt;= 2\n\n        .###################################33###############################3\n\n        # --- 4. ################################################################3\n        f_met = met_pt[has_2_jets]\n        f_met_phi = met_phi[has_2_jets]\n        f_mu = leading_mu[has_2_jets]\n        f_central = central_jets[has_2_jets]\n        f_forward = forward_jets[has_2_jets]\n        f_gen_weight = gen_weight[has_2_jets]\n\n        # mT_W\n        dphi_lep = f_mu.phi - f_met_phi\n        mt_w = np.sqrt(2 * f_mu.pt * f_met * (1 - np.cos(dphi_lep)))\n\n        # min DeltaPhi\n        jets_top2 = f_central[:, :2]\n        dphi_jets = abs(jets_top2.phi - f_met_phi)\n        dphi_jets = np.mod(dphi_jets + np.pi, 2*np.pi) - np.pi\n        min_dphi = ak.min(abs(dphi_jets), axis=1)\n\n        # B-tagging\n        is_btag = f_central.btag &gt; 0.2770\n        n_btag = ak.sum(is_btag, axis=1)\n\n\n        # 1. Conteo Forward Jets\n        n_fwd = ak.num(f_forward)\n\n        # 2. mT_b (Masa Transversa MET - Leading b-jet)\n        b_jets = f_central[is_btag]\n        has_b = ak.num(b_jets) &gt; 0\n\n        # Padding seguro\n        b_jet_padded = ak.fill_none(ak.firsts(b_jets), {\"pt\": 0, \"phi\": 0}, axis=0)\n        dphi_b = b_jet_padded.phi - f_met_phi\n        calc_mt_b = np.sqrt(2 * b_jet_padded.pt * f_met * (1 - np.cos(dphi_b)))\n\n        mt_b_np = ak.to_numpy(calc_mt_b)\n        has_b_np = ak.to_numpy(has_b)\n        mt_b_np[~has_b_np] = -1.0 # Valor dummy\n\n        ###############################################################################\n\n######## 5 . #############################################################################\n\n        return {\n            \"dataset\": dataset,\n            \"lep_pt\": ak.to_numpy(f_mu.pt),\n            \"lep_eta\": ak.to_numpy(f_mu.eta),\n            \"met\": ak.to_numpy(f_met),\n            \"mT_W\": ak.to_numpy(mt_w),\n            \"genWeight\": ak.to_numpy(f_gen_weight),\n            \"nJet\": ak.to_numpy(ak.num(f_central)),\n            \"nBTag\": ak.to_numpy(n_btag),\n            \"min_dphi\": ak.to_numpy(min_dphi),\n\n            ## to use the processed datasets later \n            \"nForwardJets\": ak.to_numpy(n_fwd),\n            \"mT_b\": mt_b_np\n        }\n\n    except Exception as e:\n        print(f\"Error procesando {filename}: {e}\")\n        return None\n</code></pre> <p>BLOCK 1 \u2014 Dataset list (Muon Channel only)</p> <p>This block defines the list of datasets that will be processed with the muon selection logic.</p> <p>SingleMuon is data.</p> <p>Everything else is MC background. This allows the orchestrator to automatically detect whether generator weights exist.</p> <p>BLOCK 2 \u2014 Orchestrator function</p> <p>This function:</p> <p>Determines whether the dataset is Data or MC.</p> <p>Checks that the dataset exists in the global fileset.</p> <p>Loops over the first n_files files of the dataset.</p> <p>For each file:</p> <p>Calls process_file_muon() (the physics function you wrote earlier).</p> <p>Converts the returned dict into a pandas.DataFrame.</p> <p>Merges all partial DataFrames.</p> <p>Saves the result to a Parquet file under output_raw/.</p> <p>Returns the full DataFrame.</p> <p>This function does not perform physics. Its job is to:</p> <p>--loop</p> <p>--collect</p> <p>--assemble</p> <p>--save</p> <p>It is the \u201cmanager\u201d layer.</p> <p>BLOCK 3 \u2014 Execution loop</p> <p>This simply iterates over all muon-channel datasets and processes each one with a chosen number of input ROOT files per dataset.</p> <pre><code>#import pandas as pd\n#import os\n#import awkward as ak\n#import uproot\n#import numpy as np\n#import vector\n\nvector.register_awkward()\n\n# BLOCK 1 \u2014 DATASET LIST (Muon Channel Only)\n\n\ndatasets_muon_channel = [\n    'SingleMuon',           # DATA\n    'ttbar-semileptonic',   # Main background\n    'ttW', 'WW', 'ZZ', 'Zvv',\n    'DYJets-Zpt200',\n    't-channel-top',\n    'WJets-HT400to600'\n]\n\n\n# BLOCK 2 \u2014 ORCHESTRATOR FUNCTION (Muon Analysis Logic)\n\ndef process_dataset_muon_raw(dataset, n_files=5):\n    \"\"\"\n    High-level orchestrator:\n    - Determines if dataset is Data or MC\n    - Retrieves ROOT files\n    - Calls the muon-physics function (process_file_muon)\n    - Converts results to DataFrames\n    - Concatenates them and saves as a Parquet file\n    \"\"\"\n\n    # Check if dataset is Data (only SingleMuon)\n    is_data = \"SingleMuon\" in dataset\n\n    print(f\" Processing RAW {dataset} (Is Data: {is_data})...\")\n\n    # Verify that dataset exists in the global fileset\n    if dataset not in fileset:\n        print(f\" {dataset} not found in fileset. Skipping.\")\n        return None\n\n    # Select only the first n_files\n    files = fileset[dataset][\"files\"][:n_files]\n    dfs = []\n\n    for f in files:\n        try:\n            # Call your physics selection function\n            data_dict = process_file_muon(f, dataset=dataset, IS_DATA=is_data)\n\n            # Turn dict into DataFrame\n            df = pd.DataFrame(data_dict)\n            dfs.append(df)\n\n        except Exception as e:\n            # A single bad file should not stop the batch\n            print(f\" Error in file {f}: {e}\")\n\n    # If no results were generated\n    if len(dfs) == 0:\n        print(f\" No valid events produced for {dataset}\")\n        return None\n\n    # Merge all dataframes\n    full_df = pd.concat(dfs, ignore_index=True)\n\n    # Save as parquet in output_raw/\n    os.makedirs(\"output_raw\", exist_ok=True)\n    output_path = f\"output_raw/{dataset}_raw.parquet\"\n\n    full_df.to_parquet(output_path, index=False)\n    print(f\" Saved: {output_path} with {len(full_df)} events.\")\n\n    return full_df\n\n\n# BLOCK 3 \u2014 EXECUTION LOOP\n\n\nN_FILES = 10  # Increase to 20+ for proper statistics\n\nprint(f\"=== STARTING MUON PROCESSING ({N_FILES} files per dataset) ===\")\n\nfor ds in datasets_muon_channel:\n    process_dataset_muon_raw(ds, n_files=N_FILES)\n\n</code></pre> <pre><code>=== STARTING MUON PROCESSING (10 files per dataset) ===\n Processing RAW SingleMuon (Is Data: True)...\n Saved: output_raw/SingleMuon_raw.parquet with 10832 events.\n Processing RAW ttbar-semileptonic (Is Data: False)...\n Saved: output_raw/ttbar-semileptonic_raw.parquet with 108389 events.\n Processing RAW ttW (Is Data: False)...\n Saved: output_raw/ttW_raw.parquet with 85898 events.\n Processing RAW WW (Is Data: False)...\n Saved: output_raw/WW_raw.parquet with 8476 events.\n Processing RAW ZZ (Is Data: False)...\n Saved: output_raw/ZZ_raw.parquet with 100 events.\n Processing RAW Zvv (Is Data: False)...\n Saved: output_raw/Zvv_raw.parquet with 4 events.\n Processing RAW DYJets-Zpt200 (Is Data: False)...\n Saved: output_raw/DYJets-Zpt200_raw.parquet with 2240 events.\n Processing RAW t-channel-top (Is Data: False)...\n Saved: output_raw/t-channel-top_raw.parquet with 6811 events.\n Processing RAW WJets-HT400to600 (Is Data: False)...\n Saved: output_raw/WJets-HT400to600_raw.parquet with 49574 events.\n</code></pre>"},{"location":"Single_Lepton/Analisis_muon_final_version/#why-normalization-is-needed","title":"\u2014 Why Normalization Is Needed","text":"<p>This section introduces the central problem: data and MC cannot be compared directly because:</p> <ul> <li>Data reflects what the detector actually recorded.</li> <li>MC is generated with arbitrary numbers of events and must be rescaled.</li> </ul> <p>Your introduction sets the conceptual foundation: MC must be weighted so that its event yields match the luminosity of the data sample.</p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#what-this-enables","title":"What this enables","text":"<p>The next blocks will:</p> <ul> <li>Extract necessary metadata</li> <li>Compute normalization weights</li> <li>Apply them when building histograms</li> </ul> <p>Without this conceptual block, the following code would feel unmotivated.</p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#extracting-total-generated-weights-sumgenweights","title":"Extracting Total Generated Weights (<code>sumGenWeights</code>)","text":""},{"location":"Single_Lepton/Analisis_muon_final_version/#explanation","title":"Explanation","text":"<p>To compute the MC weight</p> \\[ w = \\frac{\\sigma \\cdot L}{N_{\\text{gen}}} \\] <p>we need the denominator: the number of generated events, usually stored as sum of generated event weights:</p> <pre><code>Runs/genEventSumw\n</code></pre> <p>This block reads that information efficiently from the <code>Runs</code> tree in each file.</p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#what-this-block-does-for-normalization","title":"What this block does for normalization","text":"<ul> <li>Provides N_gen \u2261 sumGenWeights</li> <li>Without it, normalization would be impossible</li> <li>For data, you correctly set the weight to 1 (data is never scaled)</li> </ul> <pre><code>#import uproot\n#import numpy as np\n\n\nsum_weights_map = {}\n\n\nprint(f\"{'Dataset':&lt;30} | {'SumW (Runs)':&lt;20}\")\nprint(\"-\" * 60)\n\nfor dataset_name, info in fileset.items():\n\n    # Identify data (data has no generator weights)\n    is_data = any(x in dataset_name for x in [\"SingleMuon\", \"SingleElectron\", \"MET\", \"EGamma\"])\n\n    if is_data:\n        sum_weights_map[dataset_name] = 1.0\n        print(f\"{dataset_name:&lt;30} | {'1.0 (DATA)':&lt;20}\")\n        continue\n\n    total_sum_w = 0.0\n    file_list = info[\"files\"]\n\n    for filename in file_list:\n        try:\n            with uproot.open(f\"{filename}:Runs\") as runs:\n                if \"genEventSumw\" in runs:\n                    w = runs[\"genEventSumw\"].array(library=\"np\")\n                    total_sum_w += np.sum(w)\n        except Exception as e:\n            print(f\" Error reading {filename}: {e}\")\n\n    sum_weights_map[dataset_name] = total_sum_w\n    print(f\"{dataset_name:&lt;30} | {total_sum_w:.2e}\")\n\nprint(\"\\n Normalization metadata loaded.\")\n\n</code></pre> <pre><code>Dataset                        | SumW (Runs)         \n------------------------------------------------------------\nmet                            | 0.00e+00\nSingleMuon                     | 1.0 (DATA)          \nSingleElectron                 | 1.0 (DATA)          \nttbar-semileptonic             | 4.35e+10\nttbar-hadronic                 | 3.36e+10\nt-channel-top                  | 2.30e+09\nttW                            | 1.11e+06\nWJets-HT400to600               | 2.12e+06\nDYJets-Zpt200                  | 7.51e+03\nWW                             | 1.58e+07\nZZ                             | 1.15e+06\nZvv                            | 6.47e+04\n\n Normalization metadata loaded.\n</code></pre>"},{"location":"Single_Lepton/Analisis_muon_final_version/#defining-the-physics-metadata-cross-sections-classification","title":"Defining the Physics Metadata (Cross Sections + Classification)","text":""},{"location":"Single_Lepton/Analisis_muon_final_version/#explanation_1","title":"Explanation","text":"<p>This block assigns:</p> <ul> <li>Cross sections (\u03c3)</li> <li>Dataset category (ttbar, WJets, etc.)</li> <li>Plotting style (colors)</li> </ul> <p>This is where you get the numerator of the weight formula:</p> <p>[ \\sigma \\cdot L ]</p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#how-it-connects-to-normalization","title":"How it connects to normalization","text":"<p>You now have:</p> <ul> <li>\u03c3 (from <code>fileset[ds][\"metadata\"]</code>)</li> <li>L (your chosen <code>LUM</code>)</li> <li>N_gen (from previous block)</li> </ul> <p>\u2192 Everything needed to compute per-event scale factors.</p> <pre><code>import pandas as pd\n\nLUM = 2590.0  # pb^-1\n\nDATA_SL = {\"SingleMuon\", \"SingleElectron\"}\n\nCOLOR_MAP = {\n    \"ttbar\":     \"#FF9933\", \n    \"WJets\":     \"#33CC33\", \n    \"ZJets\":     \"#3399FF\", \n    \"SingleTop\": \"#CC33CC\", \n    \"Diboson\":   \"#FFCC00\", \n    \"Rare\":      \"#FF0000\", \n    \"Other\":     \"#999999\"   \n}\n\ndef get_group_info(name):\n\n    #####################################################################################################\n    if \"ttW\" in name or \"ttZ\" in name: return \"Rare\", r\"$t\\bar{t}V$\", COLOR_MAP[\"Rare\"]\n    if \"ttbar\" in name: return \"ttbar\", r\"$t\\bar{t}$ Semileptonic\", COLOR_MAP[\"ttbar\"]\n    if \"channel\" in name or \"tW\" in name: return \"SingleTop\", r\"Single Top\", COLOR_MAP[\"SingleTop\"]\n    if \"WJets\" in name: return \"WJets\", r\"W+Jets\", COLOR_MAP[\"WJets\"]\n    if \"DY\" in name or \"Zvv\" in name: return \"ZJets\", r\"Z/$\\gamma^*$+Jets\", COLOR_MAP[\"ZJets\"]\n    if name in [\"WW\", \"ZZ\", \"WZ\"]: return \"Diboson\", r\"VV (Diboson)\", COLOR_MAP[\"Diboson\"]\n    return \"Other\", \"Other\", COLOR_MAP[\"Other\"]\n    ###############################################################################################\n\n\nprint(f\"{'Dataset':&lt;25} | {'Xsec [pb]':&lt;10} \"\n      f\"| {'SumGenWeights':&lt;15} | {'Scale Factor':&lt;12}\")\nprint(\"-\" * 70)\n\ndatasets_general_check = list(fileset.keys())\n\nfor ds in datasets_general_check:\n\n    # DATA\n    if ds in DATA_SL:\n        print(f\"{ds:&lt;25} | {'-':&lt;10} | {'-':&lt;15} | {'1.00':&lt;12}\")\n        continue\n\n    if ds not in fileset:\n        print(f\"{ds:&lt;25} | {'No fileset':&lt;10} | -\")\n        continue\n\n    xsec = fileset[ds][\"metadata\"][\"xsec\"]\n    sum_w = sum_weights_map.get(ds, 0.0)\n\n    if sum_w &gt; 0 and xsec is not None:\n        scale = (xsec * LUM) / sum_w\n        scale_str = f\"{scale:.2e}\"\n        if scale &gt; 10.0:\n            scale_str += \" HIGH\"\n        print(f\"{ds:&lt;25} | {xsec:&lt;10.2f} | {sum_w:&lt;15.2e} | {scale_str:&lt;12}\")\n\n    else:\n        reason = \"SumW=0\" if sum_w == 0 else \"Xsec=None\"\n        print(f\"{ds:&lt;25} | {str(xsec):&lt;10} | {sum_w:&lt;15.2e} | ERROR ({reason})\")\n\n</code></pre> <pre><code>Dataset                   | Xsec [pb]  | SumGenWeights   | Scale Factor\n----------------------------------------------------------------------\nmet                       | None       | 0.00e+00        | ERROR (SumW=0)\nSingleMuon                | -          | -               | 1.00        \nSingleElectron            | -          | -               | 1.00        \nttbar-semileptonic        | 364.35     | 4.35e+10        | 2.17e-05    \nttbar-hadronic            | 377.96     | 3.36e+10        | 2.91e-05    \nt-channel-top             | 136.02     | 2.30e+09        | 1.53e-04    \nttW                       | 0.20       | 1.11e+06        | 4.75e-04    \nWJets-HT400to600          | 48.91      | 2.12e+06        | 5.99e-02    \nDYJets-Zpt200             | 1.27       | 7.51e+03        | 4.38e-01    \nWW                        | 118.70     | 1.58e+07        | 1.94e-02    \nZZ                        | 16.60      | 1.15e+06        | 3.74e-02    \nZvv                       | 77.30      | 6.47e+04        | 3.09e+00\n</code></pre> <p>Inventory: We define exactly which datasets we want to mix.</p> <p>Loop &amp; Load: We iterate through the list, read the processed Parquet files (which are much faster than ROOT files), and load them into RAM.</p> <p>Normalization: We apply the physics weights immediately so every dataframe in all_dfs is ready to be plotted.</p> <p>Visualization: We trigger the plots right at the end.</p> <p>To produce publication-quality plots\u2014like those found in CMS analyses\u2014we need a function that:</p> <ol> <li>Builds histograms for each MC process, applying the final per-event normalization weight.</li> <li>Groups MC samples by physics category (tt\u0304, W+jets, Single Top, Diboson, etc.).</li> <li>Stacks the MC contributions in the correct order (smallest on top) so that the final shape reflects the Standard Model expectation.</li> <li>Overlays the real DATA histogram with error bars.</li> <li>Applies CMS styling, including the \u201cPreliminary\u201d tag and integrated luminosity.</li> <li>Ensures the plot is clean, readable, and suitable for analysis notes or a professional report.</li> </ol> <p>This function does exactly that. By defining it once, we ensure that every observable (pT, eta, MET, jets, etc.) is plotted consistently and in the same professional format used in CMS.</p> <pre><code>import mplhep as hep\nimport matplotlib.pyplot as plt\nplt.style.use(hep.style.CMS)\n\n\ndef plot_grouped_stack(var_name, x_label, x_range, channel_data=\"SingleMuon\",\n                       n_bins=30, log_scale=False):\n\n    # 1. Bines\n    bins = np.linspace(x_range[0], x_range[1], n_bins + 1)\n\n    grouped_counts = {}\n    grouped_info   = {}\n\n    # 2. AGRUPAR MC\n    for name, df in all_dfs.items():\n\n        # Ignore DATA here\n        if name in DATA_SL:\n            continue\n\n        group_key, label, color = get_group_info(name)\n\n        counts, _ = np.histogram(df[var_name], bins=bins, weights=df[\"final_weight\"])\n\n        if group_key not in grouped_counts:\n            grouped_counts[group_key] = counts\n            grouped_info[group_key]   = {\"label\": label, \"color\": color, \"yield\": np.sum(counts)}\n        else:\n            grouped_counts[group_key] += counts\n            grouped_info[group_key][\"yield\"] += np.sum(counts)\n\n    # 3. ORDENAR GRUPOS (por yield)\n    active_groups = list(grouped_info.keys())\n    active_groups.sort(key=lambda g: grouped_info[g][\"yield\"])  # small \u2192 top in stack\n\n    mc_counts = []\n    mc_colors = []\n    mc_labels = []\n    total_mc = np.zeros(n_bins)\n\n    for g in active_groups:\n        mc_counts.append(grouped_counts[g])\n        mc_colors.append(grouped_info[g][\"color\"])\n        mc_labels.append(grouped_info[g][\"label\"])\n        total_mc += grouped_counts[g]\n\n    # 4. DATA\n    df_data = all_dfs.get(channel_data)\n    if df_data is None:\n        print(f\"ERROR: No DATA found for channel {channel_data}\")\n        return\n\n    data_counts, _ = np.histogram(df_data[var_name], bins=bins)\n\n    # 5. PLOT\n    fig, ax = plt.subplots(figsize=(10, 8))\n\n    # --- MC STACK -----\n    if len(mc_counts) &gt; 0:\n        hep.histplot(\n            mc_counts,\n            bins=bins,\n            stack=True,\n            histtype=\"fill\",\n            color=mc_colors,\n            label=mc_labels,\n            edgecolor=\"black\",\n            linewidth=1,\n            ax=ax\n        )\n\n    # --- DATA -----\n    hep.histplot(\n        data_counts,\n        bins=bins,\n        histtype=\"errorbar\",\n        color=\"black\",\n        label=f\"{channel_data} (Data)\",\n        yerr=True,\n        marker=\"o\",\n        markersize=5,\n        ax=ax\n    )\n\n    # --- CMS Style -----\n    hep.cms.label(\"Preliminary\", data=True, lumi=2.6, year=2016, ax=ax)\n\n    # Leyenda ordenada para que DATA quede arriba\n    handles, labels = ax.get_legend_handles_labels()\n    ax.legend(reversed(handles), reversed(labels), fontsize=16, ncol=2, loc=\"upper right\")\n\n    # Ejes\n    ax.set_xlabel(x_label, fontsize=24)\n    ax.set_ylabel(\"Events\", fontsize=24)\n    ax.set_xlim(x_range)\n\n    if log_scale:\n        ax.set_yscale(\"log\")\n        ax.set_ylim(0.1, max(np.max(data_counts), np.max(total_mc)) * 500)\n    else:\n        ax.set_ylim(0, max(np.max(data_counts), np.max(total_mc)) * 1.5)\n\n    plt.tight_layout()\n    plt.show()\n\n</code></pre> <p>This block loads every muon-channel dataset from the previously generated _raw.parquet files, applies the correct normalization (data vs. Monte Carlo), assigns a final per-event weight, and stores everything inside a unified dictionary (all_dfs). Once all datasets are normalized, we can safely call plot_grouped_stack to generate stacked MC vs. Data plots that follow a professional CMS-style presentation.</p> <pre><code>loaded_dfs = {}\n\n\n# Full list of expected Muon datasets\ndatasets_muon_channel = [\n    'SingleMuon',           # Data\n    'ttbar-semileptonic',   # Top\n    'ttW', 'WW', 'ZZ', 'Zvv', 'DYJets-Zpt200',\n    't-channel-top',\n    'WJets-HT400to600'      # WJets binned (GOOD)\n]\n\nfor dataset in datasets_muon_channel:\n\n    # Muon channel uses '_raw.parquet' (no electron prefix)\n    path = f\"output_raw/{dataset}_raw.parquet\"\n\n    try:\n        df = pd.read_parquet(path)\n\n        # Normalization\n        if dataset in DATA_SL:\n            df[\"final_weight\"] = 1.0\n        else:\n            xsec = fileset[dataset][\"metadata\"][\"xsec\"]\n            sum_w = sum_weights_map.get(dataset, 1.0)\n            if sum_w == 0:\n                sum_w = 1.0\n            scale = (xsec * LUM) / sum_w\n\n            # Use genWeight if available\n            if \"genWeight\" in df.columns:\n                df[\"final_weight\"] = df[\"genWeight\"] * scale\n            else:\n                df[\"final_weight\"] = scale\n\n        loaded_dfs[dataset] = df\n        print(f\" Loaded: {dataset}\")\n\n    except FileNotFoundError:\n        # Skip missing datasets silently\n        continue\n\n# Final dictionary with loaded Muon datasets\nmuon_dfs_clean = loaded_dfs\n\n# Update all_dfs globally\nall_dfs = muon_dfs_clean\n\n\n# -------------------------------------------\n# ---          CLEAN PLOTS               ---\n# -------------------------------------------\n\nif len(muon_dfs_clean) &gt; 0:\n    mi_canal = \"SingleMuon\"\n\n    plot_grouped_stack(\"mT_W\", r\"$m_T^W$ [GeV]\", (0, 200), mi_canal, log_scale=False)\n    plot_grouped_stack(\"met\", r\"$p_T^{miss}$ [GeV]\", (150, 500), mi_canal, log_scale=True)\n    plot_grouped_stack(\"nJet\", r\"$N_{jets}$\", (2, 10), mi_canal, n_bins=8, log_scale=True)\n    plot_grouped_stack(\"nBTag\", r\"$N_{b-tags}$\", (0, 5), mi_canal, n_bins=5, log_scale=True)\n\nelse:\n    print(\" No data loaded. Check if the _raw.parquet files exist.\")\n\n</code></pre> <pre><code> Loaded: SingleMuon\n Loaded: ttbar-semileptonic\n Loaded: ttW\n Loaded: WW\n Loaded: ZZ\n Loaded: Zvv\n Loaded: DYJets-Zpt200\n Loaded: t-channel-top\n Loaded: WJets-HT400to600\n</code></pre> <p></p> <p></p> <p></p> <p></p> <pre><code>muon_dfs_clean = loaded_dfs\nall_dfs = muon_dfs_clean\n\n# ----- remover WJets -----\nif \"WJets-HT400to600\" in muon_dfs_clean:\n    muon_dfs_clean.pop(\"WJets-HT400to600\")\n\n# ----- graficar -----\nif len(muon_dfs_clean) &gt; 0:\n    mi_canal = \"SingleMuon\"\n\n    plot_grouped_stack(\"mT_W\", r\"$m_T^W$ [GeV]\", (0, 200), mi_canal, log_scale=False)\n    plot_grouped_stack(\"met\", r\"$p_T^{miss}$ [GeV]\", (150, 500), mi_canal, log_scale=True)\n    plot_grouped_stack(\"nJet\", r\"$N_{jets}$\", (2, 10), mi_canal, n_bins=8, log_scale=True)\n    plot_grouped_stack(\"nBTag\", r\"$N_{b-tags}$\", (0, 5), mi_canal, n_bins=5, log_scale=True)\n\n</code></pre> <p></p> <p></p> <p></p> <p></p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#electron","title":"Electron","text":"<p>To adapt the muon channel for the electron channel, we switch the signal object from <code>Muon</code> to <code>Electron</code> and adjust the kinematic cuts: pseudorapidity is restricted to \\(|\\eta| &lt; 2.1\\) (instead of 2.4), and a \"Gap Veto\" is implemented to exclude electrons in the barrel-endcap transition region (\\(1.4442 &lt; |\\eta| &lt; 1.566\\)). Furthermore, the identification criteria change from specific <code>tightId</code> and isolation cuts to the standard <code>cutBased == 4</code> (Tight ID), and Jet Cleaning is re-evaluated by requiring \\(\\Delta R &gt; 0.4\\) with respect to the selected electron rather than the muon.</p> <pre><code>#import awkward as ak\n#import uproot\n#import numpy as np\n#import vector\n#vector.register_awkward()\n\n\n\ndef process_electron(filename, dataset=\"Unknown\", IS_DATA=False):\n\n        with uproot.open(f\"{filename}:Events\") as tree:\n            electrons = ak.zip({\n                \"pt\": tree[\"Electron_pt\"].array(),\n                \"eta\": tree[\"Electron_eta\"].array(),\n                \"phi\": tree[\"Electron_phi\"].array(),\n                \"mass\": tree[\"Electron_mass\"].array(),\n                \"cutBased\": tree[\"Electron_cutBased\"].array(),\n            }, with_name=\"Momentum4D\")\n\n            muons = ak.zip({\n                \"pt\": tree[\"Muon_pt\"].array(),\n                \"eta\": tree[\"Muon_eta\"].array(),\n                \"phi\": tree[\"Muon_phi\"].array(),\n                \"mass\": tree[\"Muon_mass\"].array(),\n                \"looseId\": tree[\"Muon_looseId\"].array(),\n                \"iso\": tree[\"Muon_pfRelIso04_all\"].array(),\n            }, with_name=\"Momentum4D\")\n\n            jets = ak.zip({\n                \"pt\": tree[\"Jet_pt\"].array(),\n                \"eta\": tree[\"Jet_eta\"].array(),\n                \"phi\": tree[\"Jet_phi\"].array(),\n                \"mass\": tree[\"Jet_mass\"].array(),\n                \"jetId\": tree[\"Jet_jetId\"].array(),\n                \"btag\": tree[\"Jet_btagDeepFlavB\"].array(),\n            }, with_name=\"Momentum4D\")\n\n            met_pt = tree[\"MET_pt\"].array()\n            met_phi = tree[\"MET_phi\"].array()\n\n            if not IS_DATA: gen_weight = tree[\"genWeight\"].array()\n            else: gen_weight = ak.ones_like(met_pt)\n\n        # --- 1. selection---\n        in_gap = (abs(electrons.eta) &gt; 1.4442) &amp; (abs(electrons.eta) &lt; 1.566)\n        ele_tight_mask = (electrons.pt &gt; 30) &amp; (abs(electrons.eta) &lt; 2.1) &amp; (electrons.cutBased == 4) &amp; (~in_gap)\n        ele_veto_mask = (electrons.pt &gt; 10) &amp; (electrons.cutBased &gt;= 1)\n        mu_loose_mask = (muons.pt &gt; 10) &amp; (abs(muons.eta) &lt; 2.4) &amp; (muons.looseId) &amp; (muons.iso &lt; 0.25)\n\n        good_ele = electrons[ele_tight_mask]\n        veto_ele = electrons[ele_veto_mask]\n        veto_mu = muons[mu_loose_mask]\n\n        has_1_tight = (ak.num(good_ele) == 1)\n        is_exclusive = (ak.num(veto_ele) == 1) &amp; (ak.num(veto_mu) == 0)\n        pass_met = met_pt &gt; 150\n\n        event_mask = has_1_tight &amp; is_exclusive &amp; pass_met\n\n        good_ele = good_ele[event_mask]\n        jets = jets[event_mask]\n        met_pt = met_pt[event_mask]\n        met_phi = met_phi[event_mask]\n        gen_weight = gen_weight[event_mask]\n        leading_ele = good_ele[:, 0]\n\n\n        # A. Cleaning with ELECTRON\n        jet_clean_mask = (\n            (jets.pt &gt; 30) &amp; (jets.jetId &gt;= 1) &amp; \n            (jets.deltaR(leading_ele) &gt; 0.4)\n        )\n        all_clean_jets = jets[jet_clean_mask]\n\n        # B. Categories\n        central_jets = all_clean_jets[abs(all_clean_jets.eta) &lt; 2.4]\n        forward_jets = all_clean_jets[(abs(all_clean_jets.eta) &gt;= 2.4) &amp; (abs(all_clean_jets.eta) &lt; 5.0)]\n\n        has_2_jets = ak.num(central_jets) &gt;= 2\n\n        f_met = met_pt[has_2_jets]\n        f_met_phi = met_phi[has_2_jets]\n        f_ele = leading_ele[has_2_jets]\n        f_central = central_jets[has_2_jets]\n        f_forward = forward_jets[has_2_jets]\n        f_gen_weight = gen_weight[has_2_jets]\n\n        # mT\n        dphi = f_ele.phi - f_met_phi\n        mt = np.sqrt(2 * f_ele.pt * f_met * (1 - np.cos(dphi)))\n\n        # min DeltaPhi\n        jets_top2 = f_central[:, :2]\n        dphi_jets = abs(jets_top2.phi - f_met_phi)\n        dphi_jets = np.mod(dphi_jets + np.pi, 2*np.pi) - np.pi\n        min_dphi = ak.min(abs(dphi_jets), axis=1)\n\n        # B-tagging\n        is_btag = f_central.btag &gt; 0.2770\n        n_btag = ak.sum(is_btag, axis=1)\n\n        # Extras\n        n_fwd = ak.num(f_forward)\n\n        b_jets = f_central[is_btag]\n        has_b = ak.num(b_jets) &gt; 0\n        b_jet_padded = ak.fill_none(ak.firsts(b_jets), {\"pt\": 0, \"phi\": 0}, axis=0)\n        dphi_b = b_jet_padded.phi - f_met_phi\n        calc_mt_b = np.sqrt(2 * b_jet_padded.pt * f_met * (1 - np.cos(dphi_b)))\n\n        mt_b_np = ak.to_numpy(calc_mt_b)\n        has_b_np = ak.to_numpy(has_b)\n        mt_b_np[~has_b_np] = -1.0\n\n        return {\n            \"dataset\": dataset,\n            \"lep_pt\": ak.to_numpy(f_ele.pt),\n            \"lep_eta\": ak.to_numpy(f_ele.eta),\n            \"met\": ak.to_numpy(f_met),\n            \"mT_W\": ak.to_numpy(mt),\n            \"genWeight\": ak.to_numpy(f_gen_weight),\n            \"nJet\": ak.to_numpy(ak.num(f_central)),\n            \"nBTag\": ak.to_numpy(n_btag),\n            \"min_dphi\": ak.to_numpy(min_dphi),\n            \"nForwardJets\": ak.to_numpy(n_fwd),\n            \"mT_b\": mt_b_np\n        }\n\n</code></pre> <p>and with the same idea as the muon one</p> <pre><code>#import pandas as pd\n#import os\n\n\ndatasets_electron_channel = [\n    'SingleElectron',        # DATA\n    'ttbar-semileptonic',    # Main Background\n    'ttW',\n    'WW', 'ZZ', 'Zvv',\n    'DYJets-Zpt200',         # Drell\u2013Yan (important for Z\u2192ee)\n    't-channel-top',\n    'WJets-HT400to600'       # W+Jets\n]\n\ndef process_dataset_electron_raw(dataset, n_files=5):\n    # Explicit detection for data\n    is_data = \"SingleElectron\" in dataset\n\n    print(f\" Processing RAW Electron {dataset} (Is Data: {is_data})...\")\n\n    if dataset not in fileset:\n        print(f\"{dataset} not found in fileset. Skipping.\")\n        return None\n\n    files = fileset[dataset][\"files\"][:n_files]\n    dfs = []\n\n    for f in files:\n        try:\n            # Call the electron-level physics processing function\n            # (Make sure 'process_electron' is defined earlier)\n            data_dict = process_electron(f, dataset=dataset, IS_DATA=is_data)\n\n            df = pd.DataFrame(data_dict)\n            dfs.append(df)\n\n        except Exception as e:\n            # Report individual file errors without stopping the loop\n            print(f\" Error in file {f}: {e}\")\n\n    if len(dfs) == 0:\n        print(f\"No valid events were produced for {dataset}\")\n        return None\n\n    full_df = pd.concat(dfs, ignore_index=True)\n\n    # Save output\n    os.makedirs(\"output_raw\", exist_ok=True)\n\n    # NOTE: we use '_electron_raw' to avoid overlapping with muon outputs\n    output_path = f\"output_raw/{dataset}_electron_raw.parquet\"\n\n    full_df.to_parquet(output_path, index=False)\n    print(f\"Saved: {output_path} with {len(full_df)} events.\")\n\n    return full_df\n\n\n# --- 3. MASS EXECUTION ---\n# Use n_files=10 or more for reasonable statistics\nN_FILES = 10\n\nprint(f\"=== STARTING ELECTRON PROCESSING ({N_FILES} files per dataset) ===\")\n\nfor ds in datasets_electron_channel:\n    process_dataset_electron_raw(ds, n_files=N_FILES)\n\n</code></pre> <pre><code>=== STARTING ELECTRON PROCESSING (10 files per dataset) ===\n Processing RAW Electron SingleElectron (Is Data: True)...\nSaved: output_raw/SingleElectron_electron_raw.parquet with 10757 events.\n Processing RAW Electron ttbar-semileptonic (Is Data: False)...\nSaved: output_raw/ttbar-semileptonic_electron_raw.parquet with 78228 events.\n Processing RAW Electron ttW (Is Data: False)...\nSaved: output_raw/ttW_electron_raw.parquet with 60974 events.\n Processing RAW Electron WW (Is Data: False)...\nSaved: output_raw/WW_electron_raw.parquet with 6141 events.\n Processing RAW Electron ZZ (Is Data: False)...\nSaved: output_raw/ZZ_electron_raw.parquet with 83 events.\n Processing RAW Electron Zvv (Is Data: False)...\nSaved: output_raw/Zvv_electron_raw.parquet with 24 events.\n Processing RAW Electron DYJets-Zpt200 (Is Data: False)...\nSaved: output_raw/DYJets-Zpt200_electron_raw.parquet with 1398 events.\n Processing RAW Electron t-channel-top (Is Data: False)...\nSaved: output_raw/t-channel-top_electron_raw.parquet with 4238 events.\n Processing RAW Electron WJets-HT400to600 (Is Data: False)...\nSaved: output_raw/WJets-HT400to600_electron_raw.parquet with 35219 events.\n</code></pre> <pre><code>def load_all_electrons_cleaned():\n    loaded_dfs = {}\n\n    datasets_electron_channel = [\n        'SingleElectron', 'ttbar-semileptonic',\n        'ttW', 'WW', 'ZZ', 'Zvv', 'DYJets-Zpt200',\n        't-channel-top',\n        'WJets-HT400to600',\n    ]\n\n    for dataset in datasets_electron_channel:\n        path = f\"output_raw/{dataset}_electron_raw.parquet\"\n        try:\n            df = pd.read_parquet(path)\n\n            if dataset in DATA_SL:\n                df[\"final_weight\"] = 1.0\n            else:\n                xsec = fileset[dataset][\"metadata\"][\"xsec\"]\n                sum_w = sum_weights_map.get(dataset, 1.0)\n                if sum_w == 0: sum_w = 1.0\n                scale = (xsec * LUM) / sum_w\n\n                if \"genWeight\" in df.columns:\n                    df[\"final_weight\"] = df[\"genWeight\"] * scale\n                else:\n                    df[\"final_weight\"] = scale\n\n            loaded_dfs[dataset] = df\n            print(f\" Cargado: {dataset}\")\n\n        except FileNotFoundError:\n            continue\n\n    return loaded_dfs\n\n\nele_dfs_clean = load_all_electrons_cleaned()\n\nif len(ele_dfs_clean) &gt; 0:\n    print(\"\\n Generating CLEAN plots for SingleElectron...\")\n\n    all_dfs = ele_dfs_clean   # THIS CAUSES plot_grouped_stack TO USE ELECTRONS\n\n    mi_canal = \"SingleElectron\"\n\n\n    plot_grouped_stack(\"mT_W\", r\"$m_T^W$ [GeV]\", (0, 200), mi_canal, log_scale=False)\n    plot_grouped_stack(\"met\",  r\"$p_T^{miss}$ [GeV]\", (150, 500), mi_canal, log_scale=True)\n    plot_grouped_stack(\"nJet\", r\"$N_{jets}$\", (2, 10), mi_canal, n_bins=8, log_scale=True)\n    plot_grouped_stack(\"nBTag\", r\"$N_{b-tags}$\", (0, 5), mi_canal, n_bins=5, log_scale=True)\n\nelse:\n    print(\" No electron data was uploaded.\")\n\n\n</code></pre> <pre><code> Cargado: SingleElectron\n Cargado: ttbar-semileptonic\n Cargado: ttW\n Cargado: WW\n Cargado: ZZ\n Cargado: Zvv\n Cargado: DYJets-Zpt200\n Cargado: t-channel-top\n Cargado: WJets-HT400to600\n\n Generating CLEAN plots for SingleElectron...\n</code></pre> <p></p> <p></p> <p></p> <p></p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#signal-region","title":"Signal Region","text":""},{"location":"Single_Lepton/Analisis_muon_final_version/#table-13-final-event-selection-sl-and-ah","title":"Table 13 \u2014 Final Event Selection (SL and AH)","text":""},{"location":"Single_Lepton/Analisis_muon_final_version/#what-does-it-contain_1","title":"What does it contain?","text":"<p>The official final cuts defining the analysis Signal Regions (SR). Each SR is classified according to:</p> <ul> <li>Channel (semi-leptonic or hadronic)</li> <li>Number of b-jets</li> <li>Presence of forward jets</li> <li>Values of MET, MT, HT, etc.</li> </ul>"},{"location":"Single_Lepton/Analisis_muon_final_version/#what-is-it-for_2","title":"What is it for?","text":"<p>It defines the regions where dark matter signals are searched for. These regions are fed directly into the final statistical fit.</p> <pre><code>\ndisplay(Image(filename=\"Table_13.png\"))\n\n</code></pre> <p></p> <p>Now we move to the signal region. We use the events that were already filtered by the baseline selection and then apply the additional cuts described in Table 13. To do this, we first need to load the preprocessed datasets stored as parquet files, so the following function was created.</p> <p>This function loads only the datasets needed for the analysis channel (muon or electron)</p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#issues","title":"Issues","text":"<p>The normalization is applied again at the loading stage because the stored .parquet files do not consistently contain a final, analysis-ready weight. In some cases, the <code>final_weight</code> column is not saved at all, and in others it may have been produced using a different luminosity, a different fileset configuration, or an earlier definition of the analysis.</p> <p>To avoid mixing inconsistent normalizations and to guarantee that all samples are treated uniformly, the normalization is recomputed at runtime using the current cross sections and the total sum of generator weights. This ensures that the final event yields are coherent and directly comparable across datasets.</p> <pre><code>def load_data(channel=\"muon\"):\n    loaded_dfs = {}\n\n    datasets_to_load = [\n        'SingleMuon' if channel == 'muon' else 'SingleElectron',\n        'ttbar-semileptonic', 'ttW', 'WW', 'ZZ', 'Zvv', \n        'DYJets-Zpt200', 't-channel-top', 'WJets-HT400to600'\n    ]\n\n    suffix = \"_raw.parquet\" if channel == \"muon\" else \"_electron_raw.parquet\"\n\n    for ds in datasets_to_load:\n        path = f\"output_raw/{ds}{suffix}\"\n        try:\n            df = pd.read_parquet(path)\n\n            # Normalizaci\u00f3n\n            if ds in DATA_SL:\n                df[\"final_weight\"] = 1.0\n            else:\n                if ds not in fileset: continue\n                xsec = fileset[ds][\"metadata\"][\"xsec\"]\n                sum_w = sum_weights_map.get(ds, 1.0) \n                if sum_w == 0: sum_w = 1.0\n\n                scale = (xsec * LUM) / sum_w\n\n                if \"genWeight\" in df.columns:\n                    df[\"final_weight\"] = df[\"genWeight\"] * scale\n                else:\n                    df[\"final_weight\"] = scale\n\n            loaded_dfs[ds] = df\n\n        except FileNotFoundError:\n            continue\n\n    return loaded_dfs\n\n</code></pre> <pre><code>def signal_regions(df):\n\n\n    if df is None or len(df) == 0: return {}\n\n    # --- CORTES SUAVES ---\n    pass_common = (\n        (df[\"met\"] &gt; 160) &amp;\n        (df[\"min_dphi\"] &gt; 0.5) \n    )\n\n    df_sr = df[pass_common]\n    if len(df_sr) == 0: return {}\n\n    # Definici\u00f3n de las 3 Regiones (Categor\u00edas)\n    mask_1b_0f = (df_sr[\"nBTag\"] == 1) &amp; (df_sr[\"nForwardJets\"] == 0)\n    mask_1b_1f = (df_sr[\"nBTag\"] == 1) &amp; (df_sr[\"nForwardJets\"] &gt;= 1)\n    mask_2b = (df_sr[\"nBTag\"] &gt;= 2) \n\n    return {\n        \"SR_1b_0f\": df_sr[mask_1b_0f],\n        \"SR_1b_1f\": df_sr[mask_1b_1f],\n        \"SR_2b\":    df_sr[mask_2b]\n    }\n\n</code></pre> <p>Once <code>plot_grouped_stack</code> was defined, the same base code was reused to create <code>plot_region_stack</code>. The logic of the stacked histogram is the same, but extra features were added to handle analysis regions. In particular, a region label is drawn on the plot and the display is adapted to show results specific to a selected region. This keeps the core behavior unchanged while adding more flexibility for regional visualization.</p> <p>The main changes are:</p> <ul> <li>A region label parameter was added to the function signature.</li> <li>A text label was drawn on the plot using a line like:   <code>ax.text(..., region_label, ...)</code></li> <li>The plot title or decoration was adapted to reflect the selected region.</li> <li>Small adjustments were made to make the function work with region-specific dictionaries.</li> </ul> <p>All other parts of the stacking logic (histogram creation, grouping, colors, and legends) remain unchanged.</p> <pre><code>def plot_region_stack(dfs_dict, region_name, var_name, x_label, x_range, channel_label, n_bins=10):\n\n    bins = np.linspace(x_range[0], x_range[1], n_bins + 1)\n\n    # Preparar Datos para Stack\n    grouped_counts = {}\n    grouped_info = {}\n\n    for name, df in dfs_dict.items():\n        if name in DATA_SL: continue \n\n        counts, _ = np.histogram(df[var_name], bins=bins, weights=df[\"final_weight\"])\n        g_key, label, color = get_group_info(name)\n\n        if g_key not in grouped_counts:\n            grouped_counts[g_key] = counts\n            grouped_info[g_key] = {\"label\": label, \"color\": color, \"yield\": np.sum(counts)}\n        else:\n            grouped_counts[g_key] += counts\n            grouped_info[g_key][\"yield\"] += np.sum(counts)\n\n    # Ordenar Stack\n    active_groups = sorted(grouped_info.keys(), key=lambda k: grouped_info[k][\"yield\"])\n\n    mc_counts = []\n    mc_colors = []\n    mc_labels = []\n    total_mc = np.zeros(n_bins)\n\n    for g in active_groups:\n        mc_counts.append(grouped_counts[g])\n        mc_colors.append(grouped_info[g][\"color\"])\n        mc_labels.append(grouped_info[g][\"label\"])\n        total_mc += grouped_counts[g]\n\n    # Datos\n    df_data = dfs_dict.get(channel_label)\n    data_counts = np.zeros(n_bins)\n    if df_data is not None:\n        data_counts, _ = np.histogram(df_data[var_name], bins=bins)\n\n    # Graficar\n    fig, ax = plt.subplots(figsize=(10, 8))\n\n    if len(mc_counts) &gt; 0:\n        hep.histplot(mc_counts, bins=bins, stack=True, histtype=\"fill\",\n                     color=mc_colors, label=mc_labels, edgecolor=\"black\", linewidth=1, ax=ax)\n\n    hep.histplot(data_counts, bins=bins, histtype=\"errorbar\", color=\"black\",\n                 label=f\"{channel_label} (Data)\", yerr=True, marker='o', markersize=5, ax=ax)\n\n    # Decoraci\u00f3n\n    hep.cms.label(\"Preliminary\", data=True, lumi=35.9, year=2016, ax=ax)\n\n    # Leyenda Limpia\n    handles, labels = ax.get_legend_handles_labels()\n    by_label = OrderedDict(zip(labels[::-1], handles[::-1]))\n    ax.legend(by_label.values(), by_label.keys(), fontsize=15, ncol=2, loc='upper right')\n\n    # Etiqueta Interna\n    ax.text(0.05, 0.93, f\"{region_name}\", transform=ax.transAxes, \n            fontsize=20, fontweight='bold', va='top')\n\n    ax.set_xlabel(x_label, fontsize=24)\n    ax.set_ylabel(\"Events\", fontsize=24)\n    ax.set_xlim(x_range)\n    ax.set_yscale(\"log\") \n\n    max_y = max(np.max(data_counts), np.max(total_mc))\n    ax.set_ylim(0.1, max_y * 500) \n\n    plt.tight_layout()\n    plt.show()\n\n</code></pre> <pre><code>def run_analysis_for_channel(channel_mode):\n\n    raw_dfs = load_data(channel_mode)\n    if not raw_dfs: return\n\n    regions_db = {\"SR_1b_0f\": {}, \"SR_1b_1f\": {}, \"SR_2b\": {}}\n    for name, df in raw_dfs.items():\n        sub_regions = signal_regions(df)\n        for reg, df_reg in sub_regions.items():\n            regions_db[reg][name] = df_reg\n\n    d_label = \"SingleMuon\" if channel_mode == \"muon\" else \"SingleElectron\"\n\n    plot_region_stack(regions_db[\"SR_2b\"], \"SR 2b\", \"met\", r\"$p_T^{miss}$ [GeV]\", (160, 600), d_label)\n    plot_region_stack(regions_db[\"SR_1b_1f\"], r\"SR 1b $\\geq$1f\", \"met\", r\"$p_T^{miss}$ [GeV]\", (160, 600), d_label)\n    plot_region_stack(regions_db[\"SR_1b_0f\"], \"SR 1b 0f\", \"met\", r\"$p_T^{miss}$ [GeV]\", (160, 600), d_label)\n\n</code></pre> <pre><code>from collections import OrderedDict\n\n\nif 'sum_weights_map' in globals():\n    run_analysis_for_channel(\"muon\")\n    run_analysis_for_channel(\"electron\")\nelse:\n    print(\" Error.\")\n\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"Single_Lepton/Analisis_muon_final_version/#control-region","title":"Control Region","text":""},{"location":"Single_Lepton/Analisis_muon_final_version/#table-14-control-region-definitions-sl-and-ah","title":"Table 14 \u2014 Control Region Definitions (SL and AH)","text":""},{"location":"Single_Lepton/Analisis_muon_final_version/#what-does-it-contain_2","title":"What does it contain?","text":"<p>This table defines the Control Regions (CRs) required to calibrate and validate the main background processes in the analysis:</p> <ul> <li>Dileptonic tt\u0304</li> <li>W+jets</li> <li>Z\u2192\u03bd\u03bd (in the all-hadronic channel)</li> <li>Semileptonic tt\u0304 (in the all-hadronic channel)</li> </ul>"},{"location":"Single_Lepton/Analisis_muon_final_version/#what-is-it-used-for","title":"What is it used for?","text":"<p>These regions serve to:</p> <ul> <li>Constrain and normalize the simulated background yields</li> <li>Compare Monte Carlo predictions against real data</li> <li>Reduce systematic uncertainties</li> </ul> <p>They are essential for controlling the dominant backgrounds before extracting the signal in the Signal Regions (SRs).</p> <pre><code>\ndisplay(Image(filename=\"Table_14.png\"))\n\n</code></pre> <p></p> <pre><code>def filter_cr_wlnu(df):\n    \"\"\"\n    Control Region: CR W(l\u03bd)\n    Nombres oficiales Tabla 14:\n        - SL1eWR  (electr\u00f3n)\n        - SL1mWR  (mu\u00f3n)\n    \"\"\"\n    if df is None or len(df) == 0:\n        return {}\n\n    mask = (\n        (df[\"met\"] &gt;= 160) &amp;\n        (df[\"mT_W\"] &gt;= 80) &amp;\n        (df[\"nBTag\"] == 0) &amp;\n        (df[\"nJet\"] &gt;= 2)\n    )\n\n    df_cr = df[mask]\n    if len(df_cr) == 0:\n        return {}\n\n    return {\"CR_Wlnu\": df_cr}\n\n</code></pre> <p>Once <code>plot_region_stack</code> was defined, the same base structure was reused to create <code>plot_cr_stack</code>. The core stacked histogram logic stays the same, but additional lines were added or modified to specialize the plot for Control Regions.</p> <p>The main changes are:</p> <ul> <li>A new function name was created: <code>plot_cr_stack</code>.</li> <li>A new input parameter was added to handle the control region label (for example: <code>region_label</code>).</li> <li>The plot now includes a region tag drawn on the figure, added through a line like:   <code>ax.text(..., region_label, ...)</code></li> <li>The function was adapted to work with Control Region\u2013filtered datasets, instead of general or signal regions.</li> <li>The default axis ranges and binning were tuned for control-region kinematics.</li> </ul> <p>All histogram stacking, coloring, grouping, and legend logic remains the same as in the previous functions.</p> <pre><code>def plot_cr_stack(dfs_dict, region_label, var_name, x_label, x_range, data_label, n_bins=15):\n\n    bins = np.linspace(x_range[0], x_range[1], n_bins + 1)\n    grouped_counts = {}\n    grouped_info = {}\n\n    # A) MC\n    for name, df in dfs_dict.items():\n        if name in DATA_SL:\n            continue\n\n        counts, _ = np.histogram(df[var_name], bins=bins, weights=df[\"final_weight\"])\n        g_key, label, color = get_group_info(name)\n\n        if g_key not in grouped_counts:\n            grouped_counts[g_key] = counts\n            grouped_info[g_key] = {\"label\": label, \"color\": color, \"yield\": np.sum(counts)}\n        else:\n            grouped_counts[g_key] += counts\n            grouped_info[g_key][\"yield\"] += np.sum(counts)\n\n    active_groups = sorted(grouped_info.keys(), key=lambda k: grouped_info[k][\"yield\"])\n\n    mc_counts = []\n    mc_colors = []\n    mc_labels = []\n    total_mc = np.zeros(n_bins)\n\n    for g in active_groups:\n        mc_counts.append(grouped_counts[g])\n        mc_colors.append(grouped_info[g][\"color\"])\n        mc_labels.append(grouped_info[g][\"label\"])\n        total_mc += grouped_counts[g]\n\n    # B) DATA\n    df_data = dfs_dict.get(data_label)\n    if df_data is not None:\n        data_counts, _ = np.histogram(df_data[var_name], bins=bins)\n    else:\n        data_counts = np.zeros(n_bins)\n\n    # === Plot ===\n    fig, ax = plt.subplots(figsize=(10, 8))\n\n    hep.histplot(mc_counts, bins=bins, stack=True, histtype=\"fill\",\n                 color=mc_colors, label=mc_labels, edgecolor=\"black\", linewidth=1, ax=ax)\n\n    hep.histplot(data_counts, bins=bins, histtype=\"errorbar\", color=\"black\",\n                 label=f\"{data_label} (Data)\", yerr=True, marker='o', markersize=5, ax=ax)\n\n    hep.cms.label(\"Preliminary\", data=True, lumi=35.9, year=2016, ax=ax)\n\n    ax.text(0.05, 0.93, region_label, transform=ax.transAxes,\n            fontsize=20, fontweight='bold', va='top', ha='left')\n\n    handles, labels = ax.get_legend_handles_labels()\n    by_label = OrderedDict(zip(labels[::-1], handles[::-1]))\n    ax.legend(by_label.values(), by_label.keys(), fontsize=15, ncol=2, loc='upper right')\n\n    ax.set_xlabel(x_label, fontsize=24)\n    ax.set_ylabel(\"Events\", fontsize=24)\n    ax.set_xlim(x_range)\n    ax.set_yscale(\"log\")\n\n    max_y = max(np.max(data_counts), np.max(total_mc))\n    ax.set_ylim(0.1, max_y * 500)\n\n    plt.tight_layout()\n    plt.show()\n\n\n\n</code></pre> <pre><code>\ndef run_SL(channel_mode):\n\n    # 1. Load datasets\n    raw_dfs = load_data(channel_mode)\n    if not raw_dfs:\n        return\n\n    # 2. Filtrar regi\u00f3n CR W(l\u03bd)\n    cr_dict = {}\n    for name, df in raw_dfs.items():\n        reg = filter_cr_wlnu(df)\n        if \"CR_Wlnu\" in reg:\n            cr_dict[name] = reg[\"CR_Wlnu\"]\n\n    if len(cr_dict) == 0:\n        print(\" No events passed CR W(l\u03bd).\")\n        return\n\n    # 3. Etiquetas correctas seg\u00fan Tabla 14\n    if channel_mode == \"muon\":\n        region_label = \"SL1mWR\"\n        data_label = \"SingleMuon\"\n    else:\n        region_label = \"SL1eWR\"\n        data_label = \"SingleElectron\"\n\n\n    # plot MET\n    plot_cr_stack(cr_dict, region_label, \"met\", r\"$p_T^{miss}$ [GeV]\", (160, 600), data_label, n_bins=15)\n\n    # plot MT\n    #plot_cr_stack(cr_dict, region_label, \"mT_W\", r\"$m_T^W$ [GeV]\", (160, 500), data_label, n_bins=15)\n\n\n# --- RUN ---\nrun_SL(\"muon\")\nrun_SL(\"electron\")\n</code></pre> <p></p> <p></p>"}]}